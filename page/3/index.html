<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>


















  
  
  <link rel="stylesheet" href="/lib/fancybox/source/jquery.fancybox.css"/>







<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.1.2"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/leaf.jpg?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/leaf.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/leaf1.ico?v=7.1.2">


  <link rel="mask-icon" href="/images/leaf.jpg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Heroinlin&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Heroinlin&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Heroinlin&#39;s Blog">





  
  
  <link rel="canonical" href="http://yoursite.com/page/3/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Heroinlin's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Heroinlin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>Schlagwörter</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Kategorien</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archiv</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br/>Zeitplan</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/12/Python/Python_String/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/12/Python/Python_String/" class="post-title-link" itemprop="url">Python之String模块</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-03-12 10:48:11 / Geändert am: 10:51:28" itemprop="dateCreated datePublished" datetime="2018-03-12T10:48:11+08:00">2018-03-12</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#Python之String模块</p>
<p>本部分是对python中的string模块进行解析，添加函数中文说明与实例说明</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""A collection of string operations (most are no longer used).</span></span><br><span class="line"><span class="string">Warning: most of the code you see here isn't normally used nowadays.</span></span><br><span class="line"><span class="string">Beginning with Python 1.6, many of these functions are implemented as</span></span><br><span class="line"><span class="string">methods on the standard string object. They used to be implemented by</span></span><br><span class="line"><span class="string">a built-in module called strop, but strop is now obsolete itself.</span></span><br><span class="line"><span class="string">Public module variables:</span></span><br><span class="line"><span class="string">whitespace -- a string containing all characters considered whitespace</span></span><br><span class="line"><span class="string">lowercase -- a string containing all characters considered lowercase letters</span></span><br><span class="line"><span class="string">uppercase -- a string containing all characters considered uppercase letters</span></span><br><span class="line"><span class="string">letters -- a string containing all characters considered letters</span></span><br><span class="line"><span class="string">digits -- a string containing all characters considered decimal digits</span></span><br><span class="line"><span class="string">hexdigits -- a string containing all characters considered hexadecimal digits</span></span><br><span class="line"><span class="string">octdigits -- a string containing all characters considered octal digits</span></span><br><span class="line"><span class="string">punctuation -- a string containing all characters considered punctuation</span></span><br><span class="line"><span class="string">printable -- a string containing all characters considered printable</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Some strings for ctype-style character classification</span></span><br><span class="line">whitespace = <span class="string">' \t\n\r\v\f'</span></span><br><span class="line">lowercase = <span class="string">'abcdefghijklmnopqrstuvwxyz'</span></span><br><span class="line">uppercase = <span class="string">'ABCDEFGHIJKLMNOPQRSTUVWXYZ'</span></span><br><span class="line">letters = lowercase + uppercase</span><br><span class="line">ascii_lowercase = lowercase</span><br><span class="line">ascii_uppercase = uppercase</span><br><span class="line">ascii_letters = ascii_lowercase + ascii_uppercase</span><br><span class="line">digits = <span class="string">'0123456789'</span></span><br><span class="line">hexdigits = digits + <span class="string">'abcdef'</span> + <span class="string">'ABCDEF'</span></span><br><span class="line">octdigits = <span class="string">'01234567'</span></span><br><span class="line">punctuation = <span class="string">"""!"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\]^_`&#123;|&#125;~"""</span></span><br><span class="line">printable = digits + letters + punctuation + whitespace</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case conversion helpers</span></span><br><span class="line"><span class="comment"># Use str to convert Unicode literal in case of -U</span></span><br><span class="line">l = map(chr, xrange(<span class="number">256</span>))</span><br><span class="line">_idmap = str(<span class="string">''</span>).join(l)</span><br><span class="line"><span class="keyword">del</span> l</span><br><span class="line"></span><br><span class="line"><span class="comment"># Functions which aren't available as string methods.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Capitalize the words in a string, e.g. " aBc  dEf " -&gt; "Abc Def".</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">capwords</span><span class="params">(s, sep=None)</span>:</span></span><br><span class="line">    <span class="string">"""capwords(s [,sep]) -&gt; string</span></span><br><span class="line"><span class="string">    用split拆分参数转换为单词，利用capitalize使单词首字母大写，并且用join连接这些单词。</span></span><br><span class="line"><span class="string">    如果可选的第二个参数sep是缺省或无，以单个空格代替一串空白字符串，</span></span><br><span class="line"><span class="string">    开头和结尾的空格被删除，否则以sep为分隔符来分割和连接单词.</span></span><br><span class="line"><span class="string">    如string.capwords("   nice   to   meet  you     "),输出为：Nice To Meet You</span></span><br><span class="line"><span class="string">    如string.capwords(" niceto  meet  you ","e"),输出为： niceTo  meeT  you</span></span><br><span class="line"><span class="string">    Split the argument into words using split, capitalize each</span></span><br><span class="line"><span class="string">    word using capitalize, and join the capitalized words using</span></span><br><span class="line"><span class="string">    join.  If the optional second argument sep is absent or None,</span></span><br><span class="line"><span class="string">    runs of whitespace characters are replaced by a single space</span></span><br><span class="line"><span class="string">    and leading and trailing whitespace are removed, otherwise</span></span><br><span class="line"><span class="string">    sep is used to split and join the words.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> (sep <span class="keyword">or</span> <span class="string">' '</span>).join(x.capitalize() <span class="keyword">for</span> x <span class="keyword">in</span> s.split(sep))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct a translation string</span></span><br><span class="line">_idmapL = <span class="keyword">None</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">maketrans</span><span class="params">(fromstr, tostr)</span>:</span></span><br><span class="line">    <span class="string">"""maketrans(frm, to) -&gt; string</span></span><br><span class="line"><span class="string">    返回一个转换表适用于string.translate使用（字符串长256字节）。字符串frm和to必须具有相同的长度</span></span><br><span class="line"><span class="string">    Return a translation table (a string of 256 bytes long)</span></span><br><span class="line"><span class="string">    suitable for use in string.translate.  The strings frm and to</span></span><br><span class="line"><span class="string">    must be of the same length.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> len(fromstr) != len(tostr):</span><br><span class="line">        <span class="keyword">raise</span> ValueError, <span class="string">"maketrans arguments must have same length"</span></span><br><span class="line">    <span class="keyword">global</span> _idmapL</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> _idmapL:</span><br><span class="line">        _idmapL = list(_idmap)</span><br><span class="line">    L = _idmapL[:]</span><br><span class="line">    fromstr = map(ord, fromstr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(fromstr)):</span><br><span class="line">        L[fromstr[i]] = tostr[i]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join(L)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####################################################################</span></span><br><span class="line"><span class="keyword">import</span> re <span class="keyword">as</span> _re</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_multimap</span>:</span></span><br><span class="line">    <span class="string">"""Helper class for combining multiple mappings.</span></span><br><span class="line"><span class="string">    Used by .&#123;safe_,&#125;substitute() to combine the mapping and keyword</span></span><br><span class="line"><span class="string">    arguments.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, primary, secondary)</span>:</span></span><br><span class="line">        self._primary = primary</span><br><span class="line">        self._secondary = secondary</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, key)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> self._primary[key]</span><br><span class="line">        <span class="keyword">except</span> KeyError:</span><br><span class="line">            <span class="keyword">return</span> self._secondary[key]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_TemplateMetaclass</span><span class="params">(type)</span>:</span></span><br><span class="line">    pattern = <span class="string">r"""</span></span><br><span class="line"><span class="string">    %(delim)s(?:</span></span><br><span class="line"><span class="string">      (?P&lt;escaped&gt;%(delim)s) |   # Escape sequence of two delimiters</span></span><br><span class="line"><span class="string">      (?P&lt;named&gt;%(id)s)      |   # delimiter and a Python identifier</span></span><br><span class="line"><span class="string">      &#123;(?P&lt;braced&gt;%(id)s)&#125;   |   # delimiter and a braced identifier</span></span><br><span class="line"><span class="string">      (?P&lt;invalid&gt;)              # Other ill-formed delimiter exprs</span></span><br><span class="line"><span class="string">    )</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(cls, name, bases, dct)</span>:</span></span><br><span class="line">        super(_TemplateMetaclass, cls).__init__(name, bases, dct)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'pattern'</span> <span class="keyword">in</span> dct:</span><br><span class="line">            pattern = cls.pattern</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pattern = _TemplateMetaclass.pattern % &#123;</span><br><span class="line">                <span class="string">'delim'</span> : _re.escape(cls.delimiter),</span><br><span class="line">                <span class="string">'id'</span>    : cls.idpattern,</span><br><span class="line">                &#125;</span><br><span class="line">        cls.pattern = _re.compile(pattern, _re.IGNORECASE | _re.VERBOSE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Template</span>:</span></span><br><span class="line">    <span class="string">"""A string class for supporting $-substitutions."""</span></span><br><span class="line">    __metaclass__ = _TemplateMetaclass</span><br><span class="line"></span><br><span class="line">    delimiter = <span class="string">'$'</span></span><br><span class="line">    idpattern = <span class="string">r'[_a-z][_a-z0-9]*'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, template)</span>:</span></span><br><span class="line">        self.template = template</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Search for $$, $identifier, $&#123;identifier&#125;, and any bare $'s</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_invalid</span><span class="params">(self, mo)</span>:</span></span><br><span class="line">        i = mo.start(<span class="string">'invalid'</span>)</span><br><span class="line">        lines = self.template[:i].splitlines(<span class="keyword">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> lines:</span><br><span class="line">            colno = <span class="number">1</span></span><br><span class="line">            lineno = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            colno = i - len(<span class="string">''</span>.join(lines[:<span class="number">-1</span>]))</span><br><span class="line">            lineno = len(lines)</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Invalid placeholder in string: line %d, col %d'</span> %</span><br><span class="line">                         (lineno, colno))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">substitute</span><span class="params">(*args, **kws)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> args:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"descriptor 'substitute' of 'Template' object "</span></span><br><span class="line">                            <span class="string">"needs an argument"</span>)</span><br><span class="line">        self, args = args[<span class="number">0</span>], args[<span class="number">1</span>:]  <span class="comment"># allow the "self" keyword be passed</span></span><br><span class="line">        <span class="keyword">if</span> len(args) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">'Too many positional arguments'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> args:</span><br><span class="line">            mapping = kws</span><br><span class="line">        <span class="keyword">elif</span> kws:</span><br><span class="line">            mapping = _multimap(kws, args[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mapping = args[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># Helper function for .sub()</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(mo)</span>:</span></span><br><span class="line">            <span class="comment"># Check the most common path first.</span></span><br><span class="line">            named = mo.group(<span class="string">'named'</span>) <span class="keyword">or</span> mo.group(<span class="string">'braced'</span>)</span><br><span class="line">            <span class="keyword">if</span> named <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                val = mapping[named]</span><br><span class="line">                <span class="comment"># We use this idiom instead of str() because the latter will</span></span><br><span class="line">                <span class="comment"># fail if val is a Unicode containing non-ASCII characters.</span></span><br><span class="line">                <span class="keyword">return</span> <span class="string">'%s'</span> % (val,)</span><br><span class="line">            <span class="keyword">if</span> mo.group(<span class="string">'escaped'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> self.delimiter</span><br><span class="line">            <span class="keyword">if</span> mo.group(<span class="string">'invalid'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                self._invalid(mo)</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Unrecognized named group in pattern'</span>,</span><br><span class="line">                             self.pattern)</span><br><span class="line">        <span class="keyword">return</span> self.pattern.sub(convert, self.template)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">safe_substitute</span><span class="params">(*args, **kws)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> args:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"descriptor 'safe_substitute' of 'Template' object "</span></span><br><span class="line">                            <span class="string">"needs an argument"</span>)</span><br><span class="line">        self, args = args[<span class="number">0</span>], args[<span class="number">1</span>:]  <span class="comment"># allow the "self" keyword be passed</span></span><br><span class="line">        <span class="keyword">if</span> len(args) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">'Too many positional arguments'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> args:</span><br><span class="line">            mapping = kws</span><br><span class="line">        <span class="keyword">elif</span> kws:</span><br><span class="line">            mapping = _multimap(kws, args[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mapping = args[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># Helper function for .sub()</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(mo)</span>:</span></span><br><span class="line">            named = mo.group(<span class="string">'named'</span>) <span class="keyword">or</span> mo.group(<span class="string">'braced'</span>)</span><br><span class="line">            <span class="keyword">if</span> named <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># We use this idiom instead of str() because the latter</span></span><br><span class="line">                    <span class="comment"># will fail if val is a Unicode containing non-ASCII</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="string">'%s'</span> % (mapping[named],)</span><br><span class="line">                <span class="keyword">except</span> KeyError:</span><br><span class="line">                    <span class="keyword">return</span> mo.group()</span><br><span class="line">            <span class="keyword">if</span> mo.group(<span class="string">'escaped'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> self.delimiter</span><br><span class="line">            <span class="keyword">if</span> mo.group(<span class="string">'invalid'</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">return</span> mo.group()</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Unrecognized named group in pattern'</span>,</span><br><span class="line">                             self.pattern)</span><br><span class="line">        <span class="keyword">return</span> self.pattern.sub(convert, self.template)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####################################################################</span></span><br><span class="line"><span class="comment"># <span class="doctag">NOTE:</span> Everything below here is deprecated.  Use string methods instead.</span></span><br><span class="line"><span class="comment"># This stuff will go away in Python 3.0.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Backward compatible names for exceptions</span></span><br><span class="line">index_error = ValueError</span><br><span class="line">atoi_error = ValueError</span><br><span class="line">atof_error = ValueError</span><br><span class="line">atol_error = ValueError</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert UPPER CASE letters to lower case</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lower</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="string">"""lower(s) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s转换为小写的副本。</span></span><br><span class="line"><span class="string">    Return a copy of the string s converted to lowercase.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.lower()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert lower case letters to UPPER CASE</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">upper</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="string">"""upper(s) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s转换为大写的副本。</span></span><br><span class="line"><span class="string">    Return a copy of the string s converted to uppercase.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.upper()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Swap lower case letters and UPPER CASE</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">swapcase</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="string">"""swapcase(s) -&gt; string</span></span><br><span class="line"><span class="string">    返回的字符串s的副本,大写字符转换为小写，反之亦然。</span></span><br><span class="line"><span class="string">    Return a copy of the string s with upper case characters</span></span><br><span class="line"><span class="string">    converted to lowercase and vice versa.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.swapcase()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Strip leading and trailing tabs and spaces</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strip</span><span class="params">(s, chars=None)</span>:</span></span><br><span class="line">    <span class="string">"""strip(s [,chars]) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s的副本，开头和结尾的空格去掉。</span></span><br><span class="line"><span class="string">    如果chars给出，删除s开头和结尾的chars字符串，如string.strip("as1asdgas","as"),输出为：1asdg</span></span><br><span class="line"><span class="string">    Return a copy of the string s with leading and trailing</span></span><br><span class="line"><span class="string">    whitespace removed.</span></span><br><span class="line"><span class="string">    If chars is given and not None, remove characters in chars instead.</span></span><br><span class="line"><span class="string">    If chars is unicode, S will be converted to unicode before stripping.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.strip(chars)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Strip leading tabs and spaces</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstrip</span><span class="params">(s, chars=None)</span>:</span></span><br><span class="line">    <span class="string">"""lstrip(s [,chars]) -&gt; string</span></span><br><span class="line"><span class="string">    返回的字符串s的副本,开头空格删除。</span></span><br><span class="line"><span class="string">    如果字符给出，而不是None，删除s开头的chars字符串。如string.lstrip("as1asdgas","as"),输出为：1asdgas</span></span><br><span class="line"><span class="string">    Return a copy of the string s with leading whitespace removed.</span></span><br><span class="line"><span class="string">    If chars is given and not None, remove characters in chars instead.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.lstrip(chars)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Strip trailing tabs and spaces</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rstrip</span><span class="params">(s, chars=None)</span>:</span></span><br><span class="line">    <span class="string">"""rstrip(s [,chars]) -&gt; string</span></span><br><span class="line"><span class="string">    返回的字符串s的副本,结尾空格删除。</span></span><br><span class="line"><span class="string">    如果字符给出，而不是None，删除s结尾的chars字符串。如string.rstrip("as1asdgas","as"),输出为：as1asdg</span></span><br><span class="line"><span class="string">    Return a copy of the string s with trailing whitespace removed.</span></span><br><span class="line"><span class="string">    If chars is given and not None, remove characters in chars instead.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.rstrip(chars)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Split a string into a list of space/tab-separated words</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split</span><span class="params">(s, sep=None, maxsplit=<span class="number">-1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""split(s [,sep [,maxsplit]]) -&gt; list of strings</span></span><br><span class="line"><span class="string">    返回字符串s中单词的列表，用sep作为字符串的分隔符。如果maxsplit给出，分割在不超过第</span></span><br><span class="line"><span class="string">    maxsplit个分隔符的位置（结果至多为maxsplit+ 1个单词）。如果sep未指定或为None，以空白字符串作为分隔符。</span></span><br><span class="line"><span class="string">    如string.split("a  ds sd"),输出为['a','ds','sd']</span></span><br><span class="line"><span class="string">    string.split("a  ds sd",maxsplit=1),输出为['a','ds sd']</span></span><br><span class="line"><span class="string">    Return a list of the words in the string s, using sep as the</span></span><br><span class="line"><span class="string">    delimiter string.  If maxsplit is given, splits at no more than</span></span><br><span class="line"><span class="string">    maxsplit places (resulting in at most maxsplit+1 words).  If sep</span></span><br><span class="line"><span class="string">    is not specified or is None, any whitespace string is a separator.</span></span><br><span class="line"><span class="string">    (split and splitfields are synonymous)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.split(sep, maxsplit)</span><br><span class="line">splitfields = split</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split a string into a list of space/tab-separated words</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rsplit</span><span class="params">(s, sep=None, maxsplit=<span class="number">-1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""rsplit(s [,sep [,maxsplit]]) -&gt; list of strings</span></span><br><span class="line"><span class="string">    返回字符串s中单词的列表，用sep作为字符串的分隔符,分割符从字符串s尾部开始算起。如果maxsplit给出，分割在不超过第</span></span><br><span class="line"><span class="string">    maxsplit个分隔符的位置（结果至多为maxsplit+ 1个单词）。如果sep未指定或为None，以空白字符串作为分隔符。</span></span><br><span class="line"><span class="string">    如string.rsplit("a  ds sd"),输出为['a','ds','sd']</span></span><br><span class="line"><span class="string">    string.rsplit("a  ds sd",maxsplit=1),输出为['a ds','sd']</span></span><br><span class="line"><span class="string">    Return a list of the words in the string s, using sep as the</span></span><br><span class="line"><span class="string">    delimiter string, starting at the end of the string and working</span></span><br><span class="line"><span class="string">    to the front.  If maxsplit is given, at most maxsplit splits are</span></span><br><span class="line"><span class="string">    done. If sep is not specified or is None, any whitespace string</span></span><br><span class="line"><span class="string">    is a separator.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.rsplit(sep, maxsplit)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Join fields with optional separator</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span><span class="params">(words, sep = <span class="string">' '</span>)</span>:</span></span><br><span class="line">    <span class="string">"""join(list [,sep]) -&gt; string</span></span><br><span class="line"><span class="string">    返回列表中的单词所组成字符串，以sep相串联。默认的分隔符是一个空格。</span></span><br><span class="line"><span class="string">    如string.join(["nice","to", "meet","you"])，输出为：nice to meet you</span></span><br><span class="line"><span class="string">    Return a string composed of the words in list, with</span></span><br><span class="line"><span class="string">    intervening occurrences of sep.  The default separator is a</span></span><br><span class="line"><span class="string">    single space.</span></span><br><span class="line"><span class="string">    (joinfields and join are synonymous)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> sep.join(words)</span><br><span class="line">joinfields = join</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find substring, raise exception if not found</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(s, *args)</span>:</span></span><br><span class="line">    <span class="string">"""index(s, sub [,start [,end]]) -&gt; int</span></span><br><span class="line"><span class="string">    类似find，但是没有找到子串时引发ValueError错误。返回子串出现的首位置，否则报错。</span></span><br><span class="line"><span class="string">    如string.index("a sd fg a","a"),输出为：0</span></span><br><span class="line"><span class="string">    如string.index("a sd fg a fg","sdsdfg"[4:5]),输出为:5</span></span><br><span class="line"><span class="string">    Like find but raises ValueError when the substring is not found.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.index(*args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find last substring, raise exception if not found</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rindex</span><span class="params">(s, *args)</span>:</span></span><br><span class="line">    <span class="string">"""rindex(s, sub [,start [,end]]) -&gt; int</span></span><br><span class="line"><span class="string">    类似rfind，但是没有找到子串时引发ValueError错误。返回子串出现的最后位置，否则报错。</span></span><br><span class="line"><span class="string">    如string.rindex("a sd fg a","a"),输出为：8</span></span><br><span class="line"><span class="string">    如string.rindex("a sd fg a fg","sdsdfg"[4:5]),输出为:10</span></span><br><span class="line"><span class="string">    Like rfind but raises ValueError when the substring is not found.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.rindex(*args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Count non-overlapping occurrences of substring</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span><span class="params">(s, *args)</span>:</span></span><br><span class="line">    <span class="string">"""count(s, sub[, start[,end]]) -&gt; int</span></span><br><span class="line"><span class="string">    返回字符串s[start:end]中的子串sub出现的次数.可选参数start和end都解释为片符号。</span></span><br><span class="line"><span class="string">    如string.count("a sd fg a","a"),输出为2</span></span><br><span class="line"><span class="string">    如string.count("a sd fg a fg","sdsdfg"[2:3]),输出为:1</span></span><br><span class="line"><span class="string">    Return the number of occurrences of substring sub in string</span></span><br><span class="line"><span class="string">    s[start:end].  Optional arguments start and end are</span></span><br><span class="line"><span class="string">    interpreted as in slice notation.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.count(*args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find substring, return -1 if not found</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(s, *args)</span>:</span></span><br><span class="line">    <span class="string">"""find(s, sub [,start [,end]]) -&gt; int</span></span><br><span class="line"><span class="string">    返回子串出现的首位置，子串包含在s[start,end]中(即子串sub长度不超过s).可选参数start和end都解释为片符号。不存在是返回-1</span></span><br><span class="line"><span class="string">    如string.find("a sd fg a","a"),输出为：0</span></span><br><span class="line"><span class="string">    如string.find("a sd fg a fg","sdsdfg"[4:5]),输出为:5</span></span><br><span class="line"><span class="string">    Return the lowest index in s where substring sub is found,</span></span><br><span class="line"><span class="string">    such that sub is contained within s[start,end].  Optional</span></span><br><span class="line"><span class="string">    arguments start and end are interpreted as in slice notation.</span></span><br><span class="line"><span class="string">    Return -1 on failure.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.find(*args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Find last substring, return -1 if not found</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rfind</span><span class="params">(s, *args)</span>:</span></span><br><span class="line">    <span class="string">"""rfind(s, sub [,start [,end]]) -&gt; int</span></span><br><span class="line"><span class="string">    返回子串出现的最后位置，子串包含在s[start,end]中(即子串sub长度不超过s).可选参数start和end都解释为片符号。不存在是返回-1</span></span><br><span class="line"><span class="string">    如string.rfind("a sd fg a","a"),输出为：8</span></span><br><span class="line"><span class="string">    如string.rfind("a sd fg a fg","sdsdfg"[4:5]),输出为:10</span></span><br><span class="line"><span class="string">    Return the highest index in s where substring sub is found,</span></span><br><span class="line"><span class="string">    such that sub is contained within s[start,end].  Optional</span></span><br><span class="line"><span class="string">    arguments start and end are interpreted as in slice notation.</span></span><br><span class="line"><span class="string">    Return -1 on failure.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.rfind(*args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for a bit of speed</span></span><br><span class="line">_float = float</span><br><span class="line">_int = int</span><br><span class="line">_long = long</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert string to float</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">atof</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="string">"""atof(s) -&gt; float</span></span><br><span class="line"><span class="string">    Return the floating point number represented by the string s.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _float(s)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert string to integer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">atoi</span><span class="params">(s , base=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="string">"""atoi(s [,base]) -&gt; int</span></span><br><span class="line"><span class="string">    Return the integer represented by the string s in the given</span></span><br><span class="line"><span class="string">    base, which defaults to 10.  The string s must consist of one</span></span><br><span class="line"><span class="string">    or more digits, possibly preceded by a sign.  If base is 0, it</span></span><br><span class="line"><span class="string">    is chosen from the leading characters of s, 0 for octal, 0x or</span></span><br><span class="line"><span class="string">    0X for hexadecimal.  If base is 16, a preceding 0x or 0X is</span></span><br><span class="line"><span class="string">    accepted.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _int(s, base)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert string to long integer</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">atol</span><span class="params">(s, base=<span class="number">10</span>)</span>:</span></span><br><span class="line">    <span class="string">"""atol(s [,base]) -&gt; long</span></span><br><span class="line"><span class="string">    Return the long integer represented by the string s in the</span></span><br><span class="line"><span class="string">    given base, which defaults to 10.  The string s must consist</span></span><br><span class="line"><span class="string">    of one or more digits, possibly preceded by a sign.  If base</span></span><br><span class="line"><span class="string">    is 0, it is chosen from the leading characters of s, 0 for</span></span><br><span class="line"><span class="string">    octal, 0x or 0X for hexadecimal.  If base is 16, a preceding</span></span><br><span class="line"><span class="string">    0x or 0X is accepted.  A trailing L or l is not accepted,</span></span><br><span class="line"><span class="string">    unless base is 0.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _long(s, base)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Left-justify a string</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ljust</span><span class="params">(s, width, *args)</span>:</span></span><br><span class="line">    <span class="string">"""ljust(s, width[, fillchar]) -&gt; string</span></span><br><span class="line"><span class="string">    返回s的左对齐的版本，在该场指定宽度，可以根据需要用空格填充。该字符串不会被截断。如果指定了fillchar,以此代替空格。</span></span><br><span class="line"><span class="string">    如string.ljust(" adf", 8,"s"),输出为： adfssss</span></span><br><span class="line"><span class="string">    如string.ljust(" adfsfsfsfa", 3,"s"),(体现出不被截断)输出为 adfsfsfsfa</span></span><br><span class="line"><span class="string">    Return a left-justified version of s, in a field of the</span></span><br><span class="line"><span class="string">    specified width, padded with spaces as needed.  The string is</span></span><br><span class="line"><span class="string">    never truncated.  If specified the fillchar is used instead of spaces.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.ljust(width, *args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Right-justify a string</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rjust</span><span class="params">(s, width, *args)</span>:</span></span><br><span class="line">    <span class="string">"""rjust(s, width[, fillchar]) -&gt; string</span></span><br><span class="line"><span class="string">    返回s的右对齐的版本，在该场指定宽度，可以根据需要用空格填充。该字符串不会被截断。如果指定了fillchar,以此代替空格。</span></span><br><span class="line"><span class="string">    如string.rjust(" adf", 8,"s"),输出为：ssss adf</span></span><br><span class="line"><span class="string">    如string.rjust(" adfsfsfsfa", 3,"s"),(体现出不被截断)输出为 adfsfsfsfa</span></span><br><span class="line"><span class="string">    Return a right-justified version of s, in a field of the</span></span><br><span class="line"><span class="string">    specified width, padded with spaces as needed.  The string is</span></span><br><span class="line"><span class="string">    never truncated.  If specified the fillchar is used instead of spaces.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.rjust(width, *args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Center a string</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">center</span><span class="params">(s, width, *args)</span>:</span></span><br><span class="line">    <span class="string">"""center(s, width[, fillchar]) -&gt; string</span></span><br><span class="line"><span class="string">    返回s的中心对齐的版本，在该场指定宽度，可以根据需要用空格填充。该字符串不会被截断。如果指定了fillchar,以此代替空格。</span></span><br><span class="line"><span class="string">    如string.center(" adf", 9,"s"),输出为：sss adfss</span></span><br><span class="line"><span class="string">    如string.center(" adfsfsfsfa", 3,"s"),(体现出不被截断)输出为 adfsfsfsfa</span></span><br><span class="line"><span class="string">    Return a center version of s, in a field of the specified</span></span><br><span class="line"><span class="string">    width. padded with spaces as needed.  The string is never</span></span><br><span class="line"><span class="string">    truncated.  If specified the fillchar is used instead of spaces.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.center(width, *args)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Zero-fill a number, e.g., (12, 3) --&gt; '012' and (-3, 3) --&gt; '-03'</span></span><br><span class="line"><span class="comment"># Decadent feature: the argument may be a string or a number</span></span><br><span class="line"><span class="comment"># (Use of this is deprecated; it should be a string as with ljust c.s.)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">zfill</span><span class="params">(x, width)</span>:</span></span><br><span class="line">    <span class="string">"""zfill(x, width) -&gt; string</span></span><br><span class="line"><span class="string">    在字符串x左边，填充0达到指定的宽度。该字符串x不会被截断。</span></span><br><span class="line"><span class="string">    如string.zfill(" adf", 9),输出为：00000 adf</span></span><br><span class="line"><span class="string">    Pad a numeric string x with zeros on the left, to fill a field</span></span><br><span class="line"><span class="string">    of the specified width.  The string x is never truncated.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(x, basestring):</span><br><span class="line">        x = repr(x)</span><br><span class="line">    <span class="keyword">return</span> x.zfill(width)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Expand tabs in a string.</span></span><br><span class="line"><span class="comment"># Doesn't take non-printing chars into account, but does understand \n.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">expandtabs</span><span class="params">(s, tabsize=<span class="number">8</span>)</span>:</span></span><br><span class="line">    <span class="string">"""expandtabs(s [,tabsize]) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s的副本，所有的制表符(tab)由适当数量的空格替代，取决于当前列和制表符大小（默认为8）</span></span><br><span class="line"><span class="string">    Return a copy of the string s with all tab characters replaced</span></span><br><span class="line"><span class="string">    by the appropriate number of spaces, depending on the current</span></span><br><span class="line"><span class="string">    column, and the tabsize (default 8).</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.expandtabs(tabsize)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Character translation through look-up table.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">translate</span><span class="params">(s, table, deletions=<span class="string">""</span>)</span>:</span></span><br><span class="line">    <span class="string">"""translate(s,table [,deletions]) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s的副本，可选参数deletions出现的所有字符被删除，剩下的字符通过给定的转换表来映射，</span></span><br><span class="line"><span class="string">    转换表必须是长度为256的字符串.deletions不允许Unicode字符串</span></span><br><span class="line"><span class="string">    如t=string.maketrans('abc','ABC'),string.translate("abc123",t,'12'),输出为：ABC3</span></span><br><span class="line"><span class="string">    Return a copy of the string s, where all characters occurring</span></span><br><span class="line"><span class="string">    in the optional argument deletions are removed, and the</span></span><br><span class="line"><span class="string">    remaining characters have been mapped through the given</span></span><br><span class="line"><span class="string">    translation table, which must be a string of length 256.  The</span></span><br><span class="line"><span class="string">    deletions argument is not allowed for Unicode strings.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> deletions <span class="keyword">or</span> table <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> s.translate(table, deletions)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Add s[:0] so that if s is Unicode and table is an 8-bit string,</span></span><br><span class="line">        <span class="comment"># table is converted to Unicode.  This means that table *cannot*</span></span><br><span class="line">        <span class="comment"># be a dictionary -- for that feature, use u.translate() directly.</span></span><br><span class="line">        <span class="keyword">return</span> s.translate(table + s[:<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Capitalize a string, e.g. "aBc  dEf" -&gt; "Abc  def".</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">capitalize</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="string">"""capitalize(s) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串s的副本，只有首字符大写</span></span><br><span class="line"><span class="string">    Return a copy of the string s with only its first character</span></span><br><span class="line"><span class="string">    capitalized.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.capitalize()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Substring replacement (global)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">replace</span><span class="params">(s, old, new, maxreplace=<span class="number">-1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""replace (str, old, new[, maxreplace]) -&gt; string</span></span><br><span class="line"><span class="string">    返回字符串str的副本，以子串new代替所有出现的子串old。如果可选参数maxreplace给出，只有第一个maxreplace出现的地方被替换</span></span><br><span class="line"><span class="string">    如string.replace("old ffa old fsda old", "old", "new",2),输出为：new ffa new fsda old</span></span><br><span class="line"><span class="string">    Return a copy of string str with all occurrences of substring</span></span><br><span class="line"><span class="string">    old replaced by new. If the optional argument maxreplace is</span></span><br><span class="line"><span class="string">    given, only the first maxreplace occurrences are replaced.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> s.replace(old, new, maxreplace)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Try importing optional built-in module "strop" -- if it exists,</span></span><br><span class="line"><span class="comment"># it redefines some string operations that are 100-1000 times faster.</span></span><br><span class="line"><span class="comment"># It also defines values for whitespace, lowercase and uppercase</span></span><br><span class="line"><span class="comment"># that match &lt;ctype.h&gt;'s definitions.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> strop <span class="keyword">import</span> maketrans, lowercase, uppercase, whitespace</span><br><span class="line">    letters = lowercase + uppercase</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="keyword">pass</span>                                          <span class="comment"># Use the original versions</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########################################################################</span></span><br><span class="line"><span class="comment"># the Formatter class</span></span><br><span class="line"><span class="comment"># see PEP 3101 for details and purpose of this class</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The hard parts are reused from the C implementation.  They're exposed as "_"</span></span><br><span class="line"><span class="comment"># prefixed methods of str and unicode.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The overall parser is implemented in str._formatter_parser.</span></span><br><span class="line"><span class="comment"># The field name parser is implemented in str._formatter_field_name_split</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Formatter</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">format</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> args:</span><br><span class="line">            <span class="keyword">raise</span> TypeError(<span class="string">"descriptor 'format' of 'Formatter' object "</span></span><br><span class="line">                            <span class="string">"needs an argument"</span>)</span><br><span class="line">        self, args = args[<span class="number">0</span>], args[<span class="number">1</span>:]  <span class="comment"># allow the "self" keyword be passed</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            format_string, args = args[<span class="number">0</span>], args[<span class="number">1</span>:] <span class="comment"># allow the "format_string" keyword be passed</span></span><br><span class="line">        <span class="keyword">except</span> IndexError:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">'format_string'</span> <span class="keyword">in</span> kwargs:</span><br><span class="line">                format_string = kwargs.pop(<span class="string">'format_string'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> TypeError(<span class="string">"format() missing 1 required positional "</span></span><br><span class="line">                                <span class="string">"argument: 'format_string'"</span>)</span><br><span class="line">        <span class="keyword">return</span> self.vformat(format_string, args, kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">vformat</span><span class="params">(self, format_string, args, kwargs)</span>:</span></span><br><span class="line">        used_args = set()</span><br><span class="line">        result = self._vformat(format_string, args, kwargs, used_args, <span class="number">2</span>)</span><br><span class="line">        self.check_unused_args(used_args, args, kwargs)</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_vformat</span><span class="params">(self, format_string, args, kwargs, used_args, recursion_depth)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> recursion_depth &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Max string recursion exceeded'</span>)</span><br><span class="line">        result = []</span><br><span class="line">        <span class="keyword">for</span> literal_text, field_name, format_spec, conversion <span class="keyword">in</span> \</span><br><span class="line">                self.parse(format_string):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># output the literal text</span></span><br><span class="line">            <span class="keyword">if</span> literal_text:</span><br><span class="line">                result.append(literal_text)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if there's a field, output it</span></span><br><span class="line">            <span class="keyword">if</span> field_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">                <span class="comment"># this is some markup, find the object and do</span></span><br><span class="line">                <span class="comment">#  the formatting</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># given the field_name, find the object it references</span></span><br><span class="line">                <span class="comment">#  and the argument it came from</span></span><br><span class="line">                obj, arg_used = self.get_field(field_name, args, kwargs)</span><br><span class="line">                used_args.add(arg_used)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># do any conversion on the resulting object</span></span><br><span class="line">                obj = self.convert_field(obj, conversion)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># expand the format spec, if needed</span></span><br><span class="line">                format_spec = self._vformat(format_spec, args, kwargs,</span><br><span class="line">                                            used_args, recursion_depth<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># format the object and append to the result</span></span><br><span class="line">                result.append(self.format_field(obj, format_spec))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_value</span><span class="params">(self, key, args, kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(key, (int, long)):</span><br><span class="line">            <span class="keyword">return</span> args[key]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> kwargs[key]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">check_unused_args</span><span class="params">(self, used_args, args, kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">format_field</span><span class="params">(self, value, format_spec)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> format(value, format_spec)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">convert_field</span><span class="params">(self, value, conversion)</span>:</span></span><br><span class="line">        <span class="comment"># do any conversion on the resulting object</span></span><br><span class="line">        <span class="keyword">if</span> conversion <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> value</span><br><span class="line">        <span class="keyword">elif</span> conversion == <span class="string">'s'</span>:</span><br><span class="line">            <span class="keyword">return</span> str(value)</span><br><span class="line">        <span class="keyword">elif</span> conversion == <span class="string">'r'</span>:</span><br><span class="line">            <span class="keyword">return</span> repr(value)</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Unknown conversion specifier &#123;0!s&#125;"</span>.format(conversion))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># returns an iterable that contains tuples of the form:</span></span><br><span class="line">    <span class="comment"># (literal_text, field_name, format_spec, conversion)</span></span><br><span class="line">    <span class="comment"># literal_text can be zero length</span></span><br><span class="line">    <span class="comment"># field_name can be None, in which case there's no</span></span><br><span class="line">    <span class="comment">#  object to format and output</span></span><br><span class="line">    <span class="comment"># if field_name is not None, it is looked up, formatted</span></span><br><span class="line">    <span class="comment">#  with format_spec and conversion and then used</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, format_string)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> format_string._formatter_parser()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># given a field_name, find the object it references.</span></span><br><span class="line">    <span class="comment">#  field_name:   the field being looked up, e.g. "0.name"</span></span><br><span class="line">    <span class="comment">#                 or "lookup[3]"</span></span><br><span class="line">    <span class="comment">#  used_args:    a set of which args have been used</span></span><br><span class="line">    <span class="comment">#  args, kwargs: as passed in to vformat</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_field</span><span class="params">(self, field_name, args, kwargs)</span>:</span></span><br><span class="line">        first, rest = field_name._formatter_field_name_split()</span><br><span class="line"></span><br><span class="line">        obj = self.get_value(first, args, kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># loop through the rest of the field_name, doing</span></span><br><span class="line">        <span class="comment">#  getattr or getitem as needed</span></span><br><span class="line">        <span class="keyword">for</span> is_attr, i <span class="keyword">in</span> rest:</span><br><span class="line">            <span class="keyword">if</span> is_attr:</span><br><span class="line">                obj = getattr(obj, i)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                obj = obj[i]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> obj, first</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/12/Python/Python_File/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/12/Python/Python_File/" class="post-title-link" itemprop="url">python中对文件、文件夹操作</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-03-12 10:48:11 / Geändert am: 10:52:18" itemprop="dateCreated datePublished" datetime="2018-03-12T10:48:11+08:00">2018-03-12</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#python中对文件、文件夹操作</p>
<p><strong>python中对文件、文件夹（文件操作函数）的操作需要涉及到os模块和shutil模块。</strong></p>
<p>##os模块</p>
<p>得到当前工作目录，即当前Python脚本工作的目录路径: <strong>os.getcwd()</strong></p>
<p>返回指定目录下的所有文件和目录名:<strong>os.listdir()</strong></p>
<p>函数用来删除一个文件:<strong>os.remove()</strong></p>
<p>删除多个目录：<strong>os.removedirs（r“c：\python”）</strong></p>
<p>检验给出的路径是否是一个文件：<strong>os.path.isfile()</strong></p>
<p>检验给出的路径是否是一个目录：<strong>os.path.isdir()</strong></p>
<p>判断是否是绝对路径：<strong>os.path.isabs()</strong></p>
<p>检验给出的路径是否真地存:<strong>os.path.exists()</strong></p>
<p>返回一个路径的目录名和文件名:<strong>os.path.split()  </strong>   eg os.path.split(‘/home/swaroop/byte/code/poem.txt’) 结果：(‘/home/swaroop/byte/code’, ‘poem.txt’) </p>
<p>分离扩展名：<strong>os.path.splitext()</strong></p>
<p>获取路径名：<strong>os.path.dirname()</strong></p>
<p>获取文件名：<strong>os.path.basename()</strong></p>
<p>运行shell命令: <strong>os.system()</strong></p>
<p>读取和设置环境变量:<strong>os.getenv() 与os.putenv()</strong></p>
<p>给出当前平台使用的行终止符:<strong>os.linesep    </strong>Windows使用’\r\n’，Linux使用’\n’而Mac使用’\r’</p>
<p>指示你正在使用的平台：<strong>os.name </strong>      对于Windows，它是’nt’，而对于Linux/Unix用户，它是’posix’</p>
<p>重命名：<strong>os.rename（old， new）</strong></p>
<p>创建多级目录：<strong>os.makedirs（r“c：\python\test”）</strong></p>
<p>创建单个目录：<strong>os.mkdir（“test”）</strong></p>
<p>获取文件属性：<strong>os.stat（file）</strong></p>
<p>修改文件权限与时间戳：<strong>os.chmod（file）</strong></p>
<p>终止当前进程：<strong>os.exit（）</strong></p>
<p>获取文件大小：<strong>os.path.getsize（filename）</strong></p>
<p>##文件读写操作</p>
<p><strong>文件操作：os.mknod(“test.txt”) </strong>       创建空文件<br><strong>fp = open(“test.txt”,w)  </strong>   直接打开一个文件，如果文件不存在则创建文件</p>
<p>关于open 模式：</p>
<p>w     以写方式打开，<br>a     以追加模式打开 (从 EOF 开始, 必要时创建新文件)<br>r+     以读写模式打开<br>w+     以读写模式打开 (参见 w )<br>a+     以读写模式打开 (参见 a )<br>rb     以二进制读模式打开<br>wb     以二进制写模式打开 (参见 w )<br>ab     以二进制追加模式打开 (参见 a )<br>rb+    以二进制读写模式打开 (参见 r+ )<br>wb+    以二进制读写模式打开 (参见 w+ )<br>ab+    以二进制读写模式打开 (参见 a+ )</p>
<p><strong>fp.read([size])  </strong>                   #size为读取的长度，以byte为单位</p>
<p><strong>fp.readline([size])  </strong>               #读一行，如果定义了size，有可能返回的只是一行的一部分</p>
<p><strong>fp.readlines([size])   </strong>             #把文件每一行作为一个list的一个成员，并返回这个list。其实它的内部是通过循环调用readline()来实现的。如果提供size参数，size是表示读取内容的总长，也就是说可能只读到文件的一部分。</p>
<p><strong>fp.write(str)   </strong>                   #把str写到文件中，write()并不会在str后加上一个换行符</p>
<p><strong>fp.writelines(seq)    </strong>        #把seq的内容全部写到文件中(多行一次性写入)。这个函数也只是忠实地写入，不会在每行后面加上任何东西。</p>
<p><strong>fp.close()   </strong>                     #关闭文件。python会在一个文件不用后自动关闭文件，不过这一功能没有保证，最好还是养成自己关闭的习惯。  如果一个文件在关闭后还对其进行操作会产生ValueError</p>
<p><strong>fp.flush()   </strong>                                   #把缓冲区的内容写入硬盘</p>
<p><strong>fp.fileno()    </strong>                                  #返回一个长整型的”文件标签“</p>
<p><strong>fp.isatty()    </strong>                                  #文件是否是一个终端设备文件（unix系统中的）</p>
<p><strong>fp.tell()</strong>                                         #返回文件操作标记的当前位置，以文件的开头为原点</p>
<p><strong>fp.next()    </strong>                                   #返回下一行，并将文件操作标记位移到下一行。把一个file用于for … in file这样的语句时，就是调用next()函数来实现遍历的。</p>
<p><strong>fp.seek(offset[,whence])  </strong>            #将文件打操作标记移到offset的位置。这个offset一般是相对于文件的开头来计算的，一般为正数。但如果提供了whence参数就不一定了，whence可以为0表示从头开始计算，1表示以当前位置为原点计算。2表示以文件末尾为原点进行计算。需要注意，如果文件以a或a+的模式打开，每次进行写操作时，文件操作标记会自动返回到文件末尾。</p>
<p><strong>fp.truncate([size])   </strong>                    #把文件裁成规定的大小，默认的是裁到当前文件操作标记的位置。如果size比文件的大小还要大，依据系统的不同可能是不改变文件，也可能是用0把文件补到相应的大小，也可能是以一些随机的内容加上去。</p>
<h2 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h2><p><strong>目录操作：os.mkdir(“file”)     </strong>              创建目录<br>复制文件：<br><strong>shutil.copyfile(“oldfile”,”newfile”) </strong>      oldfile和newfile都只能是文件<br><strong>shutil.copy(“oldfile”,”newfile”)   </strong>         oldfile只能是文件夹，newfile可以是文件，也可以是目标目录<br>复制文件夹：<br><strong>shutil.copytree(“olddir”,”newdir”) </strong>       olddir和newdir都只能是目录，且newdir必须不存在<br>重命名文件（目录）<br><strong>os.rename(“oldname”,”newname”) </strong>      文件或目录都是使用这条命令<br>移动文件（目录）<br><strong>shutil.move(“oldpos”,”newpos”)   </strong><br>删除文件<br><strong>os.remove(“file”)</strong><br>删除目录<br><strong>os.rmdir(“dir”)</strong>只能删除空目录<br><strong>shutil.rmtree(“dir”)  </strong>  空目录、有内容的目录都可以删<br>转换目录<br><strong>os.chdir(“path”)   </strong>换路径</p>
<p><strong>相关例子 </strong></p>
<ul>
<li>将文件夹下所有图片名称加上’_fc’</li>
</ul>
<p><strong>python代码:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#str.split(string)分割字符串</span></span><br><span class="line"><span class="comment">#'连接符'.join(list) 将列表组成字符串</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">change_name</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> i</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(path) <span class="keyword">and</span> <span class="keyword">not</span> os.path.isfile(path):</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">    <span class="keyword">if</span> os.path.isfile(path):</span><br><span class="line">        file_path = os.path.split(path) <span class="comment">#分割出目录与文件</span></span><br><span class="line">        lists = file_path[<span class="number">1</span>].split(<span class="string">'.'</span>) <span class="comment">#分割出文件与文件扩展名</span></span><br><span class="line">        file_ext = lists[<span class="number">-1</span>] <span class="comment">#取出后缀名(列表切片操作)</span></span><br><span class="line">        img_ext = [<span class="string">'bmp'</span>,<span class="string">'jpeg'</span>,<span class="string">'gif'</span>,<span class="string">'psd'</span>,<span class="string">'png'</span>,<span class="string">'jpg'</span>]</span><br><span class="line">        <span class="keyword">if</span> file_ext <span class="keyword">in</span> img_ext:</span><br><span class="line">            os.rename(path,file_path[<span class="number">0</span>]+<span class="string">'/'</span>+lists[<span class="number">0</span>]+<span class="string">'_fc.'</span>+file_ext)</span><br><span class="line">            i+=<span class="number">1</span> <span class="comment">#注意这里的i是一个陷阱</span></span><br><span class="line">        <span class="comment">#或者</span></span><br><span class="line">        <span class="comment">#img_ext = 'bmp|jpeg|gif|psd|png|jpg'</span></span><br><span class="line">        <span class="comment">#if file_ext in img_ext:</span></span><br><span class="line">        <span class="comment">#    print('ok---'+file_ext)</span></span><br><span class="line">    <span class="keyword">elif</span> os.path.isdir(path):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> os.listdir(path):</span><br><span class="line">            change_name(os.path.join(path,x)) <span class="comment">#os.path.join()在路径处理上很有用</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    img_dir = <span class="string">'D:\\xx\\xx\\images'</span></span><br><span class="line">    img_dir = img_dir.replace(<span class="string">'\\'</span>,<span class="string">'/'</span>)</span><br><span class="line">    start = time.time()</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    change_name(img_dir)</span><br><span class="line">    c = time.time() - start</span><br><span class="line">    print(<span class="string">'程序运行耗时:%0.2f'</span>%(c))</span><br><span class="line">    print(<span class="string">'总共处理了 %s 张图片'</span>%(i))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<blockquote>
<p> 输出结果：</p>
<p>程序运行耗时:0.11<br>总共处理了 109 张图片</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/12/Python/Python_webbrowser/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/12/Python/Python_webbrowser/" class="post-title-link" itemprop="url">python之webbrowser</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-03-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-03-12T10:48:11+08:00">2018-03-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-10-12 17:13:24" itemprop="dateModified" datetime="2018-10-12T17:13:24+08:00">2018-10-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="python之webbrowser打开浏览器"><a href="#python之webbrowser打开浏览器" class="headerlink" title="python之webbrowser打开浏览器"></a>python之webbrowser打开浏览器</h1><h2 id="使用默认浏览器显示网址"><a href="#使用默认浏览器显示网址" class="headerlink" title="使用默认浏览器显示网址"></a>使用默认浏览器显示网址</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webbrowser.open(url, new=<span class="number">0</span>, autoraise=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<h2 id="在默认浏览器的新窗口中打开URL"><a href="#在默认浏览器的新窗口中打开URL" class="headerlink" title="在默认浏览器的新窗口中打开URL"></a>在默认浏览器的新窗口中打开URL</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webbrowser.open_new(url)</span><br></pre></td></tr></table></figure>
<h2 id="在默认浏览器的新页面（“标签”）中打开网址"><a href="#在默认浏览器的新页面（“标签”）中打开网址" class="headerlink" title="在默认浏览器的新页面（“标签”）中打开网址"></a>在默认浏览器的新页面（“标签”）中打开网址</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webbrowser.open_new_tab(url)</span><br></pre></td></tr></table></figure>
<h2 id="指定浏览器打开"><a href="#指定浏览器打开" class="headerlink" title="指定浏览器打开"></a>指定浏览器打开</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webbrowser.get(<span class="string">'chrome'</span>)</span><br></pre></td></tr></table></figure>
<p>如果name为空，则返回适用于调用者环境的默认浏览器的constructor</p>
<h2 id="注册浏览器类型名称。"><a href="#注册浏览器类型名称。" class="headerlink" title="注册浏览器类型名称。"></a>注册浏览器类型名称。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">webbrowser.register(name, constructor[, instance])</span><br></pre></td></tr></table></figure>
<p>注册浏览器类型后，get()函数可以返回该浏览器类型的constructor。如果未提供instance，或者为None，在需要时将在不使用参数的情况下调用constructor来创建实例。如果提供了实例，则永远不会调用constructor，并且可能为None</p>
<h2 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> webbrowser</span><br><span class="line"></span><br><span class="line">chromePath = <span class="string">r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe"</span></span><br><span class="line">webbrowser.register(<span class="string">'chrome1'</span>, <span class="keyword">None</span>, webbrowser.BackgroundBrowser(chromePath))</span><br><span class="line"></span><br><span class="line">browser = webbrowser.get(<span class="string">'chrome1'</span>)</span><br><span class="line">browser.open(<span class="string">'https://heroinlin.github.io/'</span>)</span><br><span class="line">browser.open_new(<span class="string">'https://heroinlin.github.io/'</span>)</span><br><span class="line">browser.open_new_tab(<span class="string">'https://heroinlin.github.io/'</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/12/Python/Python_shutil/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/12/Python/Python_shutil/" class="post-title-link" itemprop="url">python之Shutil</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-03-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-03-12T10:48:11+08:00">2018-03-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-10-12 15:08:00" itemprop="dateModified" datetime="2018-10-12T15:08:00+08:00">2018-10-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#python之Shutil文件、文件夹高级操作</p>
<h2 id="复制操作"><a href="#复制操作" class="headerlink" title="复制操作"></a>复制操作</h2><h3 id="copyfileobj"><a href="#copyfileobj" class="headerlink" title="copyfileobj"></a>copyfileobj</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copyfileobj(fsrc, fdst[, length=<span class="number">16</span>\*<span class="number">1024</span>])</span><br></pre></td></tr></table></figure>
<p>copy文件内容到另一个文件，可以copy指定大小的内容。这个方法是shutil模块中其它拷贝方法的基础，其它方法在本质上都是调用这个方法。</p>
<p>让我们看一下它的源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copyfileobj</span><span class="params">(fsrc, fdst, length=<span class="number">16</span>*<span class="number">1024</span>)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">        buf = fsrc.read(length)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> buf:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        fdst.write(buf)</span><br></pre></td></tr></table></figure>
<p>代码很简单，一看就懂。但是要注意，其中的fsrc，fdst都是使用open()方法打开后的文件对象。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">s =open(<span class="string">'fsrc.txt'</span>,<span class="string">'r'</span>)</span><br><span class="line">d=open(<span class="string">'fdst.txt'</span>,<span class="string">'w'</span>)</span><br><span class="line">shutil.copyfileobj(s,d,length=<span class="number">16</span>*<span class="number">1024</span>)</span><br></pre></td></tr></table></figure>
<h3 id="copyfile"><a href="#copyfile" class="headerlink" title="copyfile"></a>copyfile</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copyfile(src, dst)</span><br></pre></td></tr></table></figure>
<p>拷贝整个文件。同样看下它的源码，忽略前面一些检测用的代码，该方法的核心在最后几行，我们可以很清楚地看到<code>copyfile()</code>方法对<code>copyfileobj()</code>进行了调用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">copyfile</span><span class="params">(src, dst, *, follow_symlinks=True)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> _samefile(src, dst):</span><br><span class="line">        <span class="keyword">raise</span> SameFileError(<span class="string">"&#123;!r&#125; and &#123;!r&#125; are the same file"</span>.format(src, dst))</span><br><span class="line">    <span class="keyword">for</span> fn <span class="keyword">in</span> [src, dst]:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            st = os.stat(fn)</span><br><span class="line">        <span class="keyword">except</span> OSError:      </span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> stat.S_ISFIFO(st.st_mode):</span><br><span class="line">                <span class="keyword">raise</span> SpecialFileError(<span class="string">"`%s` is a named pipe"</span> % fn)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> follow_symlinks <span class="keyword">and</span> os.path.islink(src):</span><br><span class="line">        os.symlink(os.readlink(src), dst)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> open(src, <span class="string">'rb'</span>) <span class="keyword">as</span> fsrc:</span><br><span class="line">            <span class="keyword">with</span> open(dst, <span class="string">'wb'</span>) <span class="keyword">as</span> fdst:</span><br><span class="line">                copyfileobj(fsrc, fdst)</span><br><span class="line">    <span class="keyword">return</span> dst</span><br></pre></td></tr></table></figure>
<h3 id="copymode"><a href="#copymode" class="headerlink" title="copymode"></a>copymode</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copymode(src, dst)</span><br></pre></td></tr></table></figure>
<p>仅拷贝权限。内容、组、用户均不变。</p>
<h3 id="copystat"><a href="#copystat" class="headerlink" title="copystat"></a>copystat</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copystat(src, dst)</span><br></pre></td></tr></table></figure>
<p>仅复制所有的状态信息，包括权限，组，用户，时间等。</p>
<h3 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copy(src,dst)</span><br></pre></td></tr></table></figure>
<p>同时复制文件的内容以及权限，也就是先copyfile()然后copymode()。</p>
<h3 id="copy2"><a href="#copy2" class="headerlink" title="copy2"></a>copy2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.copy2(src, dst)</span><br></pre></td></tr></table></figure>
<p>同时复制文件的内容以及文件的所有状态信息。先copyfile()后copystat()。</p>
<h3 id="ignore-patterns"><a href="#ignore-patterns" class="headerlink" title="ignore_patterns"></a>ignore_patterns</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.ignore_patterns(*patterns)</span><br></pre></td></tr></table></figure>
<p>忽略指定的文件。通常配合下面的copytree()方法使用。</p>
<h3 id="copytree"><a href="#copytree" class="headerlink" title="copytree"></a>copytree</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shutil.copytree(src, dst, symlinks=<span class="keyword">False</span>,ignore=<span class="keyword">None</span>,copy_function=copy2,</span><br><span class="line">                ignore_dangling_symlinks=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>递归地复制目录及其子目录的文件和状态信息</p>
<ul>
<li>symlinks：指定是否复制软链接。小心陷入死循环。</li>
<li>ignore：指定不参与复制的文件，其值应该是一个ignore_patterns()方法。</li>
<li>copy_function：指定复制的模式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 典型用法</span></span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copytree, ignore_patterns</span><br><span class="line">copytree(source, destination, ignore=ignore_patterns(<span class="string">'*.pyc'</span>, <span class="string">'tmp*'</span>))</span><br><span class="line">copytree(<span class="string">'folder1'</span>, <span class="string">'folder2'</span>, ignore=ignore_patterns(<span class="string">'*.pyc'</span>, <span class="string">'tmp*'</span>))</span><br><span class="line">copytree(<span class="string">'f1'</span>, <span class="string">'f2'</span>, symlinks=<span class="keyword">True</span>, ignore=ignore_patterns(<span class="string">'*.pyc'</span>, <span class="string">'tmp*'</span>))</span><br></pre></td></tr></table></figure>
<h2 id="移动删除操作"><a href="#移动删除操作" class="headerlink" title="移动删除操作"></a>移动删除操作</h2><h3 id="rmtree"><a href="#rmtree" class="headerlink" title="rmtree"></a>rmtree</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.rmtree(path[, ignore_errors[, onerror]])</span><br></pre></td></tr></table></figure>
<p>递归地删除目录及子目录内的文件。注意！<strong>该方法不会询问yes或no，被删除的文件也不会出现在回收站里，请务必小心！</strong>此函数与类似<code>os.removedirs</code> ，但是<code>os.removedirs</code> 不能删除非空文件夹</p>
<p>下面的例子在碰到只读文件时，尝试清除只读属性，然后再删除。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, stat</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remove_readonly</span><span class="params">(func, path, _)</span>:</span></span><br><span class="line">    <span class="string">"去除文件的只读属性，尝试再次删除"</span></span><br><span class="line">    os.chmod(path, stat.S_IWRITE)</span><br><span class="line">    func(path)</span><br><span class="line">shutil.rmtree(directory, onerror=remove_readonly)</span><br></pre></td></tr></table></figure>
<h3 id="move"><a href="#move" class="headerlink" title="move"></a>move</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.move(src, dst)</span><br></pre></td></tr></table></figure>
<p>递归地移动文件，类似mv命令，其实就是重命名。</p>
<h2 id="which"><a href="#which" class="headerlink" title="which"></a>which</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.which(cmd)</span><br></pre></td></tr></table></figure>
<p>类似linux的<code>which</code>命令，返回执行该命令的程序路径。Python3.3新增</p>
<h2 id="disk-usage"><a href="#disk-usage" class="headerlink" title="disk_usage"></a>disk_usage</h2><p>检测磁盘使用信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.disk_usage(&quot;d:/&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="解压缩"><a href="#解压缩" class="headerlink" title="解压缩"></a>解压缩</h2><h3 id="get-archive-formats"><a href="#get-archive-formats" class="headerlink" title="get_archive_formats"></a>get_archive_formats</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.get_archive_formats()</span><br></pre></td></tr></table></figure>
<p>获取当前系统已注册的归档文件格式（后缀）</p>
<blockquote>
<p>[(‘bztar’, “bzip2’ed tar-file”), </p>
<p>(‘gztar’, “gzip’ed tar-file”), </p>
<p>(‘tar’, ‘uncompressed tar file’),</p>
<p> (‘xztar’, “xz’ed tar-file”), </p>
<p>(‘zip’, ‘ZIP file’)]</p>
</blockquote>
<h3 id="make-archive"><a href="#make-archive" class="headerlink" title="make_archive"></a>make_archive</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])</span><br></pre></td></tr></table></figure>
<p>创建归档或压缩文件。</p>
<ul>
<li><code>base_name</code>：压缩后的文件名。如果不指定绝对路径，则压缩文件保存在当前目录下。这个参数必须指定。</li>
<li><code>format</code>：压缩格式，可以是“zip”, “tar”, “bztar” ，“gztar”，“xztar”中的一种。这个参数也必须指定。</li>
<li><code>root_dir</code>：设置压缩包里的根目录，一般使用默认值，不特别指定。</li>
<li><code>base_dir</code>：要进行压缩的源文件或目录。</li>
<li><code>owner</code>：用户，默认当前用户。</li>
<li><code>group</code>：组，默认当前组。</li>
<li><code>logger</code>：用于记录日志，通常是<code>logging.Logger</code>对象。</li>
</ul>
<p>范例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">shutil.make_archive(<span class="string">"d:\\3"</span>, <span class="string">"zip"</span>,  base_dir=<span class="string">"d:\\1.txt"</span>)</span><br></pre></td></tr></table></figure>
<h3 id="get-unpack-formats"><a href="#get-unpack-formats" class="headerlink" title="get_unpack_formats"></a>get_unpack_formats</h3><p>获取当前系统已经注册的解包文件格式(后缀)</p>
<blockquote>
<p>[(‘bztar’, [‘.tar.bz2’, ‘.tbz2’], “bzip2’ed tar-file”), </p>
<p>(‘gztar’, [‘.tar.gz’, ‘.tgz’], “gzip’ed tar-file”), </p>
<p>(‘tar’, [‘.tar’], ‘uncompressed tar file’),</p>
<p> (‘xztar’, [‘.tar.xz’, ‘.txz’], “xz’ed tar-file”),</p>
<p> (‘zip’, [‘.zip’], ‘ZIP file’)]</p>
</blockquote>
<h3 id="unpack-archive"><a href="#unpack-archive" class="headerlink" title="unpack_archive"></a>unpack_archive</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shutil.unpack_archive(filename[, extract_dir[, format]])</span><br></pre></td></tr></table></figure>
<p>解压缩或解包源文件。</p>
<ul>
<li>filename是压缩文档的完整路径</li>
<li>extract_dir是解压缩路径，默认为当前目录。</li>
<li>format是压缩格式。默认使用文件后缀名代码的压缩格式。</li>
</ul>
<p>范例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line">shutil.unpack_archive(<span class="string">"d:\\3.zip"</span>, <span class="string">"f:\\3"</span>, <span class="string">'zip'</span>)</span><br></pre></td></tr></table></figure>
<p>shutil模块的压缩和解压功能，在后台是通过调用zipfile和tarfile两个模块来进行的。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/03/07/C&C++/Debug_error_solution/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/03/07/C&C++/Debug_error_solution/" class="post-title-link" itemprop="url">C及C++编译时候出现的一些问题与解决方案</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-03-07 15:54:11" itemprop="dateCreated datePublished" datetime="2018-03-07T15:54:11+08:00">2018-03-07</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-12 10:54:18" itemprop="dateModified" datetime="2018-03-12T10:54:18+08:00">2018-03-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/C-C/" itemprop="url" rel="index"><span itemprop="name">C&C++</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="C及C-编译时候出现的一些问题与解决方案"><a href="#C及C-编译时候出现的一些问题与解决方案" class="headerlink" title="C及C++编译时候出现的一些问题与解决方案"></a>C及C++编译时候出现的一些问题与解决方案</h1><h2 id="字符串问题"><a href="#字符串问题" class="headerlink" title="字符串问题"></a>字符串问题</h2><ul>
<li><p>[no matching function for call to ‘std::basic_ofstream &gt;::basic_ofstream(std::string&amp;)’]<br>编译时候报错为no matching function for call to std::basic_ofstream&lt;char, std::char_traits<char> &gt;::basic_ofstream(std::string&amp;)</char></p>
<p>原因是C++的string类与C的字符串存在不同，一些函数无法将string类作为参数使用。</p>
<blockquote>
<p><a href="http://en.cppreference.com/w/cpp/io/basic_ofstream" target="_blank" rel="noopener"><code>std::ofstream</code></a> can only be constructed with a <code>std::string</code> if you have C++11 or higher. Typically that is done with <code>-std=c++11</code> (gcc, clang). If you do not have access to c++11 then you can use the <code>c_str()</code> function of <code>std::string</code> to pass a <code>const char *</code> to the <code>ofstream</code> constructor.</p>
</blockquote>
<p>解决方案：转换为C的字符串</p>
<p>1.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">char</span> filename[<span class="number">10</span>];  </span><br><span class="line"><span class="built_in">strcpy</span>(filename, <span class="string">"1.txt"</span>);  </span><br><span class="line">ifstream fin;  </span><br><span class="line">fin.open(filename);</span><br></pre></td></tr></table></figure>
<p>2.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="built_in">string</span> asegurado;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Nombre a agregar: "</span>;</span><br><span class="line">    <span class="built_in">cin</span> &gt;&gt; asegurado;</span><br><span class="line"></span><br><span class="line">    <span class="function">ofstream <span class="title">entrada</span><span class="params">(asegurado,<span class="string">""</span>)</span></span>;<span class="comment">/*编译报错*/</span></span><br><span class="line">    <span class="comment">//ofstream entrada(asegurado); // C++11 or higher</span></span><br><span class="line">	<span class="comment">//ofstream entrada(asegurado.c_str());  // C++03 or below</span></span><br><span class="line">    <span class="keyword">if</span> (entrada.fail())</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"El archivo no se creo correctamente"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/11/CS231n/CS231n_BP/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/02/11/CS231n/CS231n_BP/" class="post-title-link" itemprop="url">CS231n课程笔记翻译：反向传播笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-02-11 11:11:11" itemprop="dateCreated datePublished" datetime="2018-02-11T11:11:11+08:00">2018-02-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-26 08:53:14" itemprop="dateModified" datetime="2018-03-26T08:53:14+08:00">2018-03-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CS231n课程笔记翻译/" itemprop="url" rel="index"><span itemprop="name">CS231n课程笔记翻译</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CS231n课程笔记翻译：反向传播笔记"><a href="#CS231n课程笔记翻译：反向传播笔记" class="headerlink" title="CS231n课程笔记翻译：反向传播笔记"></a>CS231n课程笔记翻译：反向传播笔记</h1><h2 id="原文如下："><a href="#原文如下：" class="headerlink" title="原文如下："></a>原文如下：</h2><p>内容列表：</p>
<ul>
<li>简介</li>
<li>简单表达式和理解梯度</li>
<li>复合表达式，链式法则，反向传播</li>
<li>直观理解反向传播</li>
<li>模块：Sigmoid例子</li>
<li>反向传播实践：分段计算</li>
<li>回传流中的模式</li>
<li>用户向量化操作的梯度</li>
<li>小结</li>
</ul>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>目标</strong>：本节将帮助读者对<strong>反向传播</strong>形成直观而专业的理解。反向传播是利用<strong>链式法则</strong>递归计算表达式的梯度的方法。理解反向传播过程及其精妙之处，对于理解、实现、设计和调试神经网络非常<strong>关键</strong>。</p>
<p><strong>问题陈述</strong>：这节的核心问题是：给定函数$f(x)$，其中$x$是输入数据的向量，需要计算函数$f$关于$x$的梯度，也就是$\nabla f(x)$。</p>
<p><strong>目标</strong>：之所以关注上述问题，是因为在神经网络中$f(x)$对应的是损失函数（$L$），输入$x$里面包含训练数据和神经网络的权重。举个例子，损失函数可以是SVM的损失函数，输入则包含了训练数据$(x_i,y_i),i=1…N$、权重$W$和偏差$b$。注意训练集是给定的（在机器学习中通常都是这样），而权重是可以控制的变量。因此，即使能用反向传播计算输入数据$x_i$ 上的梯度，但在实践为了进行参数更新，通常也只计算参数（比如$W,b$）的梯度。然而$x_i$ 的梯度有时仍然是有用的：比如将神经网络所做的事情可视化便于直观理解的时候，就能用上。</p>
<p>如果读者之前对于利用链式法则计算偏微分已经很熟练，仍然建议浏览本篇笔记。因为它呈现了一个相对成熟的反向传播视角，在该视角中能看见基于实数值回路的反向传播过程，而对其细节的理解和收获将帮助读者更好地通过本课程。</p>
<h2 id="简单表达式和理解梯度"><a href="#简单表达式和理解梯度" class="headerlink" title="简单表达式和理解梯度"></a>简单表达式和理解梯度</h2><p>从简单表达式入手可以为复杂表达式打好符号和规则基础。先考虑一个简单的二元乘法函数$f(x,y)=xy$。对两个输入变量分别求偏导数还是很简单的：</p>
<center>$$\displaystyle f(x,y)=xy \to \frac {df}{dx}=y \quad \frac {df}{dy}=x$$</center>

<p><strong>解释</strong>：牢记这些导数的意义：函数变量在某个点周围的极小区域内变化，而导数就是变量变化导致的函数在该方向上的变化率。</p>
<p>注意等号左边的分号和等号右边的分号不同，不是代表分数。相反，这个符号表示操作符$\frac{d}{dx}$被应用于函数$f$，并返回一个不同的函数（导数）。对于上述公式，可以认为$h$值非常小，函数可以被一条直线近似，而导数就是这条直线的斜率。换句话说，每个变量的导数指明了整个表达式对于该变量的值的敏感程度。比如，若$x=4,y=-3$，则$f(x,y)=-12$，$x$的导数$\frac{\partial f}{\partial x}=-3$。这就说明如果将变量$x$的值变大一点，整个表达式的值就会变小（原因在于负号），而且变小的量是$x$变大的量的三倍。通过重新排列公式可以看到这一点（$f(x+h)=f(x)+h \frac{df(x)}{dx}$）。同样，因为$\frac{\partial f}{\partial y}=4$，可以知道如果将$y$的值增加$h$，那么函数的输出也将增加（原因在于正号），且增加量是$4h$。</p>
<blockquote>
<p>函数关于每个变量的导数指明了整个表达式对于该变量的敏感程度。</p>
</blockquote>
<p>如上所述，梯度$\nabla f$是偏导数的向量，所以有$\nabla f(x)=[\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}]=[y,x]$。即使是梯度实际上是一个向量，仍然通常使用类似“<em>x上的梯度</em>”的术语，而不是使用如“<em>x的偏导数</em>”的正确说法，原因是因为前者说起来简单。</p>
<p>我们也可以对加法操作求导：</p>
<center>$$\displaystyle f(x,y)=x+y \to \frac {df}{dx}=1\quad\frac {df}{dy}=1$$</center>

<p>这就是说，无论其值如何，$x,y$的导数均为1。这是有道理的，因为无论增加$x,y$中任一个的值，函数$f$的值都会增加，并且增加的变化率独立于$x,y$的具体值（情况和乘法操作不同）。取最大值操作也是常常使用的：</p>
<center>$$\displaystyle f(x,y)=max(x,y) \to \frac {df}{dx}=1 (x&gt;=y) \quad\frac {df}{dy}=1 (y&gt;=x)$$</center>

<p>上式是说，如果该变量比另一个变量大，那么梯度是1，反之为0。例如，若$x=4,y=2$，那么max是4，所以函数对于$y$就不敏感。也就是说，在$y$上增加$h$，函数还是输出为4，所以梯度是0：因为对于函数输出是没有效果的。当然，如果给$y$增加一个很大的量，比如大于2，那么函数$f$的值就变化了，但是导数并没有指明输入量有巨大变化情况对于函数的效果，他们只适用于输入量变化极小时的情况，因为定义已经指明：$lim_{h\to 0}$。</p>
<h2 id="使用链式法则计算复合表达式"><a href="#使用链式法则计算复合表达式" class="headerlink" title="使用链式法则计算复合表达式"></a>使用链式法则计算复合表达式</h2><p>现在考虑更复杂的包含多个函数的复合函数，比如$f(x,y,z)=(x+y)z$。虽然这个表达足够简单，可以直接微分，但是在此使用一种有助于读者直观理解反向传播的方法。将公式分成两部分：$q=x+y$和$f=qz$。在前面已经介绍过如何对这分开的两个公式进行计算，因为$f$是$q$和$z$相乘，所以$\displaystyle\frac{\partial f}{\partial q}=z,\frac{\partial f}{\partial z}=q$，又因为$q$是$x$加$y$，所以$\displaystyle\frac{\partial q}{\partial x}=1,\frac{\partial q}{\partial y}=1$。然而，并不需要关心中间量$q$的梯度，因为$\frac{\partial f}{\partial q}$没有用。相反，函数$f$关于$x,y,z$的梯度才是需要关注的。<strong>链式法则</strong>指出将这些梯度表达式链接起来的正确方式是相乘，比如$\displaystyle\frac{\partial f}{\partial x}=\frac{\partial f}{\partial q}\frac{\partial q}{\partial x}$。在实际操作中，这只是简单地将两个梯度数值相乘，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置输入值</span></span><br><span class="line">x = <span class="number">-2</span>; y = <span class="number">5</span>; z = <span class="number">-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行前向传播</span></span><br><span class="line">q = x + y <span class="comment"># q becomes 3</span></span><br><span class="line">f = q * z <span class="comment"># f becomes -12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行反向传播:</span></span><br><span class="line"><span class="comment"># 首先回传到 f = q * z</span></span><br><span class="line">dfdz = q <span class="comment"># df/dz = q, 所以关于z的梯度是3</span></span><br><span class="line">dfdq = z <span class="comment"># df/dq = z, 所以关于q的梯度是-4</span></span><br><span class="line"><span class="comment"># 现在回传到q = x + y</span></span><br><span class="line">dfdx = <span class="number">1.0</span> * dfdq <span class="comment"># dq/dx = 1. 这里的乘法是因为链式法则</span></span><br><span class="line">dfdy = <span class="number">1.0</span> * dfdq <span class="comment"># dq/dy = 1</span></span><br></pre></td></tr></table></figure>
<p>最后得到变量的梯度<strong>[dfdx, dfdy, dfdz]</strong>，它们告诉我们函数<strong>f</strong>对于变量<strong>[x, y, z]</strong>的敏感程度。这是一个最简单的反向传播。一般会使用一个更简洁的表达符号，这样就不用写<strong>df</strong>了。这就是说，用<strong>dq</strong>来代替<strong>dfdq</strong>，且总是假设梯度是关于最终输出的。</p>
<p>这次计算可以被可视化为如下计算线路图像：</p>
<p>————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/backprop/backprop_0.jpg?raw=true" width="350"></center><br>上图的真实值计算线路展示了计算的视觉化过程。<strong>前向传播</strong>从输入计算到输出（绿色），<strong>反向传播</strong>从尾部开始，根据链式法则递归地向前计算梯度（显示为红色），一直到网络的输入端。可以认为，梯度是从计算链路中回流。<br><br>————————————————————————————————————————<br><br>## 反向传播的直观理解<br><br>反向传播是一个优美的局部过程。在整个计算线路图中，每个门单元都会得到一些输入并立即计算两个东西：1. 这个门的输出值，和2.其输出值关于输入值的局部梯度。门单元完成这两件事是完全独立的，它不需要知道计算线路中的其他细节。然而，一旦前向传播完毕，在反向传播的过程中，门单元门将最终获得整个网络的最终输出值在自己的输出值上的梯度。链式法则指出，门单元应该将回传的梯度乘以它对其的输入的局部梯度，从而得到整个网络的输出对该门单元的每个输入值的梯度。<br><br>&gt; 这里对于每个输入的乘法操作是基于链式法则的。该操作让一个相对独立的门单元变成复杂计算线路中不可或缺的一部分，这个复杂计算线路可以是神经网络等。<br><br>下面通过例子来对这一过程进行理解。加法门收到了输入[-2, 5]，计算输出是3。既然这个门是加法操作，那么对于两个输入的局部梯度都是+1。网络的其余部分计算出最终值为-12。在反向传播时将递归地使用链式法则，算到加法门（是乘法门的输入）的时候，知道加法门的输出的梯度是-4。如果网络如果想要输出值更高，那么可以认为它会想要加法门的输出更小一点（因为负号），而且还有一个4的倍数。继续递归并对梯度使用链式法则，加法门拿到梯度，然后把这个梯度分别乘到每个输入值的局部梯度（就是让-4乘以<strong>x</strong>和<strong>y</strong>的局部梯度，x和y的局部梯度都是1，所以最终都是-4）。可以看到得到了想要的效果：如果<strong>x，y减小</strong>（它们的梯度为负），那么加法门的输出值减小，这会让乘法门的输出值增大。<br><br>因此，反向传播可以看做是门单元之间在通过梯度信号相互通信，只要让它们的输入沿着梯度方向变化，无论它们自己的输出值在何种程度上升或降低，都是为了让整个网络的输出值更高。<br><br>## 模块化：Sigmoid例子<br><br>上面介绍的门是相对随意的。任何可微分的函数都可以看做门。可以将多个门组合成一个门，也可以根据需要将一个函数分拆成多个门。现在看看一个表达式：<br><br><center>$$\displaystyle f(w,x)=\frac{1}{1+e^{-(w_0x_0+w_1x_1+w_2)}}$$</center>

<p>在后面的课程中可以看到，这个表达式描述了一个含输入<strong>x</strong>和权重<strong>w</strong>的2维的神经元，该神经元使用了<em>sigmoid激活</em>函数。但是现在只是看做是一个简单的输入为x和w，输出为一个数字的函数。这个函数是由多个门组成的。除了上文介绍的加法门，乘法门，取最大值门，还有下面这4种：</p>
<center>$$f(x) = \frac{1}{x} \hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = -1/x^2 $$<br>$$f_c(x) = c + x\hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = 1 $$<br>$$f(x) = e^x\hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = e^x$$<br>$$f_a(x) = ax\hspace{1in} \rightarrow \hspace{1in} \frac{df}{dx} = a$$ </center>

<p>其中，函数$f_c$使用对输入值进行了常量$c$将输入值扩大了常量$a$倍。它们是加法和乘法的特例，但是这里将其看做一元门单元，因为确实需要计算常量$c,a$的梯度。整个计算线路如下：</p>
<p>———————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/backprop/backprop_1.jpg?raw=true" width="400"></center>

<p>使用sigmoid激活函数的2维神经元的例子。输入是[x0, x1]，可学习的权重是[w0, w1, w2]。一会儿会看见，这个神经元对输入数据做点积运算，然后其激活数据被sigmoid函数挤压到0到1之间。</p>
<p>————————————————————————————————————————</p>
<p>在上面的例子中可以看见一个函数操作的长链条，链条上的门都对<strong>w</strong>和<strong>x</strong>的点积结果进行操作。该函数被称为sigmoid函数$\sigma (x)$。sigmoid函数关于其输入的求导是可以简化的(使用了在分子上先加后减1的技巧)：</p>
<center>$$\sigma(x) = \frac{1}{1+e^{-x}} \\\rightarrow \hspace{0.3in} \frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = \left( \frac{1 + e^{-x} - 1}{1 + e^{-x}} \right) \left( \frac{1}{1+e^{-x}} \right) = \left( 1 - \sigma(x) \right) \sigma(x)$$</center>

<p>可以看到梯度计算简单了很多。举个例子，sigmoid表达式输入为1.0，则在前向传播中计算出输出为0.73。根据上面的公式，局部梯度为(1-0.73)*0.73~=0.2，和之前的计算流程比起来，现在的计算使用一个单独的简单表达式即可。因此，在实际的应用中将这些操作装进一个单独的门单元中将会非常有用。该神经元反向传播的代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">w = [<span class="number">2</span>,<span class="number">-3</span>,<span class="number">-3</span>] <span class="comment"># 假设一些随机数据和权重</span></span><br><span class="line">x = [<span class="number">-1</span>, <span class="number">-2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">dot = w[<span class="number">0</span>]*x[<span class="number">0</span>] + w[<span class="number">1</span>]*x[<span class="number">1</span>] + w[<span class="number">2</span>]</span><br><span class="line">f = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-dot)) <span class="comment"># sigmoid函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对神经元反向传播</span></span><br><span class="line">ddot = (<span class="number">1</span> - f) * f <span class="comment"># 点积变量的梯度, 使用sigmoid函数求导</span></span><br><span class="line">dx = [w[<span class="number">0</span>] * ddot, w[<span class="number">1</span>] * ddot] <span class="comment"># 回传到x</span></span><br><span class="line">dw = [x[<span class="number">0</span>] * ddot, x[<span class="number">1</span>] * ddot, <span class="number">1.0</span> * ddot] <span class="comment"># 回传到w</span></span><br><span class="line"><span class="comment"># 完成！得到输入的梯度</span></span><br></pre></td></tr></table></figure>
<p><strong>实现提示：分段反向传播</strong>。上面的代码展示了在实际操作中，为了使反向传播过程更加简洁，把向前传播分成不同的阶段将是很有帮助的。比如我们创建了一个中间变量<strong>dot</strong>，它装着<strong>w</strong>和<strong>x</strong>的点乘结果。在反向传播的时，就可以（反向地）计算出装着<strong>w</strong>和<strong>x</strong>等的梯度的对应的变量（比如<strong>ddot</strong>，<strong>dx</strong>和<strong>dw</strong>）。</p>
<p>本节的要点就是展示反向传播的细节过程，以及前向传播过程中，哪些函数可以被组合成门，从而可以进行简化。知道表达式中哪部分的局部梯度计算比较简洁非常有用，这样他们可以“链”在一起，让代码量更少，效率更高。</p>
<h2 id="反向传播实践：分段计算"><a href="#反向传播实践：分段计算" class="headerlink" title="反向传播实践：分段计算"></a>反向传播实践：分段计算</h2><p>看另一个例子。假设有如下函数：</p>
<center>$$f(x,y) = \frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}$$</center>

<p>首先要说的是，这个函数完全没用，读者是不会用到它来进行梯度计算的，这里只是用来作为实践反向传播的一个例子，需要强调的是，如果对$x$或$y$进行微分运算，运算结束后会得到一个巨大而复杂的表达式。然而做如此复杂的运算实际上并无必要，因为我们不需要一个明确的函数来计算梯度，只需知道如何使用反向传播计算梯度即可。下面是构建前向传播的代码模式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">3</span> <span class="comment"># 例子数值</span></span><br><span class="line">y = <span class="number">-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">sigy = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-y)) <span class="comment"># 分子中的sigmoi          #(1)</span></span><br><span class="line">num = x + sigy <span class="comment"># 分子                                    #(2)</span></span><br><span class="line">sigx = <span class="number">1.0</span> / (<span class="number">1</span> + math.exp(-x)) <span class="comment"># 分母中的sigmoid         #(3)</span></span><br><span class="line">xpy = x + y                                              <span class="comment">#(4)</span></span><br><span class="line">xpysqr = xpy**<span class="number">2</span>                                          <span class="comment">#(5)</span></span><br><span class="line">den = sigx + xpysqr <span class="comment"># 分母                                #(6)</span></span><br><span class="line">invden = <span class="number">1.0</span> / den                                       <span class="comment">#(7)</span></span><br><span class="line">f = num * invden <span class="comment"># 搞定！                                 #(8)</span></span><br></pre></td></tr></table></figure>
<p>┗|｀O′|┛ 嗷~~，到了表达式的最后，就完成了前向传播。注意在构建代码s时创建了多个中间变量，每个都是比较简单的表达式，它们计算局部梯度的方法是已知的。这样计算反向传播就简单了：我们对前向传播时产生每个变量(<strong>sigy, num, sigx, xpy, xpysqr, den, invden</strong>)进行回传。我们会有同样数量的变量，但是都以<strong>d</strong>开头，用来存储对应变量的梯度。注意在反向传播的每一小块中都将包含了表达式的局部梯度，然后根据使用链式法则乘以上游梯度。对于每行代码，我们将指明其对应的是前向传播的哪部分。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回传 f = num * invden</span></span><br><span class="line">dnum = invden <span class="comment"># 分子的梯度                                         #(8)</span></span><br><span class="line">dinvden = num                                                     <span class="comment">#(8)</span></span><br><span class="line"><span class="comment"># 回传 invden = 1.0 / den </span></span><br><span class="line">dden = (<span class="number">-1.0</span> / (den**<span class="number">2</span>)) * dinvden                                <span class="comment">#(7)</span></span><br><span class="line"><span class="comment"># 回传 den = sigx + xpysqr</span></span><br><span class="line">dsigx = (<span class="number">1</span>) * dden                                                <span class="comment">#(6)</span></span><br><span class="line">dxpysqr = (<span class="number">1</span>) * dden                                              <span class="comment">#(6)</span></span><br><span class="line"><span class="comment"># 回传 xpysqr = xpy**2</span></span><br><span class="line">dxpy = (<span class="number">2</span> * xpy) * dxpysqr                                        <span class="comment">#(5)</span></span><br><span class="line"><span class="comment"># 回传 xpy = x + y</span></span><br><span class="line">dx = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line">dy = (<span class="number">1</span>) * dxpy                                                   <span class="comment">#(4)</span></span><br><span class="line"><span class="comment"># 回传 sigx = 1.0 / (1 + math.exp(-x))</span></span><br><span class="line">dx += ((<span class="number">1</span> - sigx) * sigx) * dsigx <span class="comment"># Notice += !! See notes below  #(3)</span></span><br><span class="line"><span class="comment"># 回传 num = x + sigy</span></span><br><span class="line">dx += (<span class="number">1</span>) * dnum                                                  <span class="comment">#(2)</span></span><br><span class="line">dsigy = (<span class="number">1</span>) * dnum                                                <span class="comment">#(2)</span></span><br><span class="line"><span class="comment"># 回传 sigy = 1.0 / (1 + math.exp(-y))</span></span><br><span class="line">dy += ((<span class="number">1</span> - sigy) * sigy) * dsigy                                 <span class="comment">#(1)</span></span><br><span class="line"><span class="comment"># 完成! 嗷~~</span></span><br></pre></td></tr></table></figure>
<p>需要注意的一些东西：</p>
<p><strong>对前向传播变量进行缓存</strong>：在计算反向传播时，前向传播过程中得到的一些中间变量非常有用。在实际操作中，最好代码实现对于这些中间变量的缓存，这样在反向传播的时候也能用上它们。如果这样做过于困难，也可以（但是浪费计算资源）重新计算它们。</p>
<p><strong>在不同分支的梯度要相加</strong>：如果变量x，y在前向传播的表达式中出现多次，那么进行反向传播的时候就要非常小心，使用<strong>+=</strong>而不是<strong>=</strong>来累计这些变量的梯度（不然就会造成覆写）。这是遵循了在微积分中的<em>多元链式法则</em>，该法则指出如果变量在线路中分支走向不同的部分，那么梯度在回传的时候，就应该进行累加。</p>
<h2 id="回传流中的模式"><a href="#回传流中的模式" class="headerlink" title="回传流中的模式"></a>回传流中的模式</h2><p>一个有趣的现象是在多数情况下，反向传播中的梯度可以被很直观地解释。例如神经网络中最常用的加法、乘法和取最大值这三个门单元，它们在反向传播过程中的行为都有非常简单的解释。先看下面这个例子：</p>
<p>——————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/backprop/backprop_2.jpg?raw=true" width="350"></center>

<p>一个展示反向传播的例子。加法操作将梯度相等地分发给它的输入。取最大操作将梯度路由给更大的输入。乘法门拿取输入激活数据，对它们进行交换，然后乘以梯度。</p>
<p>——————————————————————————————————————————</p>
<p>从上例可知：</p>
<p><strong>加法门单元</strong>把输出的梯度相等地分发给它所有的输入，这一行为与输入值在前向传播时的值无关。这是因为加法操作的局部梯度都是简单的+1，所以所有输入的梯度实际上就等于输出的梯度，因为乘以1.0保持不变。上例中，加法门把梯度2.00不变且相等地路由给了两个输入。</p>
<p><strong>取最大值门单元</strong>对梯度做路由。和加法门不同，取最大值门将梯度转给其中一个输入，这个输入是在前向传播中值最大的那个输入。这是因为在取最大值门中，最高值的局部梯度是1.0，其余的是0。上例中，取最大值门将梯度2.00转给了<strong>z</strong>变量，因为<strong>z</strong>的值比<strong>w</strong>高，于是<strong>w</strong>的梯度保持为0。</p>
<p><strong>乘法门单元</strong>相对不容易解释。它的局部梯度就是输入值，但是是相互交换之后的，然后根据链式法则乘以输出值的梯度。上例中，<strong>x</strong>的梯度是-4.00x2.00=-8.00。</p>
<p><em>非直观影响及其结果</em>。注意一种比较特殊的情况，如果乘法门单元的其中一个输入非常小，而另一个输入非常大，那么乘法门的操作将会不是那么直观：它将会把大的梯度分配给小的输入，把小的梯度分配给大的输入。在线性分类器中，权重和输入是进行点积$w^Tx_i$，这说明输入数据的大小对于权重梯度的大小有影响。例如，在计算过程中对所有输入数据样本$x_i$乘以1000，那么权重的梯度将会增大1000倍，这样就必须降低学习率来弥补。这就是为什么数据预处理关系重大，它即使只是有微小变化，也会产生巨大影响。对于梯度在计算线路中是如何流动的有一个直观的理解，可以帮助读者调试网络。</p>
<h2 id="用向量化操作计算梯度"><a href="#用向量化操作计算梯度" class="headerlink" title="用向量化操作计算梯度"></a>用向量化操作计算梯度</h2><p>上述内容考虑的都是单个变量情况，但是所有概念都适用于矩阵和向量操作。然而，在操作的时候要注意关注维度和转置操作。</p>
<p><strong>矩阵相乘的梯度</strong>：可能最有技巧的操作是矩阵相乘（也适用于矩阵和向量，向量和向量相乘）的乘法操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">W = np.random.randn(<span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line">X = np.random.randn(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">D = W.dot(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设我们得到了D的梯度</span></span><br><span class="line">dD = np.random.randn(*D.shape) <span class="comment"># 和D一样的尺寸</span></span><br><span class="line">dW = dD.dot(X.T) <span class="comment">#.T就是对矩阵进行转置</span></span><br><span class="line">dX = W.T.dot(dD)</span><br></pre></td></tr></table></figure>
<p><em>提示：要分析维度！</em>注意不需要去记忆<strong>dW</strong>和<strong>dX</strong>的表达，因为它们很容易通过维度推导出来。例如，权重的梯度dW的尺寸肯定和权重矩阵W的尺寸是一样的，而这又是由<strong>X</strong>和<strong>dD</strong>的矩阵乘法决定的（在上面的例子中<strong>X</strong>和<strong>W</strong>都是数字不是矩阵）。总有一个方式是能够让维度之间能够对的上的。例如，<strong>X</strong>的尺寸是[10x3]，<strong>dD</strong>的尺寸是[5x3]，如果你想要dW和W的尺寸是[5x10]，那就要<strong>dD.dot(X.T)</strong>。</p>
<p><strong>使用小而具体的例子</strong>：有些读者可能觉得向量化操作的梯度计算比较困难，建议是写出一个很小很明确的向量化例子，在纸上演算梯度，然后对其一般化，得到一个高效的向量化操作形式。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul>
<li>对梯度的含义有了直观理解，知道了梯度是如何在网络中反向传播的，知道了它们是如何与网络的不同部分通信并控制其升高或者降低，并使得最终输出值更高的。</li>
<li>讨论了<strong>分段计算</strong>在反向传播的实现中的重要性。应该将函数分成不同的模块，这样计算局部梯度相对容易，然后基于链式法则将其“链”起来。重要的是，不需要把这些表达式写在纸上然后演算它的完整求导公式，因为实际上并不需要关于输入变量的梯度的数学公式。只需要将表达式分成不同的可以求导的模块（模块可以是矩阵向量的乘法操作，或者取最大值操作，或者加法操作等），然后在反向传播中一步一步地计算梯度。</li>
</ul>
<p>在下节课中，将会开始定义神经网络，而反向传播使我们能高效计算神经网络各个节点关于损失函数的梯度。换句话说，我们现在已经准备好训练神经网络了，本课程最困难的部分已经过去了！ConvNets相比只是向前走了一小步。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.05767" target="_blank" rel="noopener"><strong>Automatic differentiation in machine learning: a survey</strong></a></li>
</ul>
<p><strong>反向传播笔记全文翻译完</strong>。</p>
<blockquote>
<p>译自斯坦福CS231n课程笔记<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/optimization-2/" target="_blank" rel="noopener"><strong>Backprop Note</strong></a>，课程教师<a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" target="_blank" rel="noopener"><strong>Andrej Karpathy</strong></a>授权翻译。本篇教程由<a href="https://www.zhihu.com/people/du-ke" target="_blank" rel="noopener">杜客</a>翻译完成，<a href="https://www.zhihu.com/people/kun-kun-97-81" target="_blank" rel="noopener">堃堃</a>和<a href="https://www.zhihu.com/people/hmonkey" target="_blank" rel="noopener">巩子嘉</a>进行校对修改。</p>
<p>知乎地址：<a href="https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21407711?refer=intelligentunit</a></p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/11/hello-world/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/02/11/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-02-11 11:11:11" itemprop="dateCreated datePublished" datetime="2018-02-11T11:11:11+08:00">2018-02-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-02 16:54:52" itemprop="dateModified" datetime="2018-03-02T16:54:52+08:00">2018-03-02</time>
              
            
          </span>

          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/11/CS231n/CS231n_Neural_Network1/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/02/11/CS231n/CS231n_Neural_Network1/" class="post-title-link" itemprop="url">CS231n课程笔记翻译：神经网络笔记1</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-02-11 11:11:11" itemprop="dateCreated datePublished" datetime="2018-02-11T11:11:11+08:00">2018-02-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-26 08:53:28" itemprop="dateModified" datetime="2018-03-26T08:53:28+08:00">2018-03-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CS231n课程笔记翻译/" itemprop="url" rel="index"><span itemprop="name">CS231n课程笔记翻译</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CS231n课程笔记翻译：神经网络笔记"><a href="#CS231n课程笔记翻译：神经网络笔记" class="headerlink" title="CS231n课程笔记翻译：神经网络笔记"></a>CS231n课程笔记翻译：神经网络笔记</h1><h2 id="原文如下"><a href="#原文如下" class="headerlink" title="原文如下"></a>原文如下</h2><p>内容列表：</p>
<ul>
<li>不用大脑做类比的快速简介</li>
<li>单个神经元建模<ul>
<li>生物动机和连接</li>
<li>作为线性分类器的单个神经元</li>
<li>常用的激活函数 </li>
</ul>
</li>
<li>神经网络结构<ul>
<li>层组织</li>
<li>前向传播计算例子</li>
<li>表达能力</li>
<li>设置层的数量和尺寸</li>
</ul>
</li>
<li>小节</li>
<li>参考文献</li>
</ul>
<h2 id="快速简介"><a href="#快速简介" class="headerlink" title="快速简介"></a>快速简介</h2><p>在不诉诸大脑的类比的情况下，依然是可以对神经网络算法进行介绍的。在线性分类一节中，在给出图像的情况下，是使用$s=Wx$来计算不同视觉类别的评分，其中$W$是一个矩阵，$x$是一个输入列向量，它包含了图像的全部像素数据。在使用数据库CIFAR-10的案例中，$x$是一个[3072x1]的列向量，$W$是一个[10x3072]的矩阵，所以输出的评分是一个包含10个分类评分的向量。</p>
<p>神经网络算法则不同，它的计算公式是$s=W_2max(0,W_1x)$。其中$W_1$的含义是这样的：举个例子来说，它可以是一个[100x3072]的矩阵，其作用是将图像转化为一个100维的过渡向量。函数$max(0,-)$是非线性的，它会作用到每个元素。这个非线性函数有多种选择，后续将会学到。但这个形式是一个最常用的选择，它就是简单地设置阈值，将所有小于0的值变成0。最终，矩阵$W_2$的尺寸是[10x100]，因此将得到10个数字，这10个数字可以解释为是分类的评分。注意非线性函数在计算上是至关重要的，如果略去这一步，那么两个矩阵将会合二为一，对于分类的评分计算将重新变成关于输入的线性函数。这个非线性函数就是<em>改变</em>的关键点。参数$W_1,W_2$将通过随机梯度下降来学习到，他们的梯度在反向传播过程中，通过链式法则来求导计算得出。</p>
<p>一个三层的神经网络可以类比地看做$s=W_3max(0,W_2max(0,W_1x))$，其中$W_1,W_2,W_3$是需要进行学习的参数。中间隐层的尺寸是网络的超参数，后续将学习如何设置它们。现在让我们先从神经元或者网络的角度理解上述计算。</p>
<h2 id="单个神经元建模"><a href="#单个神经元建模" class="headerlink" title="单个神经元建模"></a>单个神经元建模</h2><p>神经网络算法领域最初是被对生物神经系统建模这一目标启发，但随后与其分道扬镳，成为一个工程问题，并在机器学习领域取得良好效果。然而，讨论将还是从对生物系统的一个高层次的简略描述开始，因为神经网络毕竟是从这里得到了启发。</p>
<h3 id="生物动机与连接"><a href="#生物动机与连接" class="headerlink" title="生物动机与连接"></a>生物动机与连接</h3><p>大脑的基本计算单位是 <strong>神经元（neuron）</strong> 。人类的神经系统中大约有860亿个神经元，它们被大约10^14-10^15个 <strong>突触(synapses)</strong> 连接起来。下面图表的左边展示了一个生物学的神经元，右边展示了一个常用的数学模型。每个神经元都从它的 <strong>树突</strong> 获得输入信号，然后沿着它唯一的 <strong>轴突（axon）</strong> 产生输出信号。轴突在末端会逐渐分枝，通过突触和其他神经元的树突相连。</p>
<p>在神经元的计算模型中，沿着轴突传播的信号（比如$x_0$）将基于突触的突触强度（比如$w_0$），与其他神经元的树突进行乘法交互（比如$w_0x_0$）。其观点是，突触的强度（也就是权重$w$），是可学习的且可以控制一个神经元对于另一个神经元的影响强度（还可以控制影响方向：使其兴奋（正权重）或使其抑制（负权重））。在基本模型中，树突将信号传递到细胞体，信号在细胞体中相加。如果最终之和高于某个阈值，那么神经元将会<em>激活</em>，向其轴突输出一个峰值信号。在计算模型中，我们假设峰值信号的准确时间点不重要，是激活信号的频率在交流信息。基于这个<em>速率编码</em>的观点，将神经元的激活率建模为<strong>激活函数（activation function）$f$</strong>，它表达了轴突上激活信号的频率。由于历史原因，激活函数常常选择使用<strong>sigmoid函数$\sigma$ </strong>，该函数输入实数值（求和后的信号强度），然后将输入值压缩到0-1之间。在本节后面部分会看到这些激活函数的各种细节。</p>
<p>————————————————————————————————————————</p>
<table><tr><br><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_0.png?raw=true" width="200" border="0"></center></td><br><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_1.jpg?raw=true" width="200" border="0"></center></td><br></tr></table>

<p>左边是生物神经元，右边是数学模型。</p>
<p>————————————————————————————————————————</p>
<p>一个神经元前向传播的实例代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span><span class="params">(object)</span>:</span></span><br><span class="line">  <span class="comment"># ... </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    <span class="string">""" 假设输入和权重是1-D的numpy数组，偏差是一个数字 """</span></span><br><span class="line">    cell_body_sum = np.sum(inputs * self.weights) + self.bias</span><br><span class="line">    firing_rate = <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-cell_body_sum)) <span class="comment"># sigmoid激活函数</span></span><br><span class="line">    <span class="keyword">return</span> firing_rate</span><br></pre></td></tr></table></figure>
<p>换句话说，每个神经元都对它的输入和权重进行点积，然后加上偏差，最后使用非线性函数（或称为激活函数）。本例中使用的是sigmoid函数$\sigma(x)=1/(1+e^{-x})$。在本节的末尾部分将介绍不同激活函数的细节。</p>
<p><strong>粗糙模型</strong>：要注意这个对于生物神经元的建模是非常粗糙的：在实际中，有很多不同类型的神经元，每种都有不同的属性。生物神经元的树突可以进行复杂的非线性计算。突触并不就是一个简单的权重，它们是复杂的非线性动态系统。很多系统中，输出的峰值信号的精确时间点非常重要，说明速率编码的近似是不够全面的。鉴于所有这些已经介绍和更多未介绍的简化，如果你画出人类大脑和神经网络之间的类比，有神经科学背景的人对你的板书起哄也是非常自然的。如果你对此感兴趣，可以看看这份<a href="http://link.zhihu.com/?target=https%3A//physics.ucsd.edu/neurophysics/courses/physics_171/annurev.neuro.28.061604.135703.pdf" target="_blank" rel="noopener"><strong>评论</strong></a>或者最新的<a href="http://link.zhihu.com/?target=http%3A//www.sciencedirect.com/science/article/pii/S0959438814000130" target="_blank" rel="noopener"><strong>另一份</strong></a>。</p>
<h3 id="作为线性分类器的单个神经元"><a href="#作为线性分类器的单个神经元" class="headerlink" title="作为线性分类器的单个神经元"></a>作为线性分类器的单个神经元</h3><p>神经元模型的前向计算数学公式看起来可能比较眼熟。就像在线性分类器中看到的那样，神经元有能力“喜欢”（激活函数值接近1），或者不喜欢（激活函数值接近0）输入空间中的某些线性区域。因此，只要在神经元的输出端有一个合适的损失函数，就能让单个神经元变成一个线性分类器。</p>
<p><strong>二分类Softmax分类器</strong>   举例来说，可以把$\displaystyle\sigma(\Sigma_iw_ix_i+b)$看做其中一个分类的概率$P(y_i=1|x_i;w)$，其他分类的概率为$P(y_i=0|x_i;w)=1-P(y_i=1|x_i;w)$，因为它们加起来必须为1。根据这种理解，可以得到交叉熵损失，这个在线性分一节中已经介绍。然后将它最优化为二分类的Softmax分类器（也就是逻辑回归）。因为sigmoid函数输出限定在0-1之间，所以分类器做出预测的基准是神经元的输出是否大于0.5。</p>
<p><strong>二分类SVM分类器</strong>    或者可以在神经元的输出外增加一个最大边界折叶损失（max-margin hinge loss）函数，将其训练成一个二分类的支持向量机。</p>
<p><strong>理解正则化</strong>  在SVM/Softmax的例子中，正则化损失从生物学角度可以看做<em>逐渐遗忘</em>，因为它的效果是让所有突触权重$w$在参数更新过程中逐渐向着0变化。</p>
<blockquote>
<p>一个单独的神经元可以用来实现一个二分类分类器，比如二分类的Softmax或者SVM分类器。</p>
</blockquote>
<h3 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h3><p>每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。下面是在实践中可能遇到的几种激活函数：</p>
<p>————————————————————————————————————————</p>
<p><table><tr></tr></table></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_2.jpg?raw=true" width="200"></center></td></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_3.jpg?raw=true" width="200"></center></td><br><br>左边是Sigmoid非线性函数，将实数压缩到[0,1]之间。右边是tanh函数，将实数压缩到[-1,1]。</p>
<p>————————————————————————————————————————</p>
<p><strong>Sigmoid</strong>  sigmoid非线性函数的数学公式是$\displaystyle\sigma(x)=1/(1+e^{-x})$，函数图像如上图的左边所示。在前一节中已经提到过，它输入实数值并将其“挤压”到0到1范围内。更具体地说，很大的负数变成0，很大的正数变成1。在历史上，sigmoid函数非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活（0）到在求和后的最大频率处的完全饱和（<strong>saturated</strong>）的激活（1）。然而现在sigmoid函数已经不太受欢迎，实际很少使用了，这是因为它有两个主要缺点：</p>
<ul>
<li><em>Sigmoid函数饱和使梯度消失</em>。sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。</li>
<li><em>Sigmoid函数的输出不是零中心的</em>。这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^Tx+b$中每个元素都$x&gt;0$），那么关于$w$的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式$f$而定）。这将会导致梯度下降权重更新时出现z字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。</li>
</ul>
<p><strong>Tanh</strong>    tanh非线性函数图像如上图右边所示。它将实数值压缩到[-1,1]之间。和sigmoid神经元一样，它也存在饱和问题，但是和sigmoid神经元不同的是，它的输出是零中心的。因此，在实际操作中，<em>tanh非线性函数比sigmoid非线性函数更受欢迎</em>。注意tanh神经元是一个简单放大的sigmoid神经元，具体说来就是：$tanh(x)=2\sigma(2x)-1$。<br>————————————————————————————————————————</p>
<p><table><tr></tr></table></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_4.jpg?raw=true" width="200"></center></td></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_5.jpg?raw=true" width="200"></center></td><br><br>左边是ReLU（校正线性单元：Rectified Linear Unit）激活函数，当$x=0$时函数值为0。当$x&gt;0$函数的斜率为1。右边是从<a href="http://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%7Efritz/absps/imagenet.pdf" target="_blank" rel="noopener"><strong>Krizhevsky</strong></a> 等的论文中截取的图表，指明使用ReLU比使用tanh的收敛快6倍。</p>
<p>————————————————————————————————————————</p>
<p><strong>ReLU</strong>   在近些年ReLU变得非常流行。它的函数公式是$f(x)=max(0,x)$)。换句话说，这个激活函数就是一个关于0的阈值（如上图左侧）。使用ReLU有以下一些优缺点：</p>
<ul>
<li>优点：相较于sigmoid和tanh函数，ReLU对于随机梯度下降的收敛有巨大的加速作用（<a href="http://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%7Efritz/absps/imagenet.pdf" target="_blank" rel="noopener"><strong>Krizhevsky</strong></a> 等的论文指出有6倍之多）。据称这是由它的线性，非饱和的公式导致的。</li>
<li>优点：sigmoid和tanh神经元含有指数运算等耗费计算资源的操作，而ReLU可以简单地通过对一个矩阵进行阈值计算得到。</li>
<li>缺点：在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低。</li>
</ul>
<p><strong>Leaky ReLU</strong>    Leaky ReLU是为解决“ReLU死亡”问题的尝试。ReLU中当x&lt;0时，函数值为0。而Leaky ReLU则是给出一个很小的负数梯度值，比如0.01。所以其函数公式为</p>
<p><center>$$f(x)=1(x&lt;0)(\alpha x)+1(x&gt;=0)(x)$$</center><br>其中 $\alpha$是一个小的常量。有些研究者的论文指出这个激活函数表现很不错，但是其效果并不是很稳定。Kaiming He等人在2015年发布的论文<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.01852" target="_blank" rel="noopener"><strong>Delving Deep into Rectifiers</strong></a> 中介绍了一种新方法PReLU，把负区间上的斜率当做每个神经元中的一个参数。然而该激活函数在在不同任务中均有益处的一致性并没有特别清晰。</p>
<p><strong>Maxout</strong>      一些其他类型的单元被提了出来，它们对于权重和数据的内积结果不再使用$f(w^Tx+b)$函数形式。一个相关的流行选择是Maxout（最近由<a href="http://link.zhihu.com/?target=http%3A//www-etud.iro.umontreal.ca/%7Egoodfeli/maxout.html" target="_blank" rel="noopener"><strong>Goodfellow</strong></a> 等发布）神经元。Maxout是对ReLU和leaky ReLU的一般化归纳，它的函数是：$max(w^T_1x+b_1,w^T_2x+b_2)$。ReLU和Leaky ReLU都是这个公式的特殊情况（比如ReLU就是当$w_1,b_1=0$的时候）。这样Maxout神经元就拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。</p>
<p>以上就是一些常用的神经元及其激活函数。最后需要注意一点：在同一个网络中混合使用不同类型的神经元是非常少见的，虽然没有什么根本性问题来禁止这样做。</p>
<p><strong>一句话</strong>：“<em>那么该用那种呢？</em>”用ReLU非线性函数。注意设置好学习率，或许可以监控你的网络中死亡的神经元占的比例。如果单元死亡问题困扰你，就试试Leaky ReLU或者Maxout，不要再用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout。</p>
<h2 id="神经网络结构"><a href="#神经网络结构" class="headerlink" title="神经网络结构"></a>神经网络结构</h2><h3 id="灵活地组织层"><a href="#灵活地组织层" class="headerlink" title="灵活地组织层"></a>灵活地组织层</h3><p><strong>将神经网络算法以神经元的形式图形化</strong>    神经网络被建模成神经元的集合，神经元之间以无环图的形式进行连接。也就是说，一些神经元的输出是另一些神经元的输入。在网络中是不允许循环的，因为这样会导致前向传播的无限循环。通常神经网络模型中神经元是分层的，而不是像生物神经元一样聚合成大小不一的团状。对于普通神经网络，最普通的层的类型是<strong>全连接层（fully-connected layer）</strong>。全连接层中的神经元与其前后两层的神经元是完全成对连接的，但是在同一个全连接层内的神经元之间没有连接。下面是两个神经网络的图例，都使用的全连接层：</p>
<p>————————————————————————————————————————</p>
<p><table><tr></tr></table></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_6.jpg?raw=true" width="250"></center></td></p>
<p><td><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_7.jpg?raw=true" width="250"></center></td><br><br>左边是一个2层神经网络，隐层由4个神经元（也可称为单元（unit））组成，输出层由2个神经元组成，输入层是3个神经元。右边是一个3层神经网络，两个含4个神经元的隐层。注意：层与层之间的神经元是全连接的，但是层内的神经元不连接。</p>
<p>————————————————————————————————————————</p>
<p><strong>命名规则</strong>     当我们说N层神经网络的时候，我们没有把输入层算入。因此，单层的神经网络就是没有隐层的（输入直接映射到输出）。因此，有的研究者会说逻辑回归或者SVM只是单层神经网络的一个特例。研究者们也会使用<em>人工神经网络（</em>Artificial Neural Networks <em>缩写ANN）</em>或者<em>多层感知器（Multi-Layer Perceptrons 缩写MLP）</em>来指代神经网络。很多研究者并不喜欢神经网络算法和人类大脑之间的类比，他们更倾向于用<em>单元（unit）</em>而不是神经元作为术语。</p>
<p><strong>输出层</strong>    和神经网络中其他层不同，输出层的神经元一般是不会有激活函数的（或者也可以认为它们有一个线性相等的激活函数）。这是因为最后的输出层大多用于表示分类评分值，因此是任意值的实数，或者某种实数值的目标数（比如在回归中）。</p>
<p><strong>确定网络尺寸</strong>    用来度量神经网络的尺寸的标准主要有两个：一个是神经元的个数，另一个是参数的个数，用上面图示的两个网络举例：</p>
<ul>
<li>第一个网络有4+2=6个神经元（输入层不算），[3x4]+[4x2]=20个权重，还有4+2=6个偏置，共26个可学习的参数。</li>
<li>第二个网络有4+4+1=9个神经元，[3x4]+[4x4]+[4x1]=32个权重，4+4+1=9个偏置，共41个可学习的参数。</li>
</ul>
<p>为了方便对比，现代卷积神经网络能包含约1亿个参数，可由10-20层构成（这就是深度学习）。然而，<em>有效（effective）</em>连接的个数因为参数共享的缘故大大增多。在后面的卷积神经网络内容中我们将学习更多。</p>
<h3 id="前向传播计算举例"><a href="#前向传播计算举例" class="headerlink" title="前向传播计算举例"></a>前向传播计算举例</h3><p><em>不断重复的矩阵乘法与激活函数交织</em>。将神经网络组织成层状的一个主要原因，就是这个结构让神经网络算法使用矩阵向量操作变得简单和高效。用上面那个3层神经网络举例，输入是[3x1]的向量。一个层所有连接的强度可以存在一个单独的矩阵中。比如第一个隐层的权重<strong>W1</strong>是[4x3]，所有单元的偏置储存在<strong>b1</strong>中，尺寸[4x1]。这样，每个神经元的权重都在<strong>W1</strong>的一个行中，于是矩阵乘法<strong>np.dot(W1, x)</strong>就能计算该层中所有神经元的激活数据。类似的，<strong>W2</strong>将会是[4x4]矩阵，存储着第二个隐层的连接，<strong>W3</strong>是[1x4]的矩阵，用于输出层。完整的3层神经网络的前向传播就是简单的3次矩阵乘法，其中交织着激活函数的应用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个3层神经网络的前向传播:</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: <span class="number">1.0</span>/(<span class="number">1.0</span> + np.exp(-x)) <span class="comment"># 激活函数(用的sigmoid)</span></span><br><span class="line">x = np.random.randn(<span class="number">3</span>, <span class="number">1</span>) <span class="comment"># 含3个数字的随机输入向量(3x1)</span></span><br><span class="line">h1 = f(np.dot(W1, x) + b1) <span class="comment"># 计算第一个隐层的激活数据(4x1)</span></span><br><span class="line">h2 = f(np.dot(W2, h1) + b2) <span class="comment"># 计算第二个隐层的激活数据(4x1)</span></span><br><span class="line">out = np.dot(W3, h2) + b3 <span class="comment"># 神经元输出(1x1)</span></span><br></pre></td></tr></table></figure>
<p>在上面的代码中，<strong>W1，W2，W3，b1，b2，b3</strong>都是网络中可以学习的参数。注意<strong>x</strong>并不是一个单独的列向量，而可以是一个批量的训练数据（其中每个输入样本将会是<strong>x</strong>中的一列），所有的样本将会被并行化的高效计算出来。注意神经网络最后一层通常是没有激活函数的（例如，在分类任务中它给出一个实数值的分类评分）。</p>
<blockquote>
<p>全连接层的前向传播一般就是先进行一个矩阵乘法，然后加上偏置并运用激活函数。</p>
</blockquote>
<h3 id="表达能力"><a href="#表达能力" class="headerlink" title="表达能力"></a>表达能力</h3><p>理解具有全连接层的神经网络的一个方式是：可以认为它们定义了一个由一系列函数组成的函数族，网络的权重就是每个函数的参数。如此产生的问题是：该函数族的表达能力如何？存在不能被神经网络表达的函数吗？</p>
<p>现在看来，拥有至少一个隐层的神经网络是一个<em>通用的近似器</em>。在研究（例如1989年的论文<a href="http://link.zhihu.com/?target=http%3A//www.dartmouth.edu/%257Egvc/Cybenko_MCSS.pdf" target="_blank" rel="noopener"><strong>Approximation by Superpositions of Sigmoidal Function</strong></a> ，或者<a href="http://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/chap4.html" target="_blank" rel="noopener"><strong>Michael Nielsen</strong></a> 的这个直观解释。）中已经证明，给出任意连续函数$f(x)$和任意$\epsilon &gt;0$，均存在一个至少含1个隐层的神经网络$g(x)$（并且网络中有合理选择的非线性激活函数，比如sigmoid），对于$\forall x$，使得$|f(x)-g(x)|&lt;\epsilon$。换句话说，神经网络可以近似任何连续函数。</p>
<p>既然一个隐层就能近似任何函数，那为什么还要构建更多层来将网络做得更深？答案是：虽然一个2层网络在数学理论上能完美地近似所有连续函数，但在实际操作中效果相对较差。在一个维度上，虽然以$a,b,c$为参数向量“指示块之和”函数$g(x)=\sum_ic_i1(a_i&lt;x&lt;b_i) $也是通用的近似器，但是谁也不会建议在机器学习中使用这个函数公式。神经网络在实践中非常好用，是因为它们表达出的函数不仅平滑，而且对于数据的统计特性有很好的拟合。同时，网络通过最优化算法（例如梯度下降）能比较容易地学习到这个函数。类似的，虽然在理论上深层网络（使用了多个隐层）和单层网络的表达能力是一样的，但是就实践经验而言，深度网络效果比单层网络好。</p>
<p>另外，在实践中3层的神经网络会比2层的表现好，然而继续加深（做到4，5，6层）很少有太大帮助。卷积神经网络的情况却不同，在卷积神经网络中，对于一个良好的识别系统来说，深度是一个极端重要的因素（比如数十(以10为量级)个可学习的层）。对于该现象的一种解释观点是：因为图像拥有层次化结构（比如脸是由眼睛等组成，眼睛又是由边缘组成），所以多层处理对于这种数据就有直观意义。</p>
<p>全面的研究内容还很多，近期研究的进展也很多。如果你对此感兴趣，我么推荐你阅读下面文献：</p>
<ul>
<li><a href="http://link.zhihu.com/?target=http%3A//www.deeplearningbook.org/" target="_blank" rel="noopener"><strong>Deep Learning</strong></a> 的<a href="http://link.zhihu.com/?target=http%3A//www.deeplearningbook.org/contents/mlp.html" target="_blank" rel="noopener"><strong>Chapter6.4</strong></a> ，作者是Bengio等。</li>
<li><a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1312.6184" target="_blank" rel="noopener"><strong>Do Deep Nets Really Need to be Deep?</strong></a> </li>
<li><a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.6550" target="_blank" rel="noopener"><strong>FitNets: Hints for Thin Deep Nets</strong></a> </li>
</ul>
<h3 id="设置层的数量和尺寸"><a href="#设置层的数量和尺寸" class="headerlink" title="设置层的数量和尺寸"></a>设置层的数量和尺寸</h3><p>在面对一个具体问题的时候该确定网络结构呢？到底是不用隐层呢？还是一个隐层？两个隐层或更多？每个层的尺寸该多大？</p>
<p>首先，要知道当我们增加层的数量和尺寸时，网络的容量上升了。即神经元们可以合作表达许多复杂函数，所以表达函数的空间增加。例如，如果有一个在二维平面上的二分类问题。我们可以训练3个不同的神经网络，每个网络都只有一个隐层，但是每层的神经元数目不同：</p>
<p>————————————————————————————————————————</p>
<p><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_8.jpg?raw=true" width="400"></center><br>更大的神经网络可以表达更复杂的函数。数据是用不同颜色的圆点表示他们的不同类别，决策边界是由训练过的神经网络做出的。你可以在 <a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" target="_blank" rel="noopener"><strong>ConvNetsJS demo</strong></a> 上练练手。</p>
<p>————————————————————————————————————————</p>
<p>在上图中，可以看见有更多神经元的神经网络可以表达更复杂的函数。然而这既是优势也是不足，优势是可以分类更复杂的数据，不足是可能造成对训练数据的过拟合。<strong>过拟合（Overfitting）</strong> 是网络对数据中的噪声有很强的拟合能力，而没有重视数据间（假设）的潜在基本关系。举例来说，有20个神经元隐层的网络拟合了所有的训练数据，但是其代价是把决策边界变成了许多不相连的红绿区域。而有3个神经元的模型的表达能力只能用比较宽泛的方式去分类数据。它将数据看做是两个大块，并把个别在绿色区域内的红色点看做噪声。在实际中，这样可以在测试数据中获得更好的 <strong>泛化（generalization）</strong> 能力。</p>
<p>基于上面的讨论，看起来如果数据不是足够复杂，则似乎小一点的网络更好，因为可以防止过拟合。然而并非如此，防止神经网络的过拟合有很多方法（L2正则化，dropout和输入噪音等），后面会详细讨论。在实践中，使用这些方法来控制过拟合比减少网络神经元数目要好得多。</p>
<p>不要减少网络神经元数目的主要原因在于小网络更难使用梯度下降等局部方法来进行训练：虽然小型网络的损失函数的局部极小值更少，也比较容易收敛到这些局部极小值，但是这些最小值一般都很差，损失值很高。相反，大网络拥有更多的局部极小值，但就实际损失值来看，这些局部极小值表现更好，损失更小。因为神经网络是非凸的，就很难从数学上研究这些特性。即便如此，还是有一些文章尝试对这些目标函数进行理解，例如<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1412.0233" target="_blank" rel="noopener"><strong>The Loss Surfaces of Multilayer Networks</strong></a> 这篇论文。在实际中，你将发现如果训练的是一个小网络，那么最终的损失值将展现出多变性：某些情况下运气好会收敛到一个好的地方，某些情况下就收敛到一个不好的极值。从另一方面来说，如果你训练一个大的网络，你将发现许多不同的解决方法，但是最终损失值的差异将会小很多。这就是说，所有的解决办法都差不多，而且对于随机初始化参数好坏的依赖也会小很多。</p>
<p>重申一下，正则化强度是控制神经网络过拟合的好方法。看下图结果：</p>
<p>————————————————————————————————————————</p>
<p><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_9.jpg?raw=true" width="400"></center><br>不同正则化强度的效果：每个神经网络都有20个隐层神经元，但是随着正则化强度增加，它的决策边界变得更加平滑。你可以在 <a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html" target="_blank" rel="noopener"><strong>ConvNetsJS demo</strong></a> 上练练手。</p>
<p>————————————————————————————————————————</p>
<p>需要记住的是：不应该因为害怕出现过拟合而使用小网络。相反，应该进尽可能使用大网络，然后使用正则化技巧来控制过拟合。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>小结如下：</p>
<ul>
<li><p>介绍了生物神经元的粗略模型；</p>
</li>
<li><p>讨论了几种不同类型的激活函数，其中ReLU是最佳推荐；</p>
</li>
<li><p>介绍了<strong>神经网络</strong>，神经元通过<strong>全连接层</strong>连接，层间神经元两两相连，但是层内神经元不连接；</p>
</li>
<li><p>理解了分层的结构能够让神经网络高效地进行矩阵乘法和激活函数运算；</p>
</li>
<li><p>理解了神经网络是一个<strong>通用函数近似器</strong>，但是该性质与其广泛使用无太大关系。之所以使用神经网络，是因为它们对于实际问题中的函数的公式能够某种程度上做出“正确”假设。</p>
</li>
<li><p>讨论了更大网络总是更好的这一事实。然而更大容量的模型一定要和更强的正则化（比如更高的权重衰减）配合，否则它们就会过拟合。在后续章节中我们讲学习更多正则化的方法，尤其是dropout。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1></li>
<li><p>使用Theano的<a href="http://link.zhihu.com/?target=http%3A//www.deeplearning.net/tutorial/mlp.html" target="_blank" rel="noopener"><strong>deeplearning.net tutorial</strong></a></p>
</li>
<li><p><a href="http://link.zhihu.com/?target=http%3A//www.deeplearning.net/tutorial/mlp.html" target="_blank" rel="noopener"><strong>ConvNetJS</strong></a></p>
</li>
<li><p><a href="http://link.zhihu.com/?target=http%3A//neuralnetworksanddeeplearning.com/chap1.html" target="_blank" rel="noopener"><strong>Michael Nielsen’s tutorials</strong></a></p>
</li>
</ul>
<blockquote>
<p>译自斯坦福CS231n课程笔记<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-1/" target="_blank" rel="noopener"><strong>Neural Nets notes 1</strong></a> ，课程教师<a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" target="_blank" rel="noopener"><strong>Andrej Karpathy</strong></a> 授权翻译。本篇教程由<a href="https://www.zhihu.com/people/du-ke" target="_blank" rel="noopener">杜客</a>翻译完成，<a href="https://www.zhihu.com/people/hmonkey" target="_blank" rel="noopener">巩子嘉</a>和<a href="https://www.zhihu.com/people/kun-kun-97-81" target="_blank" rel="noopener">堃堃</a>进行校对修改.</p>
<p>知乎地址： <a href="https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21462488?refer=intelligentunit</a></p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/11/CS231n/CS231n_Linear_Classify/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/02/11/CS231n/CS231n_Linear_Classify/" class="post-title-link" itemprop="url">CS231n课程笔记翻译：线性分类笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-02-11 11:11:11" itemprop="dateCreated datePublished" datetime="2018-02-11T11:11:11+08:00">2018-02-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-26 08:53:54" itemprop="dateModified" datetime="2018-03-26T08:53:54+08:00">2018-03-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CS231n课程笔记翻译/" itemprop="url" rel="index"><span itemprop="name">CS231n课程笔记翻译</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CS231n课程笔记翻译：线性分类笔记"><a href="#CS231n课程笔记翻译：线性分类笔记" class="headerlink" title="CS231n课程笔记翻译：线性分类笔记"></a>CS231n课程笔记翻译：线性分类笔记</h1><h2 id="原文如下"><a href="#原文如下" class="headerlink" title="原文如下"></a>原文如下</h2><p>内容列表：</p>
<ul>
<li><p>线性分类器简介</p>
</li>
<li><p>线性评分函数</p>
</li>
<li><p>阐明线性分类器</p>
</li>
<li><p>损失函数</p>
<ul>
<li>多类SVM</li>
</ul>
</li>
</ul>
<ul>
<li>Softmax分类器</li>
<li>SVM和Softmax的比较</li>
</ul>
<ul>
<li><p>基于Web的可交互线性分类器原型</p>
</li>
<li><p>小结</p>
</li>
</ul>
<h2 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h2><p>上一篇笔记介绍了图像分类问题。图像分类的任务，就是从已有的固定分类标签集合中选择一个并分配给一张图像。我们还介绍了k-Nearest Neighbor （k-NN）分类器，该分类器的基本思想是通过将测试图像与训练集带标签的图像进行比较，来给测试图像打上分类标签。k-Nearest Neighbor分类器存在以下不足：</p>
<ul>
<li>分类器必须<em>记住</em>所有训练数据并将其存储起来，以便于未来测试数据用于比较。这在存储空间上是低效的，数据集的大小很容易就以GB计。</li>
<li>对一个测试图像进行分类需要和所有训练图像作比较，算法计算资源耗费高。</li>
</ul>
<p><strong>概述</strong>：我们将要实现一种更强大的方法来解决图像分类问题，该方法可以自然地延伸到神经网络和卷积神经网络上。这种方法主要有两部分组成：一个是<strong>评分函数（score function）</strong>，它是原始图像数据到类别分值的映射。另一个是<strong>损失函数（loss function）</strong>，它是用来量化预测分类标签的得分与真实标签之间一致性的。该方法可转化为一个最优化问题，在最优化过程中，将通过更新评分函数的参数来最小化损失函数值。</p>
<h2 id="从图像到标签分值的参数化映射"><a href="#从图像到标签分值的参数化映射" class="headerlink" title="从图像到标签分值的参数化映射"></a>从图像到标签分值的参数化映射</h2><p>​        该方法的第一部分就是定义一个评分函数，这个函数将图像的像素值映射为各个分类类别的得分，得分高低代表图像属于该类别的可能性高低。下面会利用一个具体例子来展示该方法。现在假设有一个包含很多图像的训练集$x_i \in R^D$，每个图像都有一个对应的分类标签$y_i$。这里$i=1,2….N$并且$y_i \in 1….K$。这就是说，我们有<strong>N</strong>个图像样例，每个图像的维度是<strong>D</strong>，共有<strong>K</strong>种不同的分类。</p>
<p>举例来说，在CIFAR-10中，我们有一个<strong>N</strong>=50000的训练集，每个图像有<strong>D</strong>=32x32x3=3072个像素，而<strong>K</strong>=10，这是因为图片被分为10个不同的类别（狗，猫，汽车等）。我们现在定义评分函数为：$f:R^D \rightarrow R^K$，该函数是原始图像像素到分类分值的映射。</p>
<p><strong>线性分类器</strong>：在本模型中，我们从最简单的概率函数开始，一个线性映射：</p>
<center>$$f(x_i,W,b)=Wx_i+b$$</center>

<p>在上面的公式中，假设每个图像数据都被拉长为一个长度为D的列向量，大小为[D x 1]。其中大小为[K x D]的矩阵<strong>W</strong>和大小为[K x 1]列向量<strong>b</strong>为该函数的<strong>参数（parameters）</strong>。还是以CIFAR-10为例，$x_i$就包含了第$i$个图像的所有像素信息，这些信息被拉成为一个[3072 x 1]的列向量，W大小为[10x3072]，b的大小为[10x1]。因此，3072个数字（原始像素数值）输入函数，函数输出10个数字（不同分类得到的分值）。参数W被称为权重（weights）。b被称为偏差向量（bias vector），这是因为它影响输出数值，但是并不和原始数据产生关联。在实际情况中，人们常常混用权重和参数这两个术语。</p>
<p>需要注意的几点：</p>
<ul>
<li>首先，一个单独的矩阵乘法$Wx_i$就高效地并行评估10个不同的分类器（每个分类器针对一个分类），其中每个类的分类器就是W的一个行向量。</li>
<li>注意我们认为输入数据$(x_i,y_i)$是给定且不可改变的，但参数<strong>W</strong>和<strong>b</strong>是可控制改变的。我们的目标就是通过设置这些参数，使得计算出来的分类分值情况和训练集中图像数据的真实类别标签相符。在接下来的课程中，我们将详细介绍如何做到这一点，但是目前只需要直观地让正确分类的分值比错误分类的分值高即可。</li>
<li>该方法的一个优势是训练数据是用来学习到参数<strong>W</strong>和<strong>b</strong>的，一旦训练完成，训练数据就可以丢弃，留下学习到的参数即可。这是因为一个测试图像可以简单地输入函数，并基于计算出的分类分值来进行分类。</li>
<li>最后，注意只需要做一个矩阵乘法和一个矩阵加法就能对一个测试数据分类，这比k-NN中将测试图像和所有训练数据做比较的方法快多了。</li>
</ul>
<blockquote>
<p><em>预告：卷积神经网络映射图像像素值到分类分值的方法和上面一样，但是映射$(f)$就要复杂多了，其包含的参数也更多。</em></p>
</blockquote>
<h2 id="理解线性分类器"><a href="#理解线性分类器" class="headerlink" title="理解线性分类器"></a>理解线性分类器</h2><p>线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出喜好或者厌恶（根据每个权重的符号而定）。举个例子，可以想象“船”分类就是被大量的蓝色所包围（对应的就是水）。那么“船”分类器在蓝色通道上的权重就有很多的正权重（它们的出现提高了“船”分类的分值），而在绿色和红色通道上的权重为负的就比较多（它们的出现降低了“船”分类的分值）。</p>
<p>————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_0.jpg?raw=true" width="300"></center>

<p>一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。</p>
<p>————————————————————————————————————————</p>
<p><strong>将图像看做高维度的点</strong>：既然图像被伸展成为了一个高维度的列向量，那么我们可以把图像看做这个高维度空间中的一个点（即每张图像是3072维空间中的一个点）。整个数据集就是一个点的集合，每个点都带有1个分类标签。</p>
<p>既然定义每个分类类别的分值是权重和图像的矩阵乘，那么每个分类类别的分数就是这个空间中的一个线性函数的函数值。我们没办法可视化3072维空间中的线性函数，但假设把这些维度挤压到二维，那么就可以看看这些分类器在做什么了：</p>
<p>——————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_1.jpg?raw=true" width="350"></center>

<p>图像空间的示意图。其中每个图像是一个点，有3个分类器。以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低。</p>
<p>—————————————————————————————————————————</p>
<p>从上面可以看到，<strong>W</strong>的每一行都是一个分类类别的分类器。对于这些数字的几何解释是：如果改变其中一行的数字，会看见分类器在空间中对应的直线开始向着不同方向旋转。而偏差<strong>b</strong>，则允许分类器对应的直线平移。需要注意的是，如果没有偏差，无论权重如何，在$x_i=0$时分类分值始终为0。这样所有分类器的线都不得不穿过原点。</p>
<p><strong>将线性分类器看做模板匹配</strong>：关于权重<strong>W</strong>的另一个解释是<strong>它</strong>的每一行对应着一个分类的模板（有时候也叫作<em>原型</em>）。一张图像对应不同分类的得分，是通过使用内积（也叫<em>点积</em>）来比较图像和模板，然后找到和哪个模板最相似。从这个角度来看，线性分类器就是在利用学习到的模板，针对图像做模板匹配。从另一个角度来看，可以认为还是在高效地使用k-NN，不同的是我们没有使用所有的训练集的图像来比较，而是每个类别只用了一张图片（这张图片是我们学习到的，而不是训练集中的某一张），而且我们会使用（负）内积来计算向量间的距离，而不是使用L1或者L2距离。</p>
<p>————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_2.jpg?raw=true" width="500"></center>

<p>将课程进度快进一点。这里展示的是以CIFAR-10为训练集，学习结束后的权重的例子。注意，船的模板如期望的那样有很多蓝色像素。如果图像是一艘船行驶在大海上，那么这个模板利用内积计算图像将给出很高的分数。</p>
<p>————————————————————————————————————————</p>
<p>可以看到马的模板看起来似乎是两个头的马，这是因为训练集中的马的图像中马头朝向各有左右造成的。线性分类器将这两种情况融合到一起了。类似的，汽车的模板看起来也是将几个不同的模型融合到了一个模板中，并以此来分辨不同方向不同颜色的汽车。这个模板上的车是红色的，这是因为CIFAR-10中训练集的车大多是红色的。线性分类器对于不同颜色的车的分类能力是很弱的，但是后面可以看到神经网络是可以完成这一任务的。神经网络可以在它的隐藏层中实现中间神经元来探测不同种类的车（比如绿色车头向左，蓝色车头向前等）。而下一层的神经元通过计算不同的汽车探测器的权重和，将这些合并为一个更精确的汽车分类分值。</p>
<p><strong>偏差和权重的合并技巧</strong>：在进一步学习前，要提一下这个经常使用的技巧。它能够将我们常用的参数$W$和$b$合二为一。回忆一下，分类评分函数定义为：</p>
<center>$$f(x_i,W,b)=Wx_i+b$$</center>

<p>分开处理这两个参数（权重参数$W$和偏差参数$b$）有点笨拙，一般常用的方法是把两个参数放到同一个矩阵中，同时$x_i$向量就要增加一个维度，这个维度的数值是常量1，这就是默认的偏差维度。这样新的公式就简化成下面这样：</p>
<center>$$f(x_i,W)=Wx_i$$</center>

<p>还是以CIFAR-10为例，那么$x_i$的大小就变成[3073x1]，而不是[3072x1]了，多出了包含常量1的1个维度）。$W$大小就是[10x3073]了。$W$中多出来的这一列对应的就是偏差值$b$，具体见下图：</p>
<p>————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_3.jpg?raw=true" width="350"></center>

<p>偏差技巧的示意图。左边是先做矩阵乘法然后做加法，右边是将所有输入向量的维度增加1个含常量1的维度，并且在权重矩阵中增加一个偏差列，最后做一个矩阵乘法即可。左右是等价的。通过右边这样做，我们就只需要学习一个权重矩阵，而不用去学习两个分别装着权重和偏差的矩阵了。</p>
<p>—————————————————————————————————————————</p>
<p><strong>图像数据预处理</strong>：在上面的例子中，所有图像都是使用的原始像素值（从0到255）。在机器学习中，对于输入的特征做归一化（normalization）处理是常见的套路。而在图像分类的例子中，图像上的每个像素可以看做一个特征。在实践中，对每个特征减去平均值来<strong>中心化</strong>数据是非常重要的。在这些图片的例子中，该步骤意味着根据训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了。下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。<strong>零均值的中心化</strong>是很重要的，等我们理解了梯度下降后再来详细解释。</p>
<h2 id="损失函数-Loss-function"><a href="#损失函数-Loss-function" class="headerlink" title="损失函数 Loss function"></a>损失函数 Loss function</h2><p>在上一节定义了从图像像素值到所属类别的评分函数（score function），该函数的参数是权重矩阵$W$。在函数中，数据$(x_i,y_i)$是给定的，不能修改。但是我们可以调整权重矩阵这个参数，使得评分函数的结果与训练数据集中图像的真实类别一致，即评分函数在正确的分类的位置应当得到最高的评分（score）。</p>
<p>回到之前那张猫的图像分类例子，它有针对“猫”，“狗”，“船”三个类别的分数。我们看到例子中权重值非常差，因为猫分类的得分非常低（-96.8），而狗（437.9）和船（61.95）比较高。我们将使用<strong>损失函数（Loss Function）</strong>（有时也叫<strong>代价函数Cost Function</strong>或<strong>目标函数Objective</strong>）来衡量我们对结果的不满意程度。直观地讲，当评分函数输出结果与真实结果之间差异越大，损失函数输出越大，反之越小。</p>
<h3 id="多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss"><a href="#多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss" class="headerlink" title="多类支持向量机损失 Multiclass Support Vector Machine Loss"></a>多类支持向量机损失 Multiclass Support Vector Machine Loss</h3><p>损失函数的具体形式多种多样。首先，介绍常用的多类支持向量机（SVM）损失函数。SVM的损失函数想要SVM在正确分类上的得分始终比不正确分类上的得分高出一个边界值$\Delta$。我们可以把损失函数想象成一个人，这位SVM先生（或者女士）对于结果有自己的品位，如果某个结果能使得损失值更低，那么SVM就更加喜欢它。</p>
<p>让我们更精确一些。回忆一下，第i个数据中包含图像$x_i​$的像素和代表正确类别的标签$y_i​$。评分函数输入像素数据，然后通过公式$f(x_i,W)​$来计算不同分类类别的分值。这里我们将分值简写为$s​$。比如，针对第j个类别的得分就是第j个元素：$s_j=f(x_i,W)_j​$。针对第i个数据的多类SVM的损失函数定义如下：</p>
<center>$$L_i=\sum_{j\neq{y_i}}\max(0,s_j-s_{y_i}+\Delta)$$</center>

<p><strong>举例</strong>：用一个例子演示公式是如何计算的。假设有3个分类，并且得到了分值$s=[13,-7,11]$。其中第一个类别是正确类别，即$y_i=0$。同时假设$\Delta$是10（后面会详细介绍该超参数）。上面的公式是将所有不正确分类（$j\not=y_i$）加起来，所以我们得到两个部分：</p>
<p>可以看到第一个部分结果是0，这是因为[-7-13+10]得到的是负数，经过$max(0,-)$函数处理后得到0。这一对类别分数和标签的损失值是0，这是因为正确分类的得分13与错误分类的得分-7的差为20，高于边界值10。而SVM只关心差距至少要大于10，更大的差值还是算作损失值为0。第二个部分计算[11-13+10]得到8。虽然正确分类的得分比不正确分类的得分要高（13&gt;11），但是比10的边界值还是小了，分差只有2，这就是为什么损失值等于8。简而言之，SVM的损失函数想要正确分类类别$y_i$的分数比不正确类别分数高，而且至少要高$\Delta$。如果不满足这点，就开始计算损失值。</p>
<p>那么在这次的模型中，我们面对的是线性评分函数（$f(x_i,W)=Wx_i$），所以我们可以将损失函数的公式稍微改写一下：</p>
<center>$$L_i=\sum_{j\neq{y_i}}\max(0,w_j^Tx_i-w_{y_i}^Tx_i+\Delta)$$</center>

<p>其中$w_j$是权重的$W$第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数$f$公式，这样做就不是必须的了。</p>
<p>在结束这一小节前，还必须提一下的属于是关于0的阀值：$max(0,-)$函数，它常被称为<strong>折叶损失（hinge loss）</strong>。有时候会听到人们使用平方折叶损失SVM（即L2-SVM），它使用的是$max(0,-)^2$，将更强烈（平方地而不是线性地）地惩罚过界的边界值。不使用平方是更标准的版本，但是在某些数据集中，平方折叶损失会工作得更好。可以通过交叉验证来决定到底使用哪个。</p>
<blockquote>
<p>我们对于预测训练集数据分类标签的情况总有一些不满意的，而损失函数就能将这些不满意的程度量化。</p>
</blockquote>
<p>—————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_4.jpg?raw=true" width="400"></center>

<p>多类SVM“想要”正确类别的分类分数比其他不正确分类类别的分数要高，而且至少高出delta的边界值。如果其他分类分数进入了红色的区域，甚至更高，那么就开始计算损失。如果没有这些情况，损失值为0。我们的目标是找到一些权重，它们既能够让训练集中的数据样例满足这些限制，也能让总的损失值尽可能地低。</p>
<p>—————————————————————————————————————————</p>
<p><strong>正则化（Regularization）：</strong>上面损失函数有一个问题。假设有一个数据集和一个权重集<strong>W</strong>能够正确地分类每个数据（即所有的边界都满足，对于所有的i都有$L_i=0$）。问题在于这个<strong>W</strong>并不唯一：可能有很多相似的<strong>W</strong>都能正确地分类所有的数据。一个简单的例子：如果<strong>W</strong>能够正确分类所有数据，即对于每个数据，损失值都是0。那么当$\lambda&gt;1$时，任何数乘$\lambda W$都能使得损失值为0，因为这个变化将所有分值的大小都均等地扩大了，所以它们之间的绝对差值也扩大了。举个例子，如果一个正确分类的分值和举例它最近的错误分类的分值的差距是15，对<strong>W</strong>乘以2将使得差距变成30。</p>
<p>换句话说，我们希望能向某些特定的权重<strong>W</strong>添加一些偏好，对其他权重则不添加，以此来消除模糊性。这一点是能够实现的，方法是向损失函数增加一个<strong>正则化惩罚(regularization penalty)</strong> $R(W)$部分。最常用的正则化惩罚是L2范式，L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重：</p>
<center>$$\sum_k\sum_l{W_{k,l}^2}$$</center>

<p>上面的表达式中，将$W$中所有元素平方后求和。注意正则化函数不是数据的函数，仅基于权重。包含正则化惩罚后，就能够给出完整的多类SVM损失函数了，它由两个部分组成：<strong>数据损失（data loss）</strong>，即所有样例的的平均损失$L_i$，以及<strong>正则化损失（regularization loss）</strong>。完整公式如下所示：</p>
<center>$$L=\displaystyle \underbrace{ \frac{1}{N}\sum_i L_i}<em>{data \  loss}+\underbrace{\lambda R(W)}</em>{regularization \ loss}$$</center>

<p>将其展开完整公式是：</p>
<center>$$L=\frac{1}{N}\sum_i \sum_{j\neq{y_i}}[max(0,f(x_i;W)_j-f(x_i;W)_{y_i}+\Delta)]+\lambda\sum_k\sum_l{W_{k,l}^2}$$</center>

<p>其中，$N$是训练集的数据量。现在正则化惩罚添加到了损失函数里面，并用超参数$\lambda$来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取。</p>
<p>除了上述理由外，引入正则化惩罚还带来很多良好的性质，这些性质大多会在后续章节介绍。比如引入了L2惩罚后，SVM们就有了<strong>最大边界（max margin）</strong>这一良好性质。（如果感兴趣，可以查看<a href="http://link.zhihu.com/?target=http%3A//cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener"><strong>CS229课程</strong></a>）。</p>
<p>其中最好的性质就是对大数值权重进行惩罚，可以提升其泛化能力，因为这就意味着没有哪个维度能够独自对于整体分值有过大的影响。举个例子，假设输入向量$x=[1,1,1,1]$，两个权重向量$w_1=[1,0,0,0]$，$w_2=[0.25,0.25,0.25,0.25]$。那么$w^T_1x=w^T_2=1$,两个权重向量都得到同样的内积，但是$w_1$的L2惩罚是1.0，而$w_2$的L2惩罚是0.25。因此，根据L2惩罚来看，$w_2$更好，因为它的正则化损失更小。从直观上来看，这是因为$w_2$的权重值更小且更分散。既然L2惩罚倾向于更小更分散的权重向量，这就会鼓励分类器最终将所有维度上的特征都用起来，而不是强烈依赖其中少数几个维度。在后面的课程中可以看到，这一效果将会提升分类器的泛化能力，并避免<em>过拟合</em>。</p>
<p>需要注意的是，和权重不同，偏差没有这样的效果，因为它们并不控制输入维度上的影响强度。因此通常只对权重$W$正则化，而不正则化偏差$b$。在实际操作中，可发现这一操作的影响可忽略不计。最后，因为正则化惩罚的存在，不可能在所有的例子中得到0的损失值，这是因为只有当$W=0$的特殊情况下，才能得到损失值为0。</p>
<p><strong>代码</strong>：下面是一个无正则化部分的损失函数的Python实现，有非向量化和半向量化两个形式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i</span><span class="params">(x, y, W)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  unvectorized version. Compute the multiclass svm loss for a single example (x,y)</span></span><br><span class="line"><span class="string">  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)</span></span><br><span class="line"><span class="string">    with an appended bias dimension in the 3073-rd position (i.e. bias trick)</span></span><br><span class="line"><span class="string">  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)</span></span><br><span class="line"><span class="string">  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  delta = <span class="number">1.0</span> <span class="comment"># see notes about delta later in this section</span></span><br><span class="line">  scores = W.dot(x) <span class="comment"># scores becomes of size 10 x 1, the scores for each class</span></span><br><span class="line">  correct_class_score = scores[y]</span><br><span class="line">  D = W.shape[<span class="number">0</span>] <span class="comment"># number of classes, e.g. 10</span></span><br><span class="line">  loss_i = <span class="number">0.0</span></span><br><span class="line">  <span class="keyword">for</span> j <span class="keyword">in</span> xrange(D): <span class="comment"># iterate over all wrong classes</span></span><br><span class="line">    <span class="keyword">if</span> j == y:</span><br><span class="line">      <span class="comment"># skip for the true class to only loop over incorrect classes</span></span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># accumulate loss for the i-th example</span></span><br><span class="line">    loss_i += max(<span class="number">0</span>, scores[j] - correct_class_score + delta)</span><br><span class="line">  <span class="keyword">return</span> loss_i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i_vectorized</span><span class="params">(x, y, W)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  A faster half-vectorized implementation. half-vectorized</span></span><br><span class="line"><span class="string">  refers to the fact that for a single example the implementation contains</span></span><br><span class="line"><span class="string">  no for loops, but there is still one loop over the examples (outside this function)</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  delta = <span class="number">1.0</span></span><br><span class="line">  scores = W.dot(x)</span><br><span class="line">  <span class="comment"># compute the margins for all classes in one vector operation</span></span><br><span class="line">  margins = np.maximum(<span class="number">0</span>, scores - scores[y] + delta)</span><br><span class="line">  <span class="comment"># on y-th position scores[y] - scores[y] canceled and gave delta. We want</span></span><br><span class="line">  <span class="comment"># to ignore the y-th position and only consider margin on max wrong class</span></span><br><span class="line">  margins[y] = <span class="number">0</span></span><br><span class="line">  loss_i = np.sum(margins)</span><br><span class="line">  <span class="keyword">return</span> loss_i</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L</span><span class="params">(X, y, W)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  fully-vectorized implementation :</span></span><br><span class="line"><span class="string">  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)</span></span><br><span class="line"><span class="string">  - y is array of integers specifying correct class (e.g. 50,000-D array)</span></span><br><span class="line"><span class="string">  - W are weights (e.g. 10 x 3073)</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="comment"># evaluate loss over all examples in X without using any for loops</span></span><br><span class="line">  <span class="comment"># left as exercise to reader in the assignment</span></span><br></pre></td></tr></table></figure>
<p>在本小节的学习中，一定要记得SVM损失采取了一种特殊的方法，使得能够衡量对于训练数据预测分类和实际分类标签的一致性。还有，对训练集中数据做出准确分类预测和让损失值最小化这两件事是等价的。</p>
<blockquote>
<p>接下来要做的，就是找到能够使损失值最小化的权重了。</p>
</blockquote>
<h3 id="实际考虑"><a href="#实际考虑" class="headerlink" title="实际考虑"></a>实际考虑</h3><p><strong>设置Delta</strong>：你可能注意到上面的内容对超参数$\Delta$及其设置是一笔带过，那么它应该被设置成什么值？需要通过交叉验证来求得吗？现在看来，该超参数在绝大多数情况下设为$\Delta=1.0$都是安全的。超参数$\Delta$和$\lambda$看起来是两个不同的超参数，但实际上他们一起控制同一个权衡：即损失函数中的数据损失和正则化损失之间的权衡。理解这一点的关键是要知道，权重$W$的大小对于分类分值有直接影响（当然对他们的差异也有直接影响）：当我们将$W$中值缩小，分类分值之间的差异也变小，反之亦然。因此，不同分类分值之间的边界的具体值（比如$\Delta=1$或$\Delta=100$）从某些角度来看是没意义的，因为权重自己就可以控制差异变大和缩小。也就是说，真正的权衡是我们允许权重能够变大到何种程度（通过正则化强度$\lambda$来控制）。</p>
<p><strong>与二元支持向量机（Binary Support Vector Machine）的关系</strong>：在学习本课程前，你可能对于二元支持向量机有些经验，它对于第i个数据的损失计算公式是：</p>
<p>其中，$C$是一个超参数，并且$y_i\in{-1,1}$。可以认为本章节介绍的SVM公式包含了上述公式，上述公式是多类支持向量机公式只有两个分类类别的特例。也就是说，如果我们要分类的类别只有两个，那么公式就化为二元SVM公式。这个公式中的$C$和多类SVM公式中的$\lambda$都控制着同样的权衡，而且它们之间的关系是$C\propto\frac{1}{\lambda}$</p>
<p><strong>备注：在初始形式中进行最优化</strong>。如果在本课程之前学习过SVM，那么对kernels，duals，SMO算法等将有所耳闻。在本课程（主要是神经网络相关）中，损失函数的最优化的始终在非限制初始形式下进行。很多这些损失函数从技术上来说是不可微的（比如当$x=y$时，$max(x,y)$函数就不可微分），但是在实际操作中并不存在问题，因为通常可以使用次梯度。</p>
<p><strong>备注：其他多类SVM公式</strong>。需要指出的是，本课中展示的多类SVM只是多种SVM公式中的一种。另一种常用的公式是<em>One-Vs-All</em>（OVA）SVM，它针对每个类和其他类训练一个独立的二元分类器。还有另一种更少用的叫做<em>All-Vs-All</em>（AVA）策略。我们的公式是按照<a href="http://link.zhihu.com/?target=https%3A//www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es1999-461.pdf" target="_blank" rel="noopener"><strong>Weston and Watkins 1999 (pdf)</strong></a>版本，比OVA性能更强（在构建有一个多类数据集的情况下，这个版本可以在损失值上取到0，而OVA就不行。感兴趣的话在论文中查阅细节）。最后一个需要知道的公式是Structured SVM，它将正确分类的分类分值和非正确分类中的最高分值的边界最大化。理解这些公式的差异超出了本课程的范围。本课程笔记介绍的版本可以在实践中安全使用，而被论证为最简单的OVA策略在实践中看起来也能工作的同样出色（在 Rikin等人2004年的论文<a href="http://link.zhihu.com/?target=http%3A//www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf" target="_blank" rel="noopener"><strong>In Defense of One-Vs-All Classification (pdf)</strong></a>中可查）。</p>
<h2 id="Softmax分类器"><a href="#Softmax分类器" class="headerlink" title="Softmax分类器"></a>Softmax分类器</h2><p>SVM是最常用的两个分类器之一，而另一个就是<strong>Softmax分类器，</strong>它的损失函数与SVM的损失函数不同。对于学习过二元逻辑回归分类器的读者来说，Softmax分类器就可以理解为逻辑回归分类器面对多个分类的一般化归纳。SVM将输出$f(x_i,W)$作为每个分类的评分（因为无定标，所以难以直接解释）。与SVM不同，Softmax的输出（归一化的分类概率）更加直观，并且从概率上可以解释，这一点后文会讨论。在Softmax分类器中，函数映射$f(x_i;W)=Wx_i$保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将<em>折叶损失（hinge loss）</em>替换为<strong>交叉熵损失（cross-entropy loss）</strong>。公式如下：</p>
<center>$\displaystyle Li=-log(\frac{e^{f_{y_i}}}{\sum_je^{f_j}})$ 或等价的 $L_i=-f_{y_i}+log(\sum_je^{f_j})$</center>

<p>在上式中，使用$f_j$来表示分类评分向量$f$中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值$L_i$之和。其中函数$f_j(z)=\frac{e^{z_j}}{\sum_ke^{z_k}}$被称作<strong>softmax 函数</strong>：其输入值是一个向量，向量中元素为任意实数的评分值（$z$中的），函数对其进行压缩，输出一个向量，其中每个元素值在0到1之间，且所有元素之和为1。所以，包含softmax函数的完整交叉熵损失看起唬人，实际上还是比较容易理解的。</p>
<p><strong>信息理论视角</strong>：在“真实”分布$p$和估计分布$q$之间的<em>交叉熵</em>定义如下：</p>
<p>因此，Softmax分类器所做的就是最小化在估计分类概率（就是上面的$e^{f_{y_i}}/\sum_je^{f_j}$）和“真实”分布之间的交叉熵，在这个解释中，“真实”分布就是所有概率密度都分布在正确的类别上（比如：$p=[0,…1,…,0]$中在$y_i$的位置就有一个单独的1）。还有，既然交叉熵可以写成熵和相对熵（Kullback-Leibler divergence）$H(p,q)=H(p)+D_{KL}(p||q)$，并且delta函数$p$的熵是0，那么就能等价的看做是对两个分布之间的相对熵做最小化操作。换句话说，交叉熵损失函数“想要”预测分布的所有概率密度都在正确分类上。</p>
<blockquote>
<p> <strong>*译者注</strong>：Kullback-Leibler差异（Kullback-Leibler Divergence）也叫做相对熵（Relative Entropy），它衡量的是相同事件空间里的两个概率分布的差异情况。*</p>
</blockquote>
<p><strong>概率论解释</strong>：先看下面的公式：</p>
<p>可以解释为是给定图像数据$x_i$为参数，分配给正确分类标签$y_i$的归一化概率。为了理解这点，请回忆一下Softmax分类器将输出向量$f$中的评分值解释为没有归一化的对数概率。那么以这些数值做指数函数的幂就得到了没有归一化的概率，而除法操作则对数据进行了归一化处理，使得这些概率的和为1。从概率论的角度来理解，我们就是在最小化正确分类的负对数概率，这可以看做是在进行<em>最大似然估计</em>（MLE）。该解释的另一个好处是，损失函数中的正则化部分$R(W)$可以被看做是权重矩阵$W$的高斯先验，这里进行的是最大后验估计（MAP）而不是最大似然估计。提及这些解释只是为了让读者形成直观的印象，具体细节就超过本课程范围了。</p>
<p><strong>实操事项：数值稳定。</strong>编程实现softmax函数计算的时候，中间项$e^{f_{y_i}}$和$\sum_j e^{f_j}$因为存在指数函数，所以数值可能非常大。除以大数值可能导致数值计算的不稳定，所以学会使用归一化技巧非常重要。如果在分式的分子和分母都乘以一个常数$C$，并把它变换到求和之中，就能得到一个从数学上等价的公式：</p>
<p>$C$的值可自由选择，不会影响计算结果，通过使用这个技巧可以提高计算中的数值稳定性。通常将$C$设为$logC=-max_jf_j$。该技巧简单地说，就是应该将向量$f$中的数值进行平移，使得最大值为0。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f = np.array([<span class="number">123</span>, <span class="number">456</span>, <span class="number">789</span>]) <span class="comment"># 例子中有3个分类，每个评分的数值都很大</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 不妙：数值问题，可能导致数值爆炸</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 那么将f中的值平移到最大值为0：</span></span><br><span class="line">f -= np.max(f) <span class="comment"># f becomes [-666, -333, 0]</span></span><br><span class="line">p = np.exp(f) / np.sum(np.exp(f)) <span class="comment"># 现在OK了，将给出正确结果</span></span><br></pre></td></tr></table></figure>
<p><strong>让人迷惑的命名规则</strong>：精确地说，SVM分类器使用的是<em>折叶损失（hinge loss）</em>，有时候又被称为<em>最大边界损失（max-margin loss）</em>。Softmax分类器使用的是<em>交叉熵损失（corss-entropy loss）</em>。Softmax分类器的命名是从<em>softmax函数</em>那里得来的，softmax函数将原始分类评分变成正的归一化数值，所有数值和为1，这样处理后交叉熵损失才能应用。注意从技术上说“softmax损失（softmax loss）”是没有意义的，因为softmax只是一个压缩数值的函数。但是在这个说法常常被用来做简称。</p>
<h2 id="SVM和Softmax的比较"><a href="#SVM和Softmax的比较" class="headerlink" title="SVM和Softmax的比较"></a>SVM和Softmax的比较</h2><p>下图有助于区分这 Softmax和SVM这两种分类器：</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_5.png?raw=true" width="350"></center>

<p>————————————————————————————————————————</p>
<p>针对一个数据点，SVM和Softmax分类器的不同处理方式的例子。两个分类器都计算了同样的分值向量<strong>f</strong>（本节中是通过矩阵乘来实现）。不同之处在于对<strong>f</strong>中分值的解释：SVM分类器将它们看做是分类评分，它的损失函数鼓励正确的分类（本例中是蓝色的类别2）的分值比其他分类的分值高出至少一个边界值。Softmax分类器将这些数值看做是每个分类没有归一化的<strong>对数概率</strong>，鼓励正确分类的归一化的对数概率变高，其余的变低。SVM的最终的损失值是1.58，Softmax的最终的损失值是0.452，但要注意这两个数值没有可比性。只在给定同样数据，在同样的分类器的损失值计算中，它们才有意义。</p>
<p>————————————————————————————————————————</p>
<p><strong>Softmax分类器为每个分类提供了“可能性”</strong>：SVM的计算是无标定的，而且难以针对所有分类的评分值给出直观解释。Softmax分类器则不同，它允许我们计算出对于所有分类标签的可能性。举个例子，针对给出的图像，SVM分类器可能给你的是一个[12.5, 0.6, -23.0]对应分类“猫”，“狗”，“船”。而softmax分类器可以计算出这三个标签的”可能性“是[0.9, 0.09, 0.01]，这就让你能看出对于不同分类准确性的把握。为什么我们要在”可能性“上面打引号呢？这是因为可能性分布的集中或离散程度是由正则化参数λ直接决定的，λ是你能直接控制的一个输入参数。举个例子，假设3个分类的原始分数是[1, -2, 0]，那么softmax函数就会计算：</p>
<p>现在，如果正则化参数λ更大，那么权重W就会被惩罚的更多，然后他的权重数值就会更小。这样算出来的分数也会更小，假设小了一半吧[0.5, -1, 0]，那么softmax函数的计算就是：</p>
<p>现在看起来，概率的分布就更加分散了。还有，随着正则化参数λ不断增强，权重数值会越来越小，最后输出的概率会接近于均匀分布。这就是说，softmax分类器算出来的概率最好是看成一种对于分类正确性的自信。和SVM一样，数字间相互比较得出的大小顺序是可以解释的，但其绝对值则难以直观解释<strong>。</strong></p>
<p><strong>在实际使用中，SVM和Softmax经常是相似的</strong>：通常说来，两种分类器的表现差别很小，不同的人对于哪个分类器更好有不同的看法。相对于Softmax分类器，SVM更加“局部目标化（local objective）”，这既可以看做是一个特性，也可以看做是一个劣势。考虑一个评分是[10, -2, 3]的数据，其中第一个分类是正确的。那么一个SVM（$\Delta =1$）会看到正确分类相较于不正确分类，已经得到了比边界值还要高的分数，它就会认为损失值是0。SVM对于数字个体的细节是不关心的：如果分数是[10, -100, -100]或者[10, 9, 9]，对于SVM来说没设么不同，只要满足超过边界值等于1，那么损失值就等于0。</p>
<p>对于softmax分类器，情况则不同。对于[10, 9, 9]来说，计算出的损失值就远远高于[10, -100, -100]的。换句话来说，softmax分类器对于分数是永远不会满意的：正确分类总能得到更高的可能性，错误分类总能得到更低的可能性，损失值总是能够更小。但是，SVM只要边界值被满足了就满意了，不会超过限制去细微地操作具体分数。这可以被看做是SVM的一种特性。举例说来，一个汽车的分类器应该把他的大量精力放在如何分辨小轿车和大卡车上，而不应该纠结于如何与青蛙进行区分，因为区分青蛙得到的评分已经足够低了。</p>
<h2 id="交互式的网页Demo"><a href="#交互式的网页Demo" class="headerlink" title="交互式的网页Demo"></a>交互式的网页Demo</h2><p>————————————————————————————————————————</p>
<p><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/linear_classification/linear_classification_6.jpg?raw=true" width="400"></center>我们实现了一个交互式的网页原型，来帮助读者直观地理解线性分类器。原型将损失函数进行可视化，画面表现的是对于2维数据的3种类别的分类。原型在课程进度上稍微超前，展现了最优化的内容，最优化将在下一节课讨论。</p>
<p>————————————————————————————————————————</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>总结如下：</p>
<ul>
<li>定义了从图像像素映射到不同类别的分类评分的评分函数。在本节中，评分函数是一个基于权重<strong>W</strong>和偏差<strong>b</strong>的线性函数。</li>
<li>与kNN分类器不同，<strong>参数方法</strong>的优势在于一旦通过训练学习到了参数，就可以将训练数据丢弃了。同时该方法对于新的测试数据的预测非常快，因为只需要与权重<strong>W</strong>进行一个矩阵乘法运算。</li>
<li>介绍了偏差技巧，让我们能够将偏差向量和权重矩阵合二为一，然后就可以只跟踪一个矩阵。</li>
<li>定义了损失函数（介绍了SVM和Softmax线性分类器最常用的2个损失函数）。损失函数能够衡量给出的参数集与训练集数据真实类别情况之间的一致性。在损失函数的定义中可以看到，对训练集数据做出良好预测与得到一个足够低的损失值这两件事是等价的。</li>
</ul>
<p>现在我们知道了如何基于参数，将数据集中的图像映射成为分类的评分，也知道了两种不同的损失函数，它们都能用来衡量算法分类预测的质量。但是，如何高效地得到能够使损失值最小的参数呢？这个求得最优参数的过程被称为最优化，将在下节课中进行介绍。</p>
<h2 id="拓展阅读"><a href="#拓展阅读" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><p>下面的内容读者可根据兴趣选择性阅读。</p>
<ul>
<li><a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1306.0239" target="_blank" rel="noopener"><strong>Deep Learning using Linear Support Vector Machines</strong></a>一文的作者是Tang Charlie，论文写于2013年，展示了一些L2SVM比Softmax表现更出色的结果。</li>
</ul>
<p><strong>线性分类笔记全文翻译完毕</strong>。</p>
<blockquote>
<p>译自斯坦福CS231n课程笔记<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/linear-classify/" target="_blank" rel="noopener"><strong>Linear Classification Note</strong></a>，课程教师<a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" target="_blank" rel="noopener"><strong>Andrej Karpathy</strong></a>授权翻译。本篇教程由<a href="https://www.zhihu.com/people/du-ke" target="_blank" rel="noopener">杜客</a>翻译完成，<a href="https://www.zhihu.com/people/kun-kun-97-81" target="_blank" rel="noopener">堃堃</a>进行校对修改</p>
<p>知乎地址：（上，中，下）</p>
<p><a href="https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20918580?refer=intelligentunit</a></p>
<p> <a href="https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/20945670?refer=intelligentunit</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21102293?refer=intelligentunit</a></p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/11/CS231n/CS231n_Neural_Network2/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/02/11/CS231n/CS231n_Neural_Network2/" class="post-title-link" itemprop="url">CS231n课程笔记翻译：神经网络笔记2</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2018-02-11 11:11:11" itemprop="dateCreated datePublished" datetime="2018-02-11T11:11:11+08:00">2018-02-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2018-03-26 08:53:34" itemprop="dateModified" datetime="2018-03-26T08:53:34+08:00">2018-03-26</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/CS231n课程笔记翻译/" itemprop="url" rel="index"><span itemprop="name">CS231n课程笔记翻译</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CS231n课程笔记翻译：神经网络笔记-2"><a href="#CS231n课程笔记翻译：神经网络笔记-2" class="headerlink" title="CS231n课程笔记翻译：神经网络笔记 2"></a>CS231n课程笔记翻译：神经网络笔记 2</h1><h2 id="原文如下"><a href="#原文如下" class="headerlink" title="原文如下"></a>原文如下</h2><p>内容列表：</p>
<ul>
<li>设置数据和模型<ul>
<li>数据预处理</li>
<li>权重初始化</li>
<li>批量归一化（Batch Normalization）</li>
<li>正则化（L2/L1/Maxnorm/Dropout）</li>
</ul>
</li>
<li>损失函数</li>
<li>小结</li>
</ul>
<h2 id="设置数据和模型"><a href="#设置数据和模型" class="headerlink" title="设置数据和模型"></a>设置数据和模型</h2><p>在上一节中介绍了神经元的模型，它在计算内积后进行非线性激活函数计算，神经网络将这些神经元组织成各个层。这些做法共同定义了<strong>评分函数（score function）</strong> 的新形式，该形式是从前面线性分类章节中的简单线性映射发展而来的。具体来说，神经网络就是进行了一系列的线性映射与非线性激活函数交织的运算。本节将讨论更多的算法设计选项，比如数据预处理，权重初始化和损失函数。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>关于数据预处理我们有3个常用的符号，数据矩阵<strong>X</strong>，假设其尺寸是 <strong>[N x D]</strong> （<strong>N</strong> 是数据样本的数量，<strong>D</strong> 是数据的维度）。</p>
<p><strong>均值减法（Mean subtraction）</strong> 是预处理最常用的形式。它对数据中每个独立<em>特征</em>减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码 <strong>X -= np.mean(X, axis=0)</strong> 实现。而对于图像，更常用的是对所有像素都减去一个值，可以用 <strong>X -= np.mean(X)</strong> 实现，也可以在3个颜色通道上分别操作。</p>
<p><strong>归一化（Normalization）</strong> 是指将数据的所有维度都归一化，使其数值范围都近似相等。有两种常用方法可以实现归一化。第一种是先对数据做零中心化（zero-centered）处理，然后每个维度都除以其标准差，实现代码为 <strong>X /= np.std(X, axis=0)</strong> 。第二种方法是对每个维度都做归一化，使得每个维度的最大和最小值是1和-1。这个预处理操作只有在确信不同的输入特征有不同的数值范围（或计量单位）时才有意义，但要注意预处理操作的重要性几乎等同于学习算法本身。在图像处理中，由于像素的数值范围几乎是一致的（都在0-255之间），所以进行这个额外的预处理步骤并不是很必要。</p>
<p>——————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_10.jpg?raw=true" width="400"></center><br>一般数据预处理流程： <strong>左边</strong> :原始的2维输入数据。 <strong>中间</strong> :在每个维度上都减去平均值后得到零中心化数据，现在数据云是以原点为中心的。 <strong>右边</strong> : 每个维度都除以其标准差来调整其数值范围。红色的线指出了数据各维度的数值范围，在中间的零中心化数据的数值范围不同，但在右边归一化数据中数值范围相同。<br><br>——————————————————————————————————————————<br><br><strong>PCA和白化（Whitening）</strong> 是另一种预处理形式。在这种处理中，先对数据进行零中心化处理，然后计算协方差矩阵，它展示了数据中的相关性结构。<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设输入数据矩阵X的尺寸为[N x D]</span></span><br><span class="line">X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># 对数据进行零中心化(重要)</span></span><br><span class="line">cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># 得到数据的协方差矩阵</span></span><br></pre></td></tr></table></figure><br><br>数据协方差矩阵的第(i, j)个元素是数据第i个和第j个维度的<em>协方差</em>。具体来说，该矩阵的对角线上的元素是方差。还有，协方差矩阵是对称和<a href="http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Positive-definite_matrix%23Negative-definite.2C_semidefinite_and_indefinite_matrices" target="_blank" rel="noopener"><strong>半正定</strong></a>的。我们可以对数据协方差矩阵进行SVD（奇异值分解）运算。<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">U,S,V = np.linalg.svd(cov)</span><br></pre></td></tr></table></figure><br><br>U的列是特征向量，S是装有奇异值的1维数组（因为cov是对称且半正定的，所以S中元素是特征值的平方）。为了去除数据相关性，将已经零中心化处理过的原始数据投影到特征基准上：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Xrot = np.dot(X,U) <span class="comment"># 对数据去相关性</span></span><br></pre></td></tr></table></figure><br><br>注意U的列是标准正交向量的集合（范式为1，列之间标准正交），所以可以把它们看做标准正交基向量。因此，投影对应x中的数据的一个旋转，旋转产生的结果就是新的特征向量。如果计算<strong>Xrot</strong>的协方差矩阵，将会看到它是对角对称的。<strong>np.linalg.svd</strong>的一个良好性质是在它的返回值<strong>U</strong>中，特征向量是按照特征值的大小排列的。我们可以利用这个性质来对数据降维，只要使用前面的小部分特征向量，丢弃掉那些包含的数据没有<strong>方差</strong>的维度。 这个操作也被称为主成分分析（ <a href="http://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener"><strong>Principal Component Analysis</strong></a> 简称PCA）降维：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Xrot_reduced = np.dot(X, U[:,:<span class="number">100</span>]) <span class="comment"># Xrot_reduced 变成 [N x 100]</span></span><br></pre></td></tr></table></figure><br><br>经过上面的操作，将原始的数据集的大小由[N x D]降到了[N x 100]，留下了数据中包含最大<strong>方差</strong>的100个维度。通常使用PCA降维过的数据训练线性分类器和神经网络会达到非常好的性能效果，同时还能节省时间和存储器空间。<br><br>最后一个在实践中会看见的变换是<strong>白化（whitening）</strong>。白化操作的输入是特征基准上的数据，然后对每个维度除以其特征值来对数值范围进行归一化。该变换的几何解释是：如果数据服从多变量的高斯分布，那么经过白化后，数据的分布将会是一个均值为零，且协方差相等的矩阵。该操作的代码如下：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对数据进行白化操作:</span></span><br><span class="line"><span class="comment"># 除以特征值 </span></span><br><span class="line">Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure><br><br><em>警告：夸大的噪声</em>。注意分母中添加了1e-5（或一个更小的常量）来防止分母为0。该变换的一个缺陷是在变换的过程中可能会夸大数据中的噪声，这是因为它将所有维度都拉伸到相同的数值范围，这些维度中也包含了那些只有极少差异性(方差小)而大多是噪声的维度。在实际操作中，这个问题可以用更强的平滑来解决（例如：采用比1e-5更大的值）。<br><br>——————————————————————————————————————————<br><br><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_11.jpg?raw=true" width="400"></center><br>PCA/白化。 <strong>左边</strong> 是二维的原始数据。 <strong>中间</strong> : 经过PCA操作的数据。可以看出数据首先是零中心的，然后变换到了数据协方差矩阵的基准轴上。这样就对数据进行了解相关（协方差矩阵变成对角阵）。 <strong>右边</strong> : 每个维度都被特征值调整数值范围，将数据协方差矩阵变为单位矩阵。从几何上看，就是对数据在各个方向上拉伸压缩，使之变成服从高斯分布的一个数据点分布。<br><br>——————————————————————————————————————————<br><br>我们可以使用CIFAR-10数据将这些变化可视化出来。CIFAR-10训练集的大小是50000x3072，其中每张图片都可以拉伸为3072维的行向量。我们可以计算[3072 x 3072]的协方差矩阵然后进行奇异值分解（比较耗费计算性能），那么经过计算的特征向量看起来是什么样子呢？<br><br>—————————————————————————————————————————<br><br><center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_12.jpg?raw=true" width="400"></center><br><strong>最左</strong>: 一个用于演示的集合，含49张图片。<strong>左二</strong>: 3072个特征值向量中的前144个。靠前面的特征向量解释了数据中大部分的方差，可以看见它们与图像中较低的频率相关。<strong>第三张</strong> 是49张经过了PCA降维处理的图片，展示了144个特征向量。这就是说，展示原始图像是每个图像用3072维的向量，向量中的元素是图片上某个位置的像素在某个颜色通道中的亮度值。而现在每张图片只使用了一个144维的向量，其中每个元素表示了特征向量对于组成这张图片的贡献度。为了让图片能够正常显示，需要将144维度重新变成基于像素基准的3072个数值。因为U是一个旋转，可以通过乘以U.transpose()[:144,:]来实现，然后将得到的3072个数值可视化。可以看见图像变得有点模糊了，这正好说明前面的特征向量获取了较低的频率。然而，大多数信息还是保留了下来。<strong>最右</strong>: 将“白化”后的数据进行显示。其中144个维度中的方差都被压缩到了相同的数值范围。然后144个白化后的数值通过乘以U.transpose()[:144,:]转换到图像像素基准上。现在较低的频率（代表了大多数方差）可以忽略不计了，较高的频率（代表相对少的方差）就被夸大了。<br><br>——————————————————————————————————————————<br><br><strong>实践操作:</strong>  在这个笔记中提到PCA和白化主要是为了介绍的完整性，实际上在卷积神经网络中并不会采用这些变换。然而对数据进行零中心化操作还是非常重要的，对每个像素进行归一化也很常见。<br><br><strong>常见错误:</strong> 进行预处理很重要的一点是：任何预处理策略（比如数据均值）都只能在训练集数据上进行计算，算法训练完毕后再应用到验证集或者测试集上。例如，如果先计算整个数据集图像的平均值然后每张图片都减去平均值，最后将整个数据集分成训练/验证/测试集，那么这个做法是错误的。<strong>应该怎么做呢？应该先分成训练/验证/测试集，只是从训练集中求图片平均值，然后各个集（训练/验证/测试集）中的图像再减去这个平均值。</strong><br><br><strong>译者注：此处确为初学者常见错误，请务必注意！</strong><br><br>### 权重初始化<br><br>我们已经看到如何构建一个神经网络的结构并对数据进行预处理，但是在开始训练网络之前，还需要初始化网络的参数。<br><br><strong>错误：全零初始化</strong>  让我们从应该避免的错误开始。在训练完毕后，虽然不知道网络中每个权重的最终值应该是多少，但如果数据经过了恰当的归一化的话，就可以假设所有权重数值中大约一半为正数，一半为负数。这样，一个听起来蛮合理的想法就是把这些权重的初始值都设为0吧，因为在期望上来说0是最合理的猜测。这个做法错误的！因为如果网络中的每个神经元都计算出同样的输出，然后它们就会在反向传播中计算出同样的梯度，从而进行同样的参数更新。换句话说，如果权重被初始化为同样的值，神经元之间就失去了不对称性的源头。<br><br><strong>小随机数初始化</strong> 因此，权重初始值要非常接近0又不能等于0。解决方法就是将权重初始化为很小的数值，以此来<em>打破对称性</em>。其思路是：如果神经元刚开始的时候是随机且不相等的，那么它们将计算出不同的更新，并将自身变成整个网络的不同部分。小随机数权重初始化的实现方法是： <strong>W = 0.01 * np.random.randn(D,H)</strong> 。其中 <strong>randn</strong> 函数是基于零均值和标准差的一个高斯分布（ <strong>译者注：国内教程一般习惯称均值参数为期望  $\mu$  </strong> ）来生成随机数的。根据这个式子，每个神经元的权重向量都被初始化为一个随机向量，而这些随机向量又服从一个多变量高斯分布，这样在输入空间中，所有的神经元的指向是随机的。也可以使用均匀分布生成的随机数，但是从实践结果来看，对于算法的结果影响极小。<br><br><strong>*警告</strong>   并不是小数值一定会得到好的结果。例如，一个神经网络的层中的权重值很小，那么在反向传播的时候就会计算出非常小的梯度（因为梯度与权重值是成比例的）。这就会很大程度上减小反向传播中的“梯度信号”，在深度网络中，就会出现问题。<br><br><strong>使用1/sqrt(n)校准方差</strong>  上面做法存在一个问题，随着输入数据量的增长，随机初始化的神经元的输出数据的分布中的方差也在增大。我们可以除以输入数据量的平方根来调整其数值范围，这样神经元输出的方差就归一化到1了。也就是说，建议将神经元的权重向量初始化为： <strong>w = np.random.randn(n) / sqrt(n)。</strong> 其中<strong>n</strong>是输入数据的数量。这样就保证了网络中所有神经元起始时有近似同样的输出分布。实践经验证明，这样做可以提高收敛的速度。<br><br>上述结论的推导过程如下：假设权重$w$和输入$x$之间的内积为$s=\sum^n_iw_ix_i$，这是还没有进行非线性激活函数运算之前的原始数值。我们可以检查$s$的方差：<br><br><center>$$\begin{align}\text{Var}(s) &amp;= \text{Var}(\sum_i^n w_ix_i) \&amp;= \sum_i^n \text{Var}(w_ix_i) \&amp;= \sum_i^n [E(w_i)]^2\text{Var}(x_i) + E[(x_i)]^2\text{Var}(w_i) + \text{Var}(x_i)\text{Var}(w_i) \&amp;= \sum_i^n \text{Var}(x_i)\text{Var}(w_i) \&amp;= \left( n \text{Var}(w) \right) \text{Var}(x)\end{align} $$</center>

<p>在前两步，使用了<a href="http://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Variance" target="_blank" rel="noopener"><strong>方差的性质</strong></a>。在第三步，因为假设输入和权重的平均值都是0，所以$E[x_i]=E[w_i]=0$。注意这并不是一般化情况，比如在ReLU单元中均值就为正。在最后一步，我们假设所有的$w_i,x_i$都服从同样的分布。从这个推导过程我们可以看见，如果想要$s$有和输入$x$一样的方差，那么在初始化的时候必须保证每个权重$w$的方差是$1/n$。又因为对于一个随机变量$X$和标量$a$，有$Var(aX)=a^2Var(X)$，这就说明可以基于一个标准高斯分布，然后乘以$a=\sqrt{1/n}$，使其方差为$1/n$)，于是得出：<strong>w = np.random.randn(n) / sqrt(n)</strong>。</p>
<p>Glorot等在论文<a href="http://link.zhihu.com/?target=http%3A//jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" target="_blank" rel="noopener"><strong>Understanding the difficulty of training deep feedforward neural networks</strong></a>中作出了类似的分析。在论文中，作者推荐初始化公式为$ ( \text{Var}(w) = 2/(n_{in} + n_{out}) ) $，其中$(n_{in}, n_{out})$是在前一层和后一层中单元的个数。这是基于妥协和对反向传播中梯度的分析得出的结论。该主题下最新的一篇论文是：<a href="http://link.zhihu.com/?target=http%3A//arxiv-web3.library.cornell.edu/abs/1502.01852" target="_blank" rel="noopener"><strong>Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</strong></a>，作者是He等人。文中给出了一种针对ReLU神经元的特殊初始化，并给出结论：网络中神经元的方差应该是$2.0/n$。代码为<strong>w = np.random.randn(n) * sqrt(2.0/n)</strong>。这个形式是神经网络算法使用ReLU神经元时的当前最佳推荐。</p>
<p><strong>稀疏初始化（Sparse initialization）</strong> 另一个处理非标定方差的方法是将所有权重矩阵设为0，但是为了打破对称性，每个神经元都同下一层固定数目的神经元随机连接（其权重数值由一个小的高斯分布生成）。一个比较典型的连接数目是10个。</p>
<p><strong>偏置（biases）的初始化</strong>  通常将偏置初始化为0，这是因为随机小数值权重矩阵已经打破了对称性。对于ReLU非线性激活函数，有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值，这是因为他们认为这样做能让所有的ReLU单元一开始就激活，这样就能保存并传播一些梯度。然而，这样做是不是总是能提高算法性能并不清楚（有时候实验结果反而显示性能更差），所以通常还是使用0来初始化偏置参数。</p>
<p><strong>实践</strong>  当前的推荐是使用ReLU激活函数，并且使用 <strong>w = np.random.randn(n) * sqrt(2.0/n)</strong> 来进行权重初始化，关于这一点，<a href="http://link.zhihu.com/?target=http%3A//arxiv-web3.library.cornell.edu/abs/1502.01852" target="_blank" rel="noopener"><strong>这篇文章</strong></a>有讨论。</p>
<p><strong>批量归一化（Batch Normalization）</strong> <a href="http://link.zhihu.com/?target=http%3A//arxiv.org/abs/1502.03167" target="_blank" rel="noopener"><strong>批量归一化</strong></a>是loffe和Szegedy最近才提出的方法，该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛：），其做法是让激活数据在训练开始前通过一个网络，网络处理数据使其服从标准高斯分布。因为归一化是一个简单可求导的操作，所以上述思路是可行的。在实现层面，应用这个技巧通常意味着全连接层（或者是卷积层，后续会讲）与激活函数之间添加一个BatchNorm层。对于这个技巧本节不会展开讲，因为上面的参考文献中已经讲得很清楚了，需要知道的是在神经网络中使用批量归一化已经变得非常常见。在实践中，使用了批量归一化的网络对于不好的初始值有更强的鲁棒性。最后一句话总结：批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起。搞定！</p>
<h3 id="正则化-Regularization"><a href="#正则化-Regularization" class="headerlink" title="正则化 Regularization"></a>正则化 Regularization</h3><p>有不少方法是通过控制神经网络的容量来防止其过拟合的：</p>
<p><strong>L2正则化</strong> 可能是最常用的正则化方法了。可以通过惩罚目标函数中所有参数的平方将其实现。即对于网络中的每个权重$w$，向目标函数中增加一个$\frac{1}{2}\lambda w^2$，其中$\lambda$是正则化强度。前面这个$\frac{1}{2}$很常见，是因为加上$\frac{1}{2}$后，该式子关于$w$梯度就是$\lambda w$而不是$2\lambda w$了。L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚，倾向于更加分散的权重向量。在线性分类章节中讨论过，由于输入和权重之间的乘法操作，这样就有了一个优良的特性：使网络更倾向于使用所有输入特征，而不是严重依赖输入特征中某些小部分特征。最后需要注意在梯度下降和参数更新的时候，使用L2正则化意味着所有的权重都以<strong>w += -lambda * W</strong>向着0线性下降。</p>
<p><strong>L1正则化</strong>  是另一个相对常用的正则化方法。对于每个$w$我们都向目标函数增加一个$\lambda|w|$。L1和L2正则化也可以进行组合：$\lambda_1|w|+\lambda_2w^2$，这也被称作<a href="http://link.zhihu.com/?target=http%3A//web.stanford.edu/%257Ehastie/Papers/B67.2%2520%25282005%2529%2520301-320%2520Zou%2520%26%2520Hastie.pdf" target="_blank" rel="noopener"><strong>Elastic net regularizaton</strong></a>。L1正则化有一个有趣的性质，它会让权重向量在最优化的过程中变得稀疏（即非常接近0）。也就是说，使用L1正则化的神经元最后使用的是它们最重要的输入数据的稀疏子集，同时对于噪音输入则几乎是不变的了。相较L1正则化，L2正则化中的权重向量大多是分散的小数字。在实践中，如果不是特别关注某些明确的特征选择，一般说来L2正则化都会比L1正则化效果好。</p>
<p><strong>最大范式约束（Max norm constraints）</strong> 另一种形式的正则化是给每个神经元中权重向量的量级设定上限，并使用投影梯度下降来确保这一约束。在实践中，与之对应的是参数更新方式不变，然后要求神经元中的权重向量$\overrightarrow{w}$必须满足$||\overrightarrow{w}||_2&lt;c$这一条件，一般$c$值为3或者4。有研究者发文称在使用这种正则化方法时效果更好。这种正则化还有一个良好的性质，即使在学习率设置过高的时候，网络中也不会出现数值“爆炸”，这是因为它的参数更新始终是被限制着的。</p>
<p><strong>随机失活（Dropout）</strong> 是一个简单又极其有效的正则化方法。该方法由Srivastava在论文<a href="http://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%257Ersalakhu/papers/srivastava14a.pdf" target="_blank" rel="noopener"><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong></a>中提出的，与L1正则化，L2正则化和最大范式约束等方法互为补充。在训练的时候，随机失活的实现方法是让神经元以超参数$p$的概率被激活或者被设置为0。</p>
<p>—————————————————————————————————————————</p>
<center><img src="https://github.com/heroinlin/picture_of_markdown/blob/master/cs231n/neural_nets/neural_nets_13.jpg?raw=true" width="400"></center><br>图片来源自 <a href="http://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%7Ersalakhu/papers/srivastava14a.pdf" target="_blank" rel="noopener"><strong>论文</strong></a>  ，展示其核心思路。在训练过程中，随机失活可以被认为是对完整的神经网络抽样出一些子集，每次基于输入数据只更新子网络的参数（然而，数量巨大的子网络们并不是相互独立的，因为它们都共享参数）。在测试过程中不使用随机失活，可以理解为是对数量巨大的子网络们做了模型集成（model ensemble），以此来计算出一个平均的预测。<br><br>—————————————————————————————————————————<br><br>一个3层神经网络的普通版随机失活可以用下面代码实现：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" 普通版随机失活: 不推荐实现 (看下面笔记) """</span></span><br><span class="line"></span><br><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="string">""" X中是输入数据 """</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = np.random.rand(*H1.shape) &lt; p <span class="comment"># 第一个随机失活遮罩</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = np.random.rand(*H2.shape) &lt; p <span class="comment"># 第二个随机失活遮罩</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure><br><br>在上面的代码中， <strong>train_step</strong> 函数在第一个隐层和第二个隐层上进行了两次随机失活。在输入层上面进行随机失活也是可以的，为此需要为输入数据 <strong>X创建</strong> 一个二值的遮罩。反向传播保持不变，但是肯定需要将遮罩 <strong>U1</strong> 和 <strong>U2</strong> 加入进去。<br><br>注意：在 <strong>predict</strong> 函数中不进行随机失活，但是对于两个隐层的输出都要乘以$p$，调整其数值范围。这一点非常重要，因为在测试时所有的神经元都能看见它们的输入，因此我们想要神经元的输出与训练时的预期输出是一致的。以$p=0.5$为例，在测试时神经元必须把它们的输出减半，这是因为在训练的时候它们的输出只有一半。为了理解这点，先假设有一个神经元$x$的输出，那么进行随机失活的时候，该神经元的输出就是$px+(1-p)0$)，这是有$1-p$的概率神经元的输出为0。在测试时神经元总是激活的，就必须调整$x\to px$来保持同样的预期输出。在测试时会在所有可能的二值遮罩（也就是数量庞大的所有子网络）中迭代并计算它们的协作预测，进行这种减弱的操作也可以认为是与之相关的。<br><br>上述操作不好的性质是必须在测试时对激活数据要按照$p$进行数值范围调整。既然测试性能如此关键，实际更倾向使用 <strong>反向随机失活（inverted dropout）</strong> ，它是在训练时就进行数值范围调整，从而让前向传播在测试时保持不变。这样做还有一个好处，无论你决定是否使用随机失活，预测方法的代码可以保持不变。反向随机失活的代码如下：<br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">""" </span></span><br><span class="line"><span class="string">反向随机失活: 推荐实现方式.</span></span><br><span class="line"><span class="string">在训练的时候drop和调整数值范围，测试时不做任何事.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># 第一个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = (np.random.rand(*H2.shape) &lt; p) / p <span class="comment"># 第二个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(X)</span>:</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) <span class="comment"># 不用数值范围调整了</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure><br><br>在随机失活发布后，很快有大量研究为什么它的实践效果如此之好，以及它和其他正则化方法之间的关系。如果你感兴趣，可以看看这些文献：<br><br>- <a href="http://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/%257Ersalakhu/papers/srivastava14a.pdf" target="_blank" rel="noopener"><strong>Dropout paper</strong></a> by Srivastava et al. 2014.<br>- <a href="http://link.zhihu.com/?target=http%3A//papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization.pdf" target="_blank" rel="noopener"><strong>Dropout Training as Adaptive Regularization</strong></a>：“我们认为：在使用费希尔信息矩阵（<a href="http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Fisher_information_metric" target="_blank" rel="noopener"><strong>fisher information matrix</strong></a>）的对角逆矩阵的期望对特征进行数值范围调整后，再进行L2正则化这一操作，与随机失活正则化是一阶相等的。”<br><br><strong>前向传播中的噪音</strong> 在更一般化的分类上，随机失活属于网络在前向传播中有随机行为的方法。测试时，通过<em>分析法</em>（在使用随机失活的本例中就是乘以$p$）或<em>数值法</em>（例如通过抽样出很多子网络，随机选择不同子网络进行前向传播，最后对它们取平均）将噪音边缘化。在这个方向上的另一个研究是<a href="http://link.zhihu.com/?target=http%3A//cs.nyu.edu/%257Ewanli/dropc/" target="_blank" rel="noopener"><strong>DropConnect</strong></a>，它在前向传播的时候，一系列权重被随机设置为0。提前说一下，卷积神经网络同样会吸取这类方法的优点，比如随机汇合（stochastic pooling），分级汇合（fractional pooling），数据增长（data augmentation）。我们在后面会详细介绍。<br><br><strong>偏置正则化</strong> 在线性分类器的章节中介绍过，对于偏置参数的正则化并不常见，因为它们在矩阵乘法中和输入数据并不产生互动，所以并不需要控制其在数据维度上的效果。然而在实际应用中（使用了合理数据预处理的情况下），对偏置进行正则化也很少会导致算法性能变差。这可能是因为相较于权重参数，偏置参数实在太少，所以分类器需要它们来获得一个很好的数据损失，那么还是能够承受的。<br><br><strong>每层正则化</strong> 对于不同的层进行不同强度的正则化很少见（可能除了输出层以外），关于这个思路的相关文献也很少。<br><br><strong>实践</strong> : 通过交叉验证获得一个全局使用的L2正则化强度是比较常见的。在使用L2正则化的同时在所有层后面使用随机失活也很常见。$p$值一般默认设为0.5，也可能在验证集上调参。<br><br>## 损失函数<br><br>我们已经讨论过损失函数的正则化损失部分，它可以看做是对模型复杂程度的某种惩罚。损失函数的第二个部分是<em>数据损失</em>，它是一个有监督学习问题，用于衡量分类算法的预测结果（即分类评分）和真实标签结果之间的一致性。数据损失是对所有样本的数据损失求平均。也就是说，$L=\frac{1}{N}\sum_iL_i$中，$N$是训练集数据的样本数。让我们把神经网络中输出层的激活函数简写为$f=f(x_i;W)$，在实际中你可能需要解决以下几类问题：<br><br><strong>分类问题</strong> 是我们一直讨论的。在该问题中，假设有一个装满样本的数据集，每个样本都有一个唯一的正确标签（是固定分类标签之一）。在这类问题中，一个最常见的损失函数就是SVM（是Weston Watkins 公式）：<br><br><center>$$L_i = \sum_{j\neq y_i} \max(0, f_j - f_{y_i} + 1)$$</center>

<p>之前简要提起过，有些学者的论文中指出平方折叶损失（即使用$max(0,f_j-f_{y_i}+1)^2$）算法的结果会更好。第二个常用的损失函数是Softmax分类器，它使用交叉熵损失：</p>
<center>$$L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)$$</center>

<p><strong>问题：类别数目巨大</strong> 当标签集非常庞大（例如字典中的所有英语单词，或者ImageNet中的22000种分类），就需要使用 <em>分层Softmax（ <strong>Hierarchical Softmax</strong> ）</em> 了（<a href="http://link.zhihu.com/?target=http%3A//arxiv.org/pdf/1310.4546.pdf" target="_blank" rel="noopener"><strong>参考文献</strong></a>）。分层softmax将标签分解成一个树。每个标签都表示成这个树上的一个路径，这个树的每个节点处都训练一个Softmax分类器来在左和右分枝之间做决策。树的结构对于算法的最终结果影响很大，而且一般需要具体问题具体分析。</p>
<p><strong>属性（Attribute）分类</strong> 上面两个损失公式的前提，都是假设每个样本只有一个正确的标签$y_i$。但是如果$y_i$是一个二值向量，每个样本可能有，也可能没有某个属性，而且属性之间并不相互排斥呢？比如在Instagram上的图片，就可以看成是被一个巨大的标签集合中的某个子集打上标签，一张图片上可能有多个标签。在这种情况下，一个明智的方法是为每个属性创建一个独立的二分类的分类器。例如，针对每个分类的二分类器会采用下面的公式：</p>
<center>$$L_i = \sum_j \max(0, 1 - y_{ij} f_j)$$</center>

<p>上式中，求和是对所有分类$j$，$y_{ij}$的值为1或者-1，具体根据第i个样本是否被第j个属性打标签而定，当该类别被正确预测并展示的时候，分值向量$f_j$为正，其余情况为负。可以发现，当一个正样本的得分小于+1，或者一个负样本得分大于-1的时候，算法就会累计损失值。</p>
<p>另一种方法是对每种属性训练一个独立的逻辑回归分类器。二分类的逻辑回归分类器只有两个分类（0，1），其中对于分类1的概率计算为：</p>
<center>$$P(y = 1 \mid x; w, b) = \frac{1}{1 + e^{-(w^Tx +b)}} = \sigma (w^Tx + b)$$</center>

<p>因为类别0和类别1的概率和为1，所以类别0的概率为：$\displaystyle P(y=0|x;w,b)=1-P(y=1|x;w,b)$。这样，如果$\sigma(w^Tx+b)&gt;0.5$或者$w^Tx+b&gt;0$，那么样本就要被分类成为正样本（y=1）。然后损失函数最大化这个对数似然函数，问题可以简化为：</p>
<center>$$L_i = \sum_j y_{ij} \log(\sigma(f_j)) + (1 - y_{ij}) \log(1 - \sigma(f_j))$$</center>

<p>上式中，假设标签$y_{ij}$非0即1，$\sigma(.)$就是sigmoid函数。上面的公式看起来吓人，但是$f$的梯度实际上非常简单：$\displaystyle \frac{\partial L_i}{\partial f_j}=y_{ij}-\sigma(f_j)$（你可以自己求导来验证）。</p>
<p><strong>回归问题</strong> 是预测实数的值的问题，比如预测房价，预测图片中某个东西的长度等。对于这种问题，通常是计算预测值和真实值之间的损失。然后用L2平方范式或L1范式度量差异。对于某个样本，L2范式计算如下：</p>
<center>$$L_i = \Vert f - y_i \Vert_2^2$$</center>

<p>之所以在目标函数中要进行平方，是因为梯度算起来更加简单。因为平方是一个单调运算，所以不用改变最优参数。L1范式则是要将每个维度上的绝对值加起来：</p>
<center>$$L_i = \Vert f - y_i \Vert_1 = \sum_j \mid f_j - (y_i)_j \mid$$</center>

<p>在上式中，如果有多个数量被预测了，就要对预测的所有维度的预测求和，即$\sum_j$。观察第i个样本的第j维，用$\delta_{ij}$表示预测值与真实值之间的差异。关于该维度的梯度（也就是$\partial L_i/\partial f_j$）能够轻松地通过被求导为L2范式的$\delta_{ij}$或$sign(\delta_{ij})$。这就是说，评分值的梯度要么与误差中的差值直接成比例，要么是固定的并从差值中继承sign。</p>
<p><em>注意</em>：L2损失比起较为稳定的Softmax损失来，其最优化过程要困难很多。直观而言，它需要网络具备一个特别的性质，即对于每个输入（和增量）都要输出一个确切的正确值。而在Softmax中就不是这样，每个评分的准确值并不是那么重要：只有当它们量级适当的时候，才有意义。还有，L2损失鲁棒性不好，因为异常值可以导致很大的梯度。所以在面对一个回归问题时，先考虑将输出变成二值化是否真的不够用。例如，如果对一个产品的星级进行预测，使用5个独立的分类器来对1-5星进行打分的效果一般比使用一个回归损失要好很多。分类还有一个额外优点，就是能给出关于回归的输出的分布，而不是一个简单的毫无把握的输出值。如果确信分类不适用，那么使用L2损失吧，但是一定要谨慎：L2非常脆弱，在网络中使用随机失活（尤其是在L2损失层的上一层）不是好主意。</p>
<blockquote>
<p>当面对一个回归任务，首先考虑是不是必须这样。一般而言，尽量把你的输出变成二分类，然后对它们进行分类，从而变成一个分类问题。</p>
</blockquote>
<p><strong>结构化预测（structured prediction）</strong> 结构化损失是指标签可以是任意的结构，例如图表、树或者其他复杂物体的情况。通常这种情况还会假设结构空间非常巨大，不容易进行遍历。结构化SVM背后的基本思想就是在正确的结构$y_i$和得分最高的非正确结构之间画出一个边界。解决这类问题，并不是像解决一个简单无限制的最优化问题那样使用梯度下降就可以了，而是需要设计一些特殊的解决方案，这样可以有效利用对于结构空间的特殊简化假设。我们简要地提一下这个问题，但是详细内容就超出本课程范围。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>小结如下：</p>
<ul>
<li>推荐的预处理操作是对数据的每个特征都进行零中心化，然后将其数值范围都归一化到[-1,1]范围之内。</li>
<li>使用标准差为$\sqrt{2/n}$的高斯分布来初始化权重，其中<img src="http://www.zhihu.com/equation?tex=n" alt="n">是输入的神经元数。例如用numpy可以写作：<strong>w = np.random.randn(n) * sqrt(2.0/n)</strong>。</li>
<li>使用L2正则化和随机失活的倒置版本。</li>
<li>使用批量归一化。</li>
<li>讨论了在实践中可能要面对的不同任务，以及每个任务对应的常用损失函数。</li>
</ul>
<p>现在，我们预处理了数据，初始化了模型。在下一节中，我们将讨论算法的学习过程及其运作特性。</p>
<blockquote>
<p>译自斯坦福CS231n课程笔记<a href="http://link.zhihu.com/?target=http%3A//cs231n.github.io/neural-networks-2/" target="_blank" rel="noopener"><strong>Neural Nets notes 2</strong></a>，课程教师<a href="http://link.zhihu.com/?target=http%3A//cs.stanford.edu/people/karpathy/" target="_blank" rel="noopener"><strong>Andrej Karpathy</strong></a>授权翻译。本篇教程由<a href="https://www.zhihu.com/people/du-ke" target="_blank" rel="noopener">杜客</a>翻译完成，<a href="https://www.zhihu.com/people/kun-kun-97-81" target="_blank" rel="noopener">堃堃</a>进行校对修改</p>
<p>知乎地址：<a href="https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21560667?refer=intelligentunit</a></p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Vorherige Seite"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Nächste Seite"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/leaf.jpg"
                alt="Heroinlin"/>
            
              <p class="site-author-name" itemprop="name">Heroinlin</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">35</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">Kategorien</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">59</span>
                    <span class="site-state-item-name">schlagwörter</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/heroinlin" title="GitHub &rarr; https://github.com/heroinlin" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="/heroinlj@gmail.com" title="E-Mail &rarr; heroinlj@gmail.com"><i class="fa fa-fw fa-gmail"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://twitter.com/Heroin" title="Twitter &rarr; https://twitter.com/Heroin" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Heroinlin</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.6.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.1.2</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script src="/lib/fancybox/source/jquery.fancybox.pack.js"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  



  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
