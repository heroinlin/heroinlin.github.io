<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.1.2"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/leaf.jpg?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/leaf.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/leaf1.ico?v=7.1.2">


  <link rel="mask-icon" href="/images/leaf.jpg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Heroinlin&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Heroinlin&#39;s Blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Heroinlin&#39;s Blog">





  
  
  <link rel="canonical" href="http://yoursite.com/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Heroinlin's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Heroinlin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Cambiar a barra de navegación">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>Inicio</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>Etiquetas</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>Categorías</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>Archivo</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br/>Calendario</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/10/Python/Python_Struct/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/10/10/Python/Python_Struct/" class="post-title-link" itemprop="url">python之Struct解析二进制数据</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-10-10 10:48:11" itemprop="dateCreated datePublished" datetime="2018-10-10T10:48:11+08:00">2018-10-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-11 17:10:28" itemprop="dateModified" datetime="2018-10-11T17:10:28+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#python之解析二进制数据</p>
<p>struct模块中最重要的三个函数是pack(), unpack(), calcsize()</p>
<h2 id="struct模块中的函数"><a href="#struct模块中的函数" class="headerlink" title="struct模块中的函数"></a>struct模块中的函数</h2><table>
<thead>
<tr>
<th>函数</th>
<th>return</th>
<th>explain</th>
</tr>
</thead>
<tbody>
<tr>
<td>pack(fmt,v1,v2…)</td>
<td>string</td>
<td>按照给定的格式(fmt),把数据封装成字符串(实际上是类似于c结构体的字节流),并将该字符串返回.</td>
</tr>
<tr>
<td>pack_into(fmt,buffer,offset,v1,v2…)</td>
<td>None</td>
<td>按照给定的格式(fmt),将数据转换成字符串(字节流),并将字节流写入以offset开始的buffer中.(buffer为可写的缓冲区,可用array模块)</td>
</tr>
<tr>
<td>unpack(fmt,v1,v2…..)</td>
<td>tuple</td>
<td>按照给定的格式(fmt)解析字节流,并返回解析出来的tuple</td>
</tr>
<tr>
<td>pack_from(fmt,buffer,offset)</td>
<td>tuple</td>
<td>按照给定的格式(fmt)解析以offset开始的缓冲区,并返回解析结果</td>
</tr>
<tr>
<td>calcsize(fmt)</td>
<td>size of fmt</td>
<td>计算给定的格式(fmt)占用多少字节的内存，注意对齐方式</td>
</tr>
</tbody>
</table>
<h2 id="格式化字符串"><a href="#格式化字符串" class="headerlink" title="格式化字符串"></a>格式化字符串</h2><p>当打包或者解包的时,需要按照特定的方式来打包或者解包.该方式就是格式化字符串,它指定了数据类型,除此之外,还有用于控制字节顺序、大小和对齐方式的特殊字符.</p>
<h3 id="对齐方式"><a href="#对齐方式" class="headerlink" title="对齐方式"></a>对齐方式</h3><p>为了同c中的结构体交换数据，还要考虑c或c++编译器使用了字节对齐，通常是以4个字节为单位的32位系统，故而struct根据本地机器字节顺序转换.可以用格式中的第一个字符来改变对齐方式.定义如下</p>
<table>
<thead>
<tr>
<th>Character</th>
<th>Byte order</th>
<th>Size</th>
<th>Alignment</th>
</tr>
</thead>
<tbody>
<tr>
<td>@(默认)</td>
<td>本机(native)</td>
<td>本机(native)</td>
<td>本机,凑够4字节</td>
</tr>
<tr>
<td>=</td>
<td>本机(native)</td>
<td>标准(standard)</td>
<td>none,按原字节数</td>
</tr>
<tr>
<td>&lt;</td>
<td>小端(little-endian)</td>
<td>标准(standard)</td>
<td>none,按原字节数</td>
</tr>
<tr>
<td>&gt;</td>
<td>大端(big-endian)</td>
<td>标准(standard)</td>
<td>none,按原字节数</td>
</tr>
<tr>
<td>!</td>
<td>network(=big-endian)</td>
<td>标准(standard)</td>
<td>none,按原字节数</td>
</tr>
</tbody>
</table>
<h3 id="格式符"><a href="#格式符" class="headerlink" title="格式符"></a>格式符</h3><table>
<thead>
<tr>
<th>格式符</th>
<th>C语言类型</th>
<th>Python类型</th>
<th>Standard size</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>pad byte(填充字节)</td>
<td>no value</td>
<td></td>
</tr>
<tr>
<td>c</td>
<td>char</td>
<td>string of length 1</td>
<td>1</td>
</tr>
<tr>
<td>b</td>
<td>signed char</td>
<td>integer</td>
<td>1</td>
</tr>
<tr>
<td>B</td>
<td>unsigned char</td>
<td>integer</td>
<td>1</td>
</tr>
<tr>
<td>?</td>
<td>_Bool</td>
<td>bool</td>
<td>1</td>
</tr>
<tr>
<td>h</td>
<td>short</td>
<td>integer</td>
<td>2</td>
</tr>
<tr>
<td>H</td>
<td>unsigned short</td>
<td>integer</td>
<td>2</td>
</tr>
<tr>
<td>i</td>
<td>int</td>
<td>integer</td>
<td>4</td>
</tr>
<tr>
<td>I(大写的i)</td>
<td>unsigned int</td>
<td>integer</td>
<td>4</td>
</tr>
<tr>
<td>l(小写的L)</td>
<td>long</td>
<td>integer</td>
<td>4</td>
</tr>
<tr>
<td>L</td>
<td>unsigned long</td>
<td>long</td>
<td>4</td>
</tr>
<tr>
<td>q</td>
<td>long long</td>
<td>long</td>
<td>8</td>
</tr>
<tr>
<td>Q</td>
<td>unsigned long long</td>
<td>long</td>
<td>8</td>
</tr>
<tr>
<td>f</td>
<td>float</td>
<td>float</td>
<td>4</td>
</tr>
<tr>
<td>d</td>
<td>double</td>
<td>float</td>
<td>8</td>
</tr>
<tr>
<td>s</td>
<td>char[]</td>
<td>string</td>
<td>1</td>
</tr>
<tr>
<td>p</td>
<td>char[]</td>
<td>string</td>
<td>1</td>
</tr>
<tr>
<td>P</td>
<td>void *</td>
<td>long</td>
</tr>
</tbody>
</table>
<p>注- -!</p>
<ol>
<li>_Bool在C99中定义,如果没有这个类型,则将这个类型视为char,一个字节;</li>
<li>q和Q只适用于64位机器;</li>
<li>每个格式前可以有一个数字,表示这个类型的个数,如s格式表示一定长度的字符串,4s表示长度为4的字符串;4i表示四个int; 但是p表示的是pascal字符串</li>
<li>P用来转换一个指针,其长度和机器字长相关;</li>
<li>f和d的长度和机器字长相关;</li>
</ol>
<h2 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h2><p>以下代码以person的属性进行二进制文件的写入和读取，person包含姓名，年龄，性别，身高，体重，并赋予力量，智力，体力，敏捷，精神五个特征值，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">import</span> struct</span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">二进制文件的写入和读取</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">(file_path)</span>:</span></span><br><span class="line">    person = []</span><br><span class="line">    file = open(file_path, <span class="string">"rb"</span>)</span><br><span class="line">    name = file.read(<span class="number">8</span>)</span><br><span class="line">    name = struct.unpack(<span class="string">'&lt;8s'</span>, name)[<span class="number">0</span>]</span><br><span class="line">    male = file.read(<span class="number">1</span>)</span><br><span class="line">    male = struct.unpack(<span class="string">'&lt;b'</span>, male)[<span class="number">0</span>]</span><br><span class="line">    age = file.read(<span class="number">2</span>)</span><br><span class="line">    age = struct.unpack(<span class="string">'&lt;H'</span>, age)[<span class="number">0</span>]</span><br><span class="line">    height = file.read(<span class="number">4</span>)</span><br><span class="line">    height = int.from_bytes(height, byteorder=<span class="string">'little'</span>)</span><br><span class="line">    <span class="comment"># height = struct.unpack('&lt;I', height)[0]</span></span><br><span class="line">    weight = file.read(<span class="number">4</span>)</span><br><span class="line">    weight = struct.unpack(<span class="string">'&lt;f'</span>, weight)[<span class="number">0</span>]</span><br><span class="line">    feature_size = file.read(<span class="number">4</span>)</span><br><span class="line">    feature_size = int.from_bytes(feature_size, byteorder=<span class="string">'little'</span>)</span><br><span class="line">    features = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(feature_size//<span class="number">4</span>):</span><br><span class="line">        feature_value = file.read(<span class="number">4</span>)</span><br><span class="line">        feature_value = struct.unpack(<span class="string">'&lt;f'</span>, feature_value)[<span class="number">0</span>]</span><br><span class="line">        features.append(feature_value)</span><br><span class="line">    person.append(&#123;</span><br><span class="line">        <span class="string">"name"</span>: name,</span><br><span class="line">        <span class="string">"male"</span>: male,</span><br><span class="line">        <span class="string">"age"</span>: age,</span><br><span class="line">        <span class="string">"height"</span>: height,</span><br><span class="line">        <span class="string">"weight"</span>: weight,</span><br><span class="line">        <span class="string">"feature_size"</span>: feature_size,</span><br><span class="line">        <span class="string">"features"</span>: features,</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">return</span> person</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_file</span><span class="params">(file_path, person, features)</span>:</span></span><br><span class="line">    file = open(file_path, <span class="string">"wb"</span>)</span><br><span class="line">    <span class="comment"># file.seek(0, 2)</span></span><br><span class="line">    <span class="comment"># 把字符串的地方转为字节类型,还要先转成utf-8的编码(否则报错string argument without an encoding)</span></span><br><span class="line">    name = struct.pack(<span class="string">'&lt;8s'</span>, person[<span class="string">'name'</span>].encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    file.write(name)</span><br><span class="line">    male = struct.pack(<span class="string">'&lt;B'</span>, person[<span class="string">'male'</span>])</span><br><span class="line">    file.write(male)</span><br><span class="line">    age = struct.pack(<span class="string">'&lt;H'</span>, person[<span class="string">'age'</span>])</span><br><span class="line">    file.write(age)</span><br><span class="line">    height = struct.pack(<span class="string">'&lt;I'</span>, person[<span class="string">'height'</span>])</span><br><span class="line">    file.write(height)</span><br><span class="line">    weight = struct.pack(<span class="string">'&lt;f'</span>, person[<span class="string">'weight'</span>])</span><br><span class="line">    file.write(weight)</span><br><span class="line">    features_size = struct.pack(<span class="string">'&lt;I'</span>, <span class="number">5</span>*<span class="number">4</span>)</span><br><span class="line">    file.write(features_size)</span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> features.items():</span><br><span class="line">        feature_value = struct.pack(<span class="string">'&lt;f'</span>, value)</span><br><span class="line">        file.write(feature_value)</span><br><span class="line">    file.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    person = OrderedDict()</span><br><span class="line">    person.update(&#123;<span class="string">'name'</span>: <span class="string">'Jame'</span>&#125;)</span><br><span class="line">    person.update(&#123;<span class="string">'male'</span>: <span class="keyword">True</span>&#125;)</span><br><span class="line">    person.update(&#123;<span class="string">'age'</span>: <span class="number">25</span>&#125;)</span><br><span class="line">    person.update(&#123;<span class="string">'height'</span>: <span class="number">178</span>&#125;)</span><br><span class="line">    person.update(&#123;<span class="string">'weight'</span>: <span class="number">64.0</span>&#125;)</span><br><span class="line">    features = &#123;<span class="string">'Strength'</span>: <span class="number">54.0</span>,  <span class="comment"># 力量</span></span><br><span class="line">                <span class="string">'Intelligence'</span>: <span class="number">78.0</span>,  <span class="comment"># 智力</span></span><br><span class="line">                <span class="string">'Constitution'</span>: <span class="number">32.0</span>,  <span class="comment"># 体力</span></span><br><span class="line">                <span class="string">'Dexterity'</span>: <span class="number">78.0</span>,  <span class="comment"># 敏捷</span></span><br><span class="line">                <span class="string">'Mentality'</span>: <span class="number">53.0</span>  <span class="comment"># 精神</span></span><br><span class="line">                &#125;</span><br><span class="line">    file_path = <span class="string">"./person_info.pkg"</span></span><br><span class="line">    write_file(file_path, person, features)</span><br><span class="line">    person_info = read_file(file_path)</span><br><span class="line">    print(person_info)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p>注意：二进制文件处理时会碰到的问题</p>
<p>我们使用处理二进制文件时，需要用如下方法</p>
<p>binfile=open(filepath,’rb’)    读二进制文件</p>
<p>binfile=open(filepath,’wb’)    写二进制文件</p>
<p>那么和binfile=open(filepath,’r’)的结果到底有何不同呢？</p>
<p>不同之处有两个地方：</p>
<p>第一，使用’r’的时候如果碰到’0x1A’，就会视为文件结束，这就是EOF。使用’rb’则不存在这个问题。即，如果你用二进制写入再用文本读出的话，如果其中存在’0X1A’，就只会读出文件的一部分。使用’rb’的时候会一直读到文件末尾。</p>
<p>第二，对于字符串x=’abc\ndef’，我们可用len(x)得到它的长度为7，\n我们称之为换行符，实际上是’0X0A’。当我们用’w’即文本方式写的时候，在windows平台上会自动将’0X0A’变成两个字符’0X0D’，’0X0A’，即文件长度实际上变成8.。当用’r’文本方式读取时，又自动的转换成原来的换行符。如果换成’wb’二进制方式来写的话，则会保持一个字符不变，读取时也是原样读取。所以如果用文本方式写入，用二进制方式读取的话，就要考虑这多出的一个字节了。’0X0D’又称回车符。Linux下不会变。因为linux只使用’0X0A’来表示换行。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://kaiyuan.me/2015/12/25/python-struct/" target="_blank" rel="noopener">Python 中 struct 模块的用法</a></p>
<p><a href="https://www.jianshu.com/p/d03310004668" target="_blank" rel="noopener">Python学习笔记 –struct模板</a></p>
<p><a href="https://sanyuesha.com/2018/03/10/why-pack-unpack/" target="_blank" rel="noopener">Python 中的 pack 和 unpack</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/10/Python/Python_JSON_and_Pickle/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/10/10/Python/Python_JSON_and_Pickle/" class="post-title-link" itemprop="url">python之JSON与Pickle</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-10-10 10:48:11" itemprop="dateCreated datePublished" datetime="2018-10-10T10:48:11+08:00">2018-10-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-12 14:28:18" itemprop="dateModified" datetime="2018-10-12T14:28:18+08:00">2018-10-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#python之数据持久化</p>
<p>Python的数据持久化方式有很多种，JSON与Pickle是其中两种比较好用又相对轻量级的。两者的使用方式非常相近。</p>
<h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><p>python中处理JSON的库就是json模块，需要用到的方法大致就是以下4个，其实它们的参数有很多这里暂且省略。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">person = &#123;<span class="string">'姓名'</span>: <span class="string">'Jame'</span>, <span class="string">'年龄'</span> : <span class="number">27</span>&#125;</span><br><span class="line">fp = open(<span class="string">'person.json'</span>, <span class="string">'w'</span>)</span><br><span class="line">json.dump(person, fp)</span><br><span class="line">fp.close()</span><br><span class="line">person_info = json.dumps(person)</span><br><span class="line">x = json.load(open(<span class="string">'person.json'</span>, <span class="string">'r'</span>))</span><br><span class="line">y = json.loads(person_info)</span><br></pre></td></tr></table></figure>
<p>可以看到，结尾带s就是在字符串层面上操作，如果不带s就是在文件层级操作。person是需要转化的对象，可以是一个字典或者列表。</p>
<p>dumps返回的是一个字符串，load和loads则会返回python的对象。</p>
<p>以上是最简单的一些使用方式，这里还有一些实用的参数可以选择。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import json</span><br><span class="line">obj = &#123;u&apos;姓名&apos; : u&apos;无名氏&apos;, u&apos;国籍&apos; : u&apos;中国&apos;&#125;</span><br><span class="line">s = json.dumps(obj, ensure_ascii=False, indent=4)</span><br><span class="line">obj2 = json.loads(s, encoding=&apos;utf8&apos;)</span><br></pre></td></tr></table></figure>
<p>ensure_ascii参数，是在有中文的情况下，设置为False可以防止将其解码而得到乱码，在loads的时候可以指定encoding来保持编码。</p>
<p>indent参数如果不指定的话，输出的字符串就是紧凑的形式，indent指定为4就可以输出缩进为4的pretty形式，在需要给人看的时候用这个不错。</p>
<h3 id="JSON序列化datetime问题"><a href="#JSON序列化datetime问题" class="headerlink" title="JSON序列化datetime问题"></a>JSON序列化datetime问题</h3><p>python自己的json.dumps不能序列化datetime对象，如果需要dump这类对象时可以自己定义JSONEncoder</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> date, datetime</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdvEncoder</span><span class="params">(json.JSONEncoder)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">default</span><span class="params">(self, obj)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(obj, datetime):</span><br><span class="line">            <span class="keyword">return</span> obj.strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>)</span><br><span class="line">        <span class="keyword">elif</span> isinstance(obj, date):</span><br><span class="line">            <span class="keyword">return</span> obj.strftime(<span class="string">'%Y-%m-%d'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> super().default(self, obj)</span><br><span class="line"></span><br><span class="line">obj = &#123;&#125;</span><br><span class="line">json.dumps(obj, cls=MyEncoder)</span><br></pre></td></tr></table></figure>
<p>这样在dump时指定cls参数就可以完成序列化datetime的任务了，如果觉得麻烦的话，可以使用偏函数的方法自己封装一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line">adumps = functools.partial(json.dumps, cls=AdvEncoder)</span><br><span class="line">d = datetime.now()</span><br><span class="line">adumps(d)</span><br></pre></td></tr></table></figure>
<h2 id="Pickle"><a href="#Pickle" class="headerlink" title="Pickle"></a>Pickle</h2><p>常用的函数和JSON的相同，这里只介绍一下dump与load。</p>
<h3 id="函数说明"><a href="#函数说明" class="headerlink" title="函数说明"></a>函数说明</h3><p>Python中可以使用 pickle 模块将对象转化为文件保存在磁盘上，在需要的时候再读取并还原。具体用法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`pickle.dump(obj, ``file``[, protocol])`</span><br></pre></td></tr></table></figure>
<p>这是将对象持久化的方法，参数的含义分别为：<br><strong>obj</strong>: 要持久化保存的对象；<br><strong>file</strong>: 一个拥有 <em>write()</em> 方法的对象，并且这个 <em>write()</em> 方法能接收一个字符串作为参数。这个对象可以是一个以写模式打开的文件对象或者一个 StringIO 对象，或者其他自定义的满足条件的对象。<br><strong>protocol</strong>: 这是一个可选的参数，默认为 0 ，如果设置为 1 或 True，则以高压缩的二进制格式保存持久化后的对象，否则以ASCII格式保存，设置为负数与0相同。</p>
<p>对象被持久化后怎么还原呢？pickle 模块也提供了相应的方法，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`pickle.load(``file``)`</span><br></pre></td></tr></table></figure>
<p>只有一个参数 file ，对应于上面 dump 方法中的 file 参数。这个 file 必须是一个拥有一个能接收一个整数为参数的 <em>read()</em> 方法以及一个不接收任何参数的 <em>readline()</em> 方法，并且这两个方法的返回值都应该是字符串。这可以是一个打开为读的文件对象、StringIO 对象或其他任何满足条件的对象。</p>
<h3 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">person = &#123;<span class="string">'姓名'</span>: <span class="string">'Jame'</span>, <span class="string">'年龄'</span> : <span class="number">27</span>&#125;</span><br><span class="line">list_obj = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">f = open(<span class="string">'person.pkl'</span>, <span class="string">'wb'</span>)</span><br><span class="line">pickle.dump(person, f, protocol=<span class="number">-1</span>)</span><br><span class="line">pickle.dump(list_obj, f, protocol=<span class="number">-1</span>)</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">f = open(<span class="string">'person.pkl'</span>, <span class="string">'rb'</span>)</span><br><span class="line">person_info = pickle.load(f)</span><br><span class="line">list_obj_info = pickle.load(f)</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
<p>可以看出上面的程序在文件里存储了2个对象，load的时候可以执行2次，person_info得到的是之前person的对象，list_obj_info的是之前list_obj的对象。不要写成这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">person_info = pickle.load(open(<span class="string">'person.pkl'</span>, <span class="string">'rb'</span>))</span><br><span class="line">list_obj_info = pickle.load(open(<span class="string">'person.pkl'</span>, <span class="string">'rb'</span>))</span><br></pre></td></tr></table></figure>
<p>这样得到的person_info,list_obj_info都是person_info的对象，原因嘛，可以想一想文件操作的方式，很好理解。</p>
<p>但存储了几个对象就只能load几次，如果load超过了存储的对象，会抛出EOFError异常。</p>
<p>可以用下面这种方式进行修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">person = &#123;<span class="string">'姓名'</span>: <span class="string">'Jame'</span>, <span class="string">'年龄'</span> : <span class="number">27</span>&#125;</span><br><span class="line">list_obj = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">f = open(<span class="string">'person.pkl'</span>, <span class="string">'wb'</span>)</span><br><span class="line">pickle.dump([person, list_obj], f, protocol=<span class="number">-1</span>)</span><br><span class="line">f.close()</span><br><span class="line"><span class="comment"># all_infos = pickle.load(open('person.pkl', 'rb'))</span></span><br><span class="line"><span class="comment"># person_info = all_infos[0]</span></span><br><span class="line"><span class="comment"># list_obj_info = all_infos[1]</span></span><br><span class="line">person_info = pickle.load(open(<span class="string">'person.pkl'</span>, <span class="string">'rb'</span>))[<span class="number">0</span>]</span><br><span class="line">list_obj_info = pickle.load(open(<span class="string">'person.pkl'</span>, <span class="string">'rb'</span>))[<span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<p>这里能够存储的对象可以是任意对象，字典、列表、元组、numpy数组、SocketServer…..</p>
<p>另外，pickle 模块还提供 dumps 和 loads 两个方法，用法与上面的 dump 和 load 方法类似，只是不需要输入 file 参数，输入及输出都是字符串对象，有些场景中使用这两个方法可能更为方便。</p>
<h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><p>官方文档中对于这2者也有一段比较的话，我就直接拿来用了</p>
<ul>
<li>JSON是文本形式的存储，Pickle则是二进制形式（至少常用二进制）</li>
<li>JSON是人可读的，Pickle不可读</li>
<li>JSON广泛应用于除Python外的其他领域，Pickle是Python独有的。</li>
<li>JSON只能dump一些python的内置对象，Pickle可以存储几乎所有对象。</li>
</ul>
<p>在我看来，如果偏向应用特别是web应用方面，可以常用JSON格式。如果偏向算法方面，尤其是机器学习，则应该使用cPickle，pylearn2库中保存model就是使用这项技术的。</p>
<p>至于重量级的那就很多了，基本都跟数据库有关。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://brieflyx.me/2015/python-module/python-data-persistence/" target="_blank" rel="noopener">Python 数据持久化方式——JSON与Pickle</a></p>
<p><a href="https://blog.oldj.net/2010/05/26/python-pickle/" target="_blank" rel="noopener">Python中使用pickle持久化对象</a></p>
<p><a href="http://www.isware.cn/python-modules/01-data-persistence-and-exchange/pickle/" target="_blank" rel="noopener">[Python常用库]pickle</a></p>
<p><a href="https://python-cookbook.readthedocs.io/zh_CN/stable/c05/p21_serializing_python_objects.html" target="_blank" rel="noopener">序列化Python对象</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/10/Python/Python_argparse/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/10/10/Python/Python_argparse/" class="post-title-link" itemprop="url">python之argparse命令行选项与参数解析</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-10-10 10:48:11" itemprop="dateCreated datePublished" datetime="2018-10-10T10:48:11+08:00">2018-10-10</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-12 14:14:16" itemprop="dateModified" datetime="2018-10-12T14:14:16+08:00">2018-10-12</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="python之argparse命令行选项与参数解析"><a href="#python之argparse命令行选项与参数解析" class="headerlink" title="python之argparse命令行选项与参数解析"></a>python之argparse命令行选项与参数解析</h1><p>argparse 是 Python 内置的一个用于命令项选项与参数解析的模块，通过在程序中定义好我们需要的参数，argparse 将会从 sys.argv 中解析出这些参数，并自动生成帮助和使用信息。当然，Python 也有第三方的库可用于命令行解析，而且功能也更加强大，比如 <a href="http://docopt.org/" target="_blank" rel="noopener">docopt</a>，<a href="http://click.pocoo.org/5/" target="_blank" rel="noopener">Click</a>。</p>
<h2 id="Argparse使用方法"><a href="#Argparse使用方法" class="headerlink" title="Argparse使用方法"></a>Argparse使用方法</h2><h3 id="创建-ArgumentParser-对象"><a href="#创建-ArgumentParser-对象" class="headerlink" title="创建 ArgumentParser() 对象"></a>创建 ArgumentParser() 对象</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ArgumentParser(prog=<span class="keyword">None</span>, usage=<span class="keyword">None</span>, description=<span class="keyword">None</span>, epilog=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>prog（不建议更改）<br>程序名称(默认sys.argv[0]，默认为函数文件名)，设置prog则改变这一默认。假设在 <code>example.py</code> 里用了 <code>ArguemntParser</code> ，而且没有特别指定 <code>prog</code>  ( <code>None</code>)， <code>prog</code> 会被自动指定成<code>example.py</code> 。</p>
</li>
<li><p>usage（不建议更改）</p>
<p>用于描述程序的使用用法（默认为添加到解析器中的参数）。在使用<code>python xxx.py -h</code>之后将出现。保持 <code>None</code> 会自动根据设定的参数产生相对应的说明字串。</p>
</li>
<li><p>description</p>
<p>字串，通常是一段简短的说明，告知使用者该程序的用途。</p>
</li>
<li><p>epilog</p>
<p>字串，出现在参数说明字串的最后，通常是一些补充资料。</p>
</li>
</ul>
<p>可通过以下代码查看具体情形</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.py</span></span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> ArgumentParser</span><br><span class="line">parser1 = ArgumentParser()</span><br><span class="line">parser2 = ArgumentParser(prog=<span class="string">"my_example"</span>)</span><br><span class="line">parser3 = ArgumentParser(usage=<span class="string">"usage"</span>)</span><br><span class="line">parser4 = ArgumentParser(description=<span class="string">"a simple demo of argparse"</span>)</span><br><span class="line">parser5 = ArgumentParser(epilog=<span class="string">"see the doc: https://docs.python.org/3/library/argparse.html"</span>)</span><br><span class="line">parser1.print_help()</span><br><span class="line">parser2.print_help()</span><br><span class="line">parser3.print_help()</span><br><span class="line">parser4.print_help()</span><br><span class="line">parser5.print_help()</span><br></pre></td></tr></table></figure>
<h3 id="调用-add-argument-方法添加参数"><a href="#调用-add-argument-方法添加参数" class="headerlink" title="调用 add_argument() 方法添加参数"></a>调用 add_argument() 方法添加参数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ArgumentParser.add_argument(name <span class="keyword">or</span> flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])</span><br></pre></td></tr></table></figure>
<ul>
<li>name or flags - 选项字符串的名字或者列表，例如 foo 或者 -f, –foo。</li>
<li>action - 命令行遇到参数时的动作，默认值是 store。<ul>
<li>store_const，表示赋值为const；</li>
<li>append，将遇到的值存储成列表，也就是如果参数重复则会保存多个值;</li>
<li>append_const，将参数规范中定义的一个值保存到一个列表；</li>
<li>count，存储遇到的次数；此外，也可以继承 argparse.Action 自定义参数解析；</li>
</ul>
</li>
<li>nargs - 应该读取的命令行参数个数，可以是具体的数字，或者是?号，当不指定值时对于 Positional argument 使用 default，对于 Optional argument 使用 const；或者是 * 号，表示 0 或多个参数；或者是 + 号表示 1 或多个参数。</li>
<li>const - action 和 nargs 所需要的常量值。</li>
<li>default - 不指定参数时的默认值。</li>
<li>type - 命令行参数应该被转换成的类型。</li>
<li>choices - 参数可允许的值的一个容器。</li>
<li>required - 可选参数是否可以省略 (仅针对可选参数)。</li>
<li>help - 参数的帮助信息，当指定为 <code>argparse.SUPPRESS</code> 时表示不显示该参数的帮助信息.</li>
<li>metavar - 在 usage 说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称.</li>
<li>dest - 解析后的参数名称，默认情况下，对于可选参数选取最长的名称，中划线转换为下划线.</li>
</ul>
<h3 id="互斥参数"><a href="#互斥参数" class="headerlink" title="互斥参数"></a>互斥参数</h3><p>另外介绍下互斥参数的设置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">group = parser.add_mutually_exclusive_group() </span><br><span class="line">group.add_argument(<span class="string">"-v"</span>, <span class="string">"--verbose"</span>, action=<span class="string">"store_true"</span>) </span><br><span class="line">group.add_argument(<span class="string">"-q"</span>, <span class="string">"--quiet"</span>, action=<span class="string">"store_true"</span>)</span><br></pre></td></tr></table></figure>
<p>第一行定义了一个互斥组，第二、三行在互斥组中添加了<code>-v</code>和<code>-q</code>两个参数，<code>-q</code>和<code>-v</code>不出现，或仅出现一个都可以，同时出现就会报错。</p>
<h3 id="使用-parse-args-解析添加的参数"><a href="#使用-parse-args-解析添加的参数" class="headerlink" title="使用 parse_args() 解析添加的参数"></a>使用 parse_args() 解析添加的参数</h3><p>一旦参数选项被指定，你就可以执行 <code>parse_args()</code>方法了。 它会处理 <code>sys.argv</code> 的值并返回一个结果实例。 每个参数值会被设置成该实例中<code>add_argument()</code> 方法的<code>dest</code> 参数指定的属性值。</p>
<h2 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">person</span><span class="params">()</span>:</span></span><br><span class="line">    args = argparse.ArgumentParser(description=<span class="string">'Personal Information '</span>, epilog=<span class="string">'Information end '</span>)</span><br><span class="line">    <span class="comment"># 必写属性,第一位</span></span><br><span class="line">    args.add_argument(<span class="string">"name"</span>, type=str, help=<span class="string">"Your name"</span>)</span><br><span class="line">    <span class="comment"># 必写属性,第二位</span></span><br><span class="line">    args.add_argument(<span class="string">"birth"</span>, type=str, help=<span class="string">"birthday"</span>)</span><br><span class="line">    <span class="comment"># 可选属性,默认为None</span></span><br><span class="line">    args.add_argument(<span class="string">"-r"</span>, <span class="string">'--race'</span>, type=str, dest=<span class="string">"race"</span>, help=<span class="string">u"民族"</span>)</span><br><span class="line">    <span class="comment"># 可选属性,默认为0,范围必须在0~150</span></span><br><span class="line">    args.add_argument(<span class="string">"-a"</span>, <span class="string">"--age"</span>, type=int, dest=<span class="string">"age"</span>, help=<span class="string">"Your age"</span>, default=<span class="number">0</span>, choices=range(<span class="number">150</span>))</span><br><span class="line">    <span class="comment"># 可选属性,默认为male</span></span><br><span class="line">    args.add_argument(<span class="string">'-s'</span>, <span class="string">"--sex"</span>, type=str, dest=<span class="string">"sex"</span>, help=<span class="string">'Your sex'</span>,  default=<span class="string">'male'</span>, choices=[<span class="string">'male'</span>, <span class="string">'female'</span>])</span><br><span class="line">    <span class="comment"># 可选属性,默认为None,-p后可接多个参数</span></span><br><span class="line">    args.add_argument(<span class="string">"-p"</span>, <span class="string">"--parent"</span>, type=str, dest=<span class="string">'parent'</span>, help=<span class="string">"Your parent"</span>, default=<span class="string">"None"</span>, nargs=<span class="string">'*'</span>)</span><br><span class="line">    <span class="comment"># 可选属性,默认为None,-o后可接多个参数</span></span><br><span class="line">    args.add_argument(<span class="string">"-o"</span>, <span class="string">"--other"</span>, type=str, dest=<span class="string">'other'</span>, help=<span class="string">"other Information"</span>, required=<span class="keyword">False</span>, nargs=<span class="string">'*'</span>)</span><br><span class="line"></span><br><span class="line">    args = args.parse_args()  <span class="comment"># 返回一个命名空间,如果想要使用变量,可用args.attr</span></span><br><span class="line">    print(<span class="string">"argparse.args="</span>, args, type(args))</span><br><span class="line">    print(<span class="string">'name = '</span>, args.name)</span><br><span class="line">    d = args.__dict__</span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> d.items():</span><br><span class="line">        print(<span class="string">'&#123;&#125; = &#123;&#125;'</span>.format(key, value))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    person()</span><br></pre></td></tr></table></figure>
<p>使用如下参数运行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python argv_argparse.py Jame <span class="number">1991.11</span><span class="number">.11</span> -p Harden John -a <span class="number">25</span> -r han -s male -o <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<blockquote>
<p>argparse.args= Namespace(age=25, birth=’1991.11.11’, name=’Jame’, other=[‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’], parent=[‘Harden’, ‘John’], race=’han’, sex=’male’) <class 'argparse.namespace'=""><br>name =  Jame<br>name = Jame<br>birth = 1991.11.11<br>race = han<br>age = 25<br>sex = male<br>parent = [‘Harden’, ‘John’]<br>other = [‘1’, ‘2’, ‘3’, ‘4’, ‘5’, ‘6’]</class></p>
</blockquote>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://wiki.jikexueyuan.com/project/explore-python/Standard-Modules/argparse.html" target="_blank" rel="noopener">极客学院 argparse</a></p>
<p><a href="http://blog.xiayf.cn/2013/03/30/argparse/" target="_blank" rel="noopener">argparse - 命令行选项与参数解析</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/34395749" target="_blank" rel="noopener">Python-argparse-命令行与参数解析</a></p>
<p><a href="https://medium.com/@dboyliao/python-%E8%B6%85%E5%A5%BD%E7%94%A8%E6%A8%99%E6%BA%96%E5%87%BD%E5%BC%8F%E5%BA%AB-argparse-4eab2e9dcc69" target="_blank" rel="noopener">Python 超好用標準函式庫 argparse</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/18/opencv/build_opencv_simple_lib/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/18/opencv/build_opencv_simple_lib/" class="post-title-link" itemprop="url">编译opencv精简静态库</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-18 13:48:11 / Modificado por: 18:37:02" itemprop="dateCreated datePublished" datetime="2018-04-18T13:48:11+08:00">2018-04-18</time>
            

            
              

              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/OpenCV/" itemprop="url" rel="index"><span itemprop="name">OpenCV</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="编译opencv精简静态库"><a href="#编译opencv精简静态库" class="headerlink" title="编译opencv精简静态库"></a>编译opencv精简静态库</h1><p>本示例在centos6.5上编译opencv2.4.9</p>
<h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install cmake gcc gcc-c++ make</span><br></pre></td></tr></table></figure>
<h2 id="cmake命令直接编译"><a href="#cmake命令直接编译" class="headerlink" title="cmake命令直接编译"></a>cmake命令直接编译</h2><p>opencv_highgui库在读写jpeg,png,tiff,jpeg2000图像格式时用到了第三方编解码库，可以根据图像的格式，精简选择需要开启的编译选项</p>
<p>在opencv根目录下创建release文件夹，打开release文件夹，之后编译产生的中文文件和最后编译结果都将存放在该目录下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">cmake -DBUILD_DOCS=off \</span><br><span class="line">	-DBUILD_SHARED_LIBS=off \</span><br><span class="line">    -DBUILD_FAT_JAVA_LIB=off \</span><br><span class="line">    -DBUILD_TESTS=off \</span><br><span class="line">    -DBUILD_TIFF=on \         </span><br><span class="line">    -DBUILD_JASPER=on \        </span><br><span class="line">    -DBUILD_JPEG=on \      </span><br><span class="line">    -DBUILD_PNG=on \          </span><br><span class="line">    -DBUILD_ZLIB=on \</span><br><span class="line">    -DBUILD_OPENEXR=off \</span><br><span class="line">    -DBUILD_opencv_apps=off \</span><br><span class="line">    -DBUILD_opencv_calib3d=off \</span><br><span class="line">    -DBUILD_opencv_contrib=off \</span><br><span class="line">    -DBUILD_opencv_features2d=off \</span><br><span class="line">    -DBUILD_opencv_flann=off \</span><br><span class="line">    -DBUILD_opencv_gpu=off \</span><br><span class="line">    -DBUILD_opencv_java=off \</span><br><span class="line">    -DBUILD_opencv_legacy=off \</span><br><span class="line">    -DBUILD_opencv_ml=off \</span><br><span class="line">    -DBUILD_opencv_nonfree=off \</span><br><span class="line">    -DBUILD_opencv_objdetect=off \</span><br><span class="line">    -DBUILD_opencv_ocl=off \</span><br><span class="line">    -DBUILD_opencv_photo=off \</span><br><span class="line">    -DBUILD_opencv_python=off \</span><br><span class="line">    -DBUILD_opencv_stitching=off \</span><br><span class="line">    -DBUILD_opencv_superres=off \</span><br><span class="line">    -DBUILD_opencv_ts=off \</span><br><span class="line">    -DBUILD_opencv_video=off \</span><br><span class="line">    -DBUILD_opencv_videostab=off \</span><br><span class="line">    -DBUILD_opencv_world=off \</span><br><span class="line">    -DBUILD_opencv_lengcy=off \</span><br><span class="line">    -DBUILD_opencv_lengcy=off \</span><br><span class="line">    -DWITH_1394=off \</span><br><span class="line">    -DWITH_EIGEN=off \</span><br><span class="line">    -DWITH_FFMPEG=off \</span><br><span class="line">    -DWITH_GIGEAPI=off \</span><br><span class="line">    -DWITH_GSTREAMER=off \</span><br><span class="line">    -DWITH_GTK=off \</span><br><span class="line">    -DWITH_PVAPI=off \</span><br><span class="line">    -DWITH_V4L=off \</span><br><span class="line">    -DWITH_LIBV4L=off \</span><br><span class="line">    -DWITH_CUDA=off \</span><br><span class="line">    -DWITH_CUFFT=off \</span><br><span class="line">    -DWITH_OPENCL=off \</span><br><span class="line">    -DWITH_OPENCLAMDBLAS=off \</span><br><span class="line">    -DWITH_OPENCLAMDFFT=off ..</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>-DBUILD_SHARED_LIBS=off \    # 指定编译静态库，默认编译动态库(.so,.dll)</li>
<li>-DBUILD_JASPER=on \          # 编译3rdparty/libjasper项目用于jpeg2000图像编解码</li>
<li>-DBUILD_JPEG=on \            # 编译3rdparty/libjpeg项目用于jpeg图像编解码</li>
<li>-DBUILD_PNG=on \             # 编译3rdparty/libpng项目用于png图像编解码</li>
<li>-DBUILD_TIFF=on \            # 编译3rdparty/libtiff项目用于tiff图像编解码</li>
<li>-DBUILD_ZLIB=on \            # 编译3rdparty/zlib项目</li>
</ul>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<p>这样编译出来的opencv只含有opencv_core,opencv_imgproc,opencv_highgui</p>
<blockquote>
<p>OPENMP支持需要gcc版本大于4.6以上，否则需要将WITH_OPENMP选项关闭</p>
</blockquote>
<h2 id="使用cmake-gui进行编译"><a href="#使用cmake-gui进行编译" class="headerlink" title="使用cmake-gui进行编译"></a>使用cmake-gui进行编译</h2><p>设置源代码路径和生成文件存放文件夹路径，按Configure</p>
<center><img src="./pic/cmake_1.jpg" width="400"></center>

<p>勾选对应的选项，多余的关闭即可</p>
<p>设置好后Configure ,Generate</p>
<p>然后到生成文件存放文件夹下，make，make install即可</p>
<h2 id="提取生成的静态库和头文件"><a href="#提取生成的静态库和头文件" class="headerlink" title="提取生成的静态库和头文件"></a>提取生成的静态库和头文件</h2><ul>
<li><p>静态库路径</p>
<p>生成的静态库可以在/usr/local/lib和/usr/local/share/OpenCV/3rdparty/lib下找到(release文件夹下的lib以及3rdparty/lib中存在对应得库文件)</p>
<p>头文件可以在/usr/local/include下找到（opencv根目录的include和modules下也有对应的头文件）</p>
</li>
<li><p>头文件修改</p>
<p>修改<code>opencv2/opencv.hpp</code>, opencv.hpp中仍包含其他模块的头文件，将多余的头文件代码删除</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/core/core_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/core/core.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/flann/miniflann.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/imgproc/imgproc_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/imgproc/imgproc.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/photo/photo.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/video/video.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/features2d/features2d.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/objdetect/objdetect.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/calib3d/calib3d.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/ml/ml.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/contrib/contrib.hpp"</span></span></span><br></pre></td></tr></table></figure>
<p>改为</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/core/core_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/core/core.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/imgproc/imgproc_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/imgproc/imgproc.hpp"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui_c.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"opencv2/highgui/highgui.hpp"</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>移动到自定义文件下</p>
<p>新建了一个3rdparty文件夹存放自定义编译的一些库文件</p>
<ul>
<li>将/usr/local/lib和/usr/local/share/OpenCV/3rdparty/lib下的 *.a 静态库放到\<path-to-3rdparty>/3rdparty/opencv/lib下</path-to-3rdparty></li>
<li>将/usr/local/include下的 opencv和opencv2文件夹放到\<path-to-3rdparty>/3rdparty/opencv/include下</path-to-3rdparty></li>
</ul>
</li>
</ul>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>本测试是在centos6.5上进行的，图像读取只对jpeg和png进行了编译，centos6.5的默认gcc版本为4.4.7，所以取消了对OPENMP的编译</p>
<ul>
<li><p>DisplayImage.cpp</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;opencv2/opencv.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> ( argc != <span class="number">2</span> )&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"usage: DisplayImage.out &lt;Image_Path&gt;\n"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Mat image;</span><br><span class="line">    image = imread( argv[<span class="number">1</span>], <span class="number">1</span> );</span><br><span class="line">    <span class="keyword">if</span> ( !image.data )&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"No image data \n"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Load image successful!\n"</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"image size is: &lt; %d x %d&gt;\n"</span>,image.cols,image.rows);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> row = <span class="number">0</span>; row &lt; <span class="number">1</span>; row++) &#123;</span><br><span class="line">         uchar* data = image.ptr&lt;uchar&gt;(row);</span><br><span class="line">         <span class="keyword">for</span> (<span class="keyword">int</span> col = <span class="number">0</span>; col &lt; <span class="number">5</span>; col++) &#123;</span><br><span class="line">              <span class="built_in">printf</span>(<span class="string">"%d \t"</span>, data[col]);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>CMakeLists.txt</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">2.8</span>)</span><br><span class="line"><span class="keyword">project</span>( DisplayImage )</span><br><span class="line"><span class="keyword">set</span>(OPENCV_PATH /home/heroin/<span class="number">3</span>rdparty/opencv)</span><br><span class="line"><span class="keyword">add_executable</span>( DisplayImage DisplayImage.cpp )</span><br><span class="line"><span class="keyword">include_directories</span>(<span class="variable">$&#123;OPENCV_PATH&#125;</span>/<span class="keyword">include</span>)</span><br><span class="line"><span class="comment"># set(OPENCV_LIBS $&#123;OPENCV_PATH&#125;/lib/libopencv_imgproc.a $&#123;OPENCV_PATH&#125;/lib/libopencv_highgui.a $&#123;OPENCV_PATH&#125;/lib/libopencv_core.a $&#123;OPENCV_PATH&#125;/lib/liblibjpeg.a  $&#123;OPENCV_PATH&#125;/lib/liblibpng.a $&#123;OPENCV_PATH&#125;/lib/libzlib.a)</span></span><br><span class="line"><span class="comment">#target_link_libraries( DisplayImage $&#123;OPENCV_LIBS&#125; dl m pthread rt)</span></span><br><span class="line"><span class="keyword">target_link_libraries</span>( DisplayImage <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/libopencv_imgproc.a  <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/libopencv_highgui.a <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/libopencv_core.a  <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/liblibjpeg.a  <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/liblibpng.a <span class="variable">$&#123;OPENCV_PATH&#125;</span>/lib/libzlib.a dl m pthread rt)</span><br></pre></td></tr></table></figure>
<p>cmake ,make即可</p>
</li>
</ul>
<p>###cmake注意事项</p>
<ul>
<li><p>链接库顺序</p>
<p>​    cmake中要注意链接的顺序，libopencv_imgproc.a，libopencv_core.a对libzlib.a存在依赖，应该把libzlib.a放在后面，libopencv_highgui.a读写图片还需要liblibjpeg.a等图像解码库的支持，liblibjpeg.a也要放在后面。</p>
<blockquote>
<p>在项目开发过层中尽量让lib是垂直关系，避免循环依赖；越是底层的库，越是往后面写！例如:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; g++ ...  obj($?) -l(上层逻辑lib) -l(中间封装lib) -l(基础lib) -l(系统lib)  -o $@</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
<li><p>源文件和链接库顺序</p>
<p>*.cpp文件应该放在链接库前面</p>
<p> 所以 以下方式是编译不通过的</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">link_libraries</span>(<span class="variable">$&#123;OPENCV_LIBS&#125;</span> dl m pthread rt)</span><br><span class="line"><span class="keyword">target_link_libraries</span>( DisplayImage)</span><br></pre></td></tr></table></figure>
<p>应该改为如下方式</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">target_link_libraries</span>( DisplayImage <span class="variable">$&#123;OPENCV_LIBS&#125;</span> dl m pthread rt)</span><br></pre></td></tr></table></figure>
<p>或者直接不设OPENCV_LIBS变量，直接将链接写在后方</p>
</li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/13/caffe/windows10_caffe_install/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/13/caffe/windows10_caffe_install/" class="post-title-link" itemprop="url">windows10编译caffe的python接口</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-13 15:11:11" itemprop="dateCreated datePublished" datetime="2018-04-13T15:11:11+08:00">2018-04-13</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-08-06 09:20:04" itemprop="dateModified" datetime="2018-08-06T09:20:04+08:00">2018-08-06</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/caffe/" itemprop="url" rel="index"><span itemprop="name">caffe</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="windows10编译caffe的python接口"><a href="#windows10编译caffe的python接口" class="headerlink" title="windows10编译caffe的python接口"></a>windows10编译caffe的python接口</h1><h2 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h2><ul>
<li><p>Visual Studio 2013 或 Visual Studio 2015</p>
<p> 选择Visual Studio 2015，caffe的windows安装只支持VS2013和VS2015</p>
</li>
<li><p>Anaconda3</p>
<p>选择Anaconda3.4.2版本，python版本为3.5。caffe的windows安装只支持python2.7和python3.5，不支持3.6版本(VS2013只支持python2.7的, VS2015支持python2.7 和 3.5)</p>
</li>
</ul>
<blockquote>
<p>详情见”\<caffe-root>\cmake\WindowsDownloadPrebuiltDependencies.cmake”中</caffe-root></p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="keyword">set</span>(DEPENDENCIES_NAME_1800_27 libraries_v120_x64_py27_<span class="variable">$&#123;DEPENDENCIES_VERSION&#125;</span>)</span><br><span class="line">&gt; <span class="keyword">set</span>(DEPENDENCIES_NAME_1900_27 libraries_v140_x64_py27_<span class="variable">$&#123;DEPENDENCIES_VERSION&#125;</span>)</span><br><span class="line">&gt; <span class="keyword">set</span>(DEPENDENCIES_NAME_1900_35 libraries_v140_x64_py35_<span class="variable">$&#123;DEPENDENCIES_VERSION&#125;</span>)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<ul>
<li><p>CMake</p>
<p>选择CMake 3.11.3</p>
</li>
</ul>
<ul>
<li><p>安装cuda并添加环境变量</p>
</li>
<li><p>安装cudnn</p>
<p>解压cudnn-8.0-windows10-x64-v7.zip，将cuda下面的bin、include与lib三文件夹复制到CUDA对应的文件夹下：C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0。</p>
</li>
<li><p>安装protobuf</p>
<p>protobuf源代码（各种语言实现）<br><a href="https://github.com/google/protobuf" target="_blank" rel="noopener">https://github.com/google/protobuf</a> </p>
<p>只需要python版和protoc（放到src文件夹下）</p>
<p>到Python目录，编译 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure>
<p>将生成的google文件夹拷贝到anaconda安装路径的<code>.\lib\site-package</code>文件夹中</p>
</li>
</ul>
<h2 id="编译安装caffe"><a href="#编译安装caffe" class="headerlink" title="编译安装caffe"></a>编译安装caffe</h2><p>使用CMake-gui，设置source code路径为caffe的根目录，在caffe根目录下新建build文件夹为build路径</p>
<center><img src="./pictures/cmake_configure_1.jpg" width="400"></center>

<ul>
<li><p>修改python版本</p>
<p>打开CMakeLists.txt，修改python_version为3(第50行)</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span>(python_version <span class="string">"3"</span> CACHE <span class="keyword">STRING</span> <span class="string">"Specify which Python version to use"</span>)</span><br></pre></td></tr></table></figure>
<p>在CMake-gui中选择PYTHON_EXECUTABLE为Anaconda3下的python (3.5版本）</p>
</li>
<li><p>设置BLAS选项为Open</p>
<p>在CMake-gui中选择BLAS为Open，原始为Atlas，Configure时会报如下错误</p>
<blockquote>
<p>Could NOT find Atlas (missing: Atlas_CLAPACK_INCLUDE_DIR   Atlas_CBLAS_LIBRARY Atlas_BLAS_LIBRARY Atlas_LAPACK_LIBRARY)</p>
</blockquote>
</li>
</ul>
<p>点击Configure，Generate</p>
<p>完成后在build目录下用VS2015打开Caffe.sln，Build  pycaffe项目即可</p>
<h2 id="测试python接口"><a href="#测试python接口" class="headerlink" title="测试python接口"></a>测试python接口</h2><p>python接口有两种使用方式，一种是将caffe根目录下的python中的caffe文件夹拷贝到anaconda安装路径的<code>.\lib\site-package</code>文件夹中，可以在python源文件中直接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> caffe</span><br></pre></td></tr></table></figure>
<p>另一种方式，在代码中添加caffe的路径到系统路径，这样可以允许使用更多版本的caffe而不至于混乱</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加所要使用的caffe的路径到系统路径</span></span><br><span class="line">caffe_root = <span class="string">'F:\caffe-windows\python'</span> </span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root)</span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">import</span> caffe</span><br></pre></td></tr></table></figure>
<p>没有报错则完成编译</p>
<blockquote>
<p>报错情况: </p>
<p>dll缺失： 注意切换Anaconda的版本，确认为python3.5</p>
<p>No module named google ： 没有安装protobuf</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/SSD/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/12/deep_learning/object_detection/SSD/" class="post-title-link" itemprop="url">目标检测网络之 SSD</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-11 10:42:26" itemprop="dateModified" datetime="2018-10-11T10:42:26+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Single-Shot-MultiBox-Detector"><a href="#Single-Shot-MultiBox-Detector" class="headerlink" title="Single Shot MultiBox Detector"></a>Single Shot MultiBox Detector</h1><p>论文地址: <a href="https://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.02325.pdf</a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目标检测近年来已经取得了很重要的进展，主流的算法主要分为两个类型（参考<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1711.06897.pdf" target="_blank" rel="noopener">RefineDet</a>）:</p>
<ul>
<li><p><strong>Two stages</strong></p>
<p>以Faster RCNN为代表，即RPN网络先生成proposals目标定位，再对proposals进行classification+bounding box regression完成目标分类, two-stage方法的优势是准确度高</p>
</li>
<li><p><strong>Single shot</strong></p>
<p>以YOLO/SSD为代表，均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同尺度和长宽比，然后利用CNN提取特征后直接进行分类与回归, 一次性完成classification+bounding box regression, 所以其优势是速度快，但是均匀的密集采样的一个重要缺点是训练比较困难，这主要是因为正样本与负样本（背景）极其不均衡（参见<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1708.02002" target="_blank" rel="noopener">Focal Loss</a>），导致模型准确度稍低。</p>
</li>
</ul>
<h2 id="1-SSD300网络结构"><a href="#1-SSD300网络结构" class="headerlink" title="1 SSD300网络结构"></a>1 SSD300网络结构</h2><center><img src="./images/ssd_yolo_对比.jpg"></center>

<center><em>图 2 SSD300/YOLO网络结构对比</em> </center>

<p>同为Single shot方式的SSD/YOLO区别：</p>
<ul>
<li>YOLO在卷积层后接全连接层，即检测时只利用了最高层Feature maps（包括Faster RCNN也是如此）</li>
<li>SSD采用金字塔结构，即利用了conv4-3/conv-7/conv6-2/conv7-2/conv8_2/conv9_2这些大小不同的feature maps，在多个feature maps上同时进行softmax分类和位置回归</li>
<li>SSD还加入了Prior box</li>
</ul>
<center><img src="./images/single_feature_map_and_pyramidal_feature_hierarchy.jpg"></center>

<center> <em>图 3 单层 feature map预测和特征金字塔预测对比</em> </center>

<h2 id="2-Prior-Box"><a href="#2-Prior-Box" class="headerlink" title="2 Prior Box"></a>2 Prior Box</h2><p>在SSD300中引入了Prior Box，实际上与Faster RCNN Anchor非常类似，就是一些目标的预选框，后续通过classification+bounding box regression获得真实目标的位置。</p>
<p>SSD按照如下规则生成prior box：</p>
<ul>
<li>以feature map上每个点的中点为中心，生成一些列同心的prior box</li>
<li>正方形prior box最小边长为和最大边长为：</li>
</ul>
<p>$$<br>\color {MidnightBlue}\mathit {\text{min_size}}<br>$$</p>
<p>$$<br>\color {MidnightBlue}\mathit {\sqrt{\text{min_size}*\text{max_size}}}<br>$$</p>
<ul>
<li>每在prototxt设置一个aspect ratio，会生成2个长方形，长宽为：</li>
</ul>
<p>$$<br>\color {MidnightBlue}\mathit {\sqrt{\text{aspect_ratio}}*\text{min_size}}<br>$$</p>
<p>$$<br>\color {MidnightBlue}\mathit {1/{\sqrt{\text{aspect_ratio}}*\text{min_size}}}<br>$$</p>
<center><img src="./images/prior box.jpg"></center>

<p>图4 prior box</p>
<ul>
<li>而每个feature map对应prior box的min_size和max_size由以下公式决定：</li>
</ul>
<center>$$s_k = s_{min} + \frac{s_{max}-s_{min}}{m-1}(k-1), \ \ k\in[1, m]$$ </center>

<p>公式中的 $m$是指进行预测时使用feature map的数量，如SSD300使用conv4-3等6个feature maps进行预测，所以 $m=6$。同时原文设定$s_{min}=0.2$ ，$s_{max}=0.9$</p>
<p>那么：</p>
<ul>
<li>对于conv4-3： $k=1$ , $min_size=s_1 <em>300$, $max_size=s_2</em>300$</li>
<li>对于conv-7：$k=2$, $min_size=s_2 <em>300$, $max_size=s_3</em>300$</li>
<li>….</li>
</ul>
<p>显然可以用上述公式推导出每个feature maps使用的Prior Box size。但是在SSD300中prior box设置并不能完全和上述公式对应：</p>
<center><table> <tr> <th width="10%,bgcolor=#eeeeee"></th> <th width="10%,bgcolor=#eeeeee">min_size</th> &lt;th width=10%,bgcolor=#eeeeee”&gt;max_size </tr> <tr> <td bgcolor="#eeeeee"> conv4_3</td> <td> 30  </td> <td> 60</td> </tr>  <tr> <td bgcolor="#eeeeee"> fc7</td> <td> 60  </td> <td> 111</td> </tr><tr> <td bgcolor="#eeeeee"> conv6_2</td> <td> 111</td> <td> 162</td> </tr><tr> <td bgcolor="#eeeeee"> conv7_2</td> <td> 162</td> <td> 213</td> </tr><tr> <td bgcolor="#eeeeee"> conv8_2</td> <td> 213</td> <td> 264</td> </tr><tr> <td bgcolor="#eeeeee"> conv9_2</td> <td> 264  </td> <td> 315</td> </tr></table> </center>

<p>不过依然可以看出：<strong>SSD使用感受野小的feature map检测小目标，使用感受野大的feature map检测更大目标</strong>。</p>
<p>更具体一点，来看SSD300在conv4_3层的Prior Box设置conv4_3生成prior box的conv4_3_norm_priorbox层prototxt定义如下，可以清晰的看到 $min_size$ 和 $max_size$以及 $aspect_ratio$等值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv4_3_norm_mbox_priorbox&quot;</span><br><span class="line">  type: &quot;PriorBox&quot;</span><br><span class="line">  bottom: &quot;conv4_3_norm&quot;</span><br><span class="line">  bottom: &quot;data&quot;</span><br><span class="line">  top: &quot;conv4_3_norm_mbox_priorbox&quot;</span><br><span class="line">  prior_box_param &#123;</span><br><span class="line">    min_size: 30.0</span><br><span class="line">    max_size: 60.0</span><br><span class="line">    aspect_ratio: 2</span><br><span class="line">    flip: true</span><br><span class="line">    clip: false</span><br><span class="line">    variance: 0.1</span><br><span class="line">    variance: 0.1</span><br><span class="line">    variance: 0.2</span><br><span class="line">    variance: 0.2</span><br><span class="line">    step: 8</span><br><span class="line">    offset: 0.5</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>知道了priorbox如何产生，接下来分析prior box如何使用。这里还是以conv4_3分析。</p>
<center><img src="/images/图5.jpg"></center>

<p>图5</p>
<p>从图5可以看到，在conv4_3网络分为了3条线路：</p>
<ol>
<li>经过一次batch norm+一次卷积后，生成了<strong>[1, num_class*num_priorbox, layer_height, layer_width]</strong>大小的feature用于softmax分类目标和非目标（其中num_class是目标类别，SSD300中num_class = 21，即20个类别+1个背景)</li>
<li>经过一次batch norm+一次卷积后，生成了<strong>[1, 4*num_priorbox, layer_height, layer_width]</strong>大小的feature用于bounding box regression（即每个点一组[dxmin，dymin，dxmax，dymax]，参考<a href="https://zhuanlan.zhihu.com/p/31426458" target="_blank" rel="noopener">Faster R-CNN</a> 2.5节）</li>
<li>生成了<strong>[1, 2, 4*num_priorbox<em>layer_height</em>layer_width]</strong>大小的prior box blob，其中2个channel分别存储prior box的4个点坐标(x1, y1, x2, y2)和对应的4个参数variance</li>
</ol>
<p>后续通过softmax分类判定Prior box是否包含目标，然后再通过bounding box regression即可可获取目标的精确位置，熟悉Faster RCNN的读者应该对上述过程应该并不陌生。其实pribox box的与Faster RCNN中的anchor非常类似，都是目标的预设框，没有本质的差异。区别是每个位置的prior box一般是4~6个，少于Faster RCNN默认的9个anchor；同时prior box是设置在不同尺度的feature maps上的，而且大小不同。</p>
<p>还有一个细节就是上面prototxt中的4个variance，这实际上是一种bounding regression中的权重。在图4线路(2)中，网络输出[dxmin，dymin，dxmax，dymax]，即对应下面代码中bbox；然后利用如下方法进行针对prior box的位置回归：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">decode_bbox-&gt;set_xmin(</span><br><span class="line">     prior_bbox.xmin() + prior_variance[<span class="number">0</span>] * bbox.xmin() * prior_width);</span><br><span class="line"> decode_bbox-&gt;set_ymin(</span><br><span class="line">     prior_bbox.ymin() + prior_variance[<span class="number">1</span>] * bbox.ymin() * prior_height);</span><br><span class="line"> decode_bbox-&gt;set_xmax(</span><br><span class="line">     prior_bbox.xmax() + prior_variance[<span class="number">2</span>] * bbox.xmax() * prior_width);</span><br><span class="line"> decode_bbox-&gt;set_ymax(</span><br><span class="line">     prior_bbox.ymax() + prior_variance[<span class="number">3</span>] * bbox.ymax() * prior_height);</span><br></pre></td></tr></table></figure>
<p>上述代码可以在SSD box_utils.cpp的void DecodeBBox()函数见到。</p>
<h2 id="3-SSD的数据流"><a href="#3-SSD的数据流" class="headerlink" title="3 SSD的数据流"></a>3 SSD的数据流</h2><p>对于新学习SSD的人，肯定有一个很大的困惑，就是这么多feature maps和Prior Box，如何组合在一起进行forwards/backwards。本节专门介绍SSD的数据流动方式，也许有点难。但是只有了解SSD的数据流动方式才能真的理解。</p>
<center><img src="/images/原理图.jpg"></center>

<center><em>图6</em></center>

<p>上一节以conv4_3 feature map分析了如何检测到目标的真实位置，但是SSD 300是使用包括conv4_3在内的共计6个feature maps一同检测出最终目标的。在网络运行的时候显然不能像图6一样：一个feature map单独计算一次multiclass softmax socre+box regression（虽然原理如此，但是不能如此实现）。</p>
<p>那么多个feature maps如何协同工作？这时候就要用到Permute，Flatten和Concat这3种层了。其中conv4_3_norm_conf_perm的prototxt定义如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">layer &#123;</span><br><span class="line">  name: &quot;conv4_3_norm_mbox_conf_perm&quot;</span><br><span class="line">  type: &quot;Permute&quot;</span><br><span class="line">  bottom: &quot;conv4_3_norm_mbox_conf&quot;</span><br><span class="line">  top: &quot;conv4_3_norm_mbox_conf_perm&quot;</span><br><span class="line">  permute_param &#123;</span><br><span class="line">    order: 0</span><br><span class="line">    order: 2</span><br><span class="line">    order: 3</span><br><span class="line">    order: 1</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Permute是SSD中自带的层，上面conv4_3_norm_mbox_conf_perm的的定义。Permute相当于交换caffe blob中的数据维度。在正常情况下caffe blob的顺序为：</p>
<p><strong>bottom blob = [batch_num, channel, height, width]</strong></p>
<p>经过conv4_3_norm_mbox_conf_perm后的caffe blob为：</p>
<p><strong>top blob = [batch_num, height, width, channel]</strong></p>
<p>而Flattlen和Concat层都是caffe自带层，请参照<a href="https://link.zhihu.com/?target=http%3A//caffe.berkeleyvision.org/tutorial/layers.html" target="_blank" rel="noopener">caffe official documentation</a>理解。</p>
<center><img src="/images/caffe blob shape变化.jpg "></center>

<center><em>图7 SSD中部分层caffe blob shape变化</em></center>

<p>那么接下来以conv4_3和fc7为例分析SSD是如何将不同size的feature map组合在一起进行prediction。图7展示了conv4_3和fc7合并在一起的过程中caffe blob shape变化（其他层类似，考虑到图片大小没有画出来，请脑补）。</p>
<ul>
<li>对于conv4_3 feature map，conv4_3_norm_priorbox（priorbox层）设置了每个点共有4个prior box。由于SSD 300共有21个分类，所以conv4_3_norm_mbox_conf的channel值为num_priorbox <em> num_class = 4 </em> 21 = 84；而每个prior box都要回归出4个位置变换量，所以conv4_3_norm_mbox_loc的caffe blob channel值为4 * 4 = 16。</li>
<li>fc7每个点有6个prior box，其他feature map同理。</li>
<li>经过一系列图7展示的caffe blob shape变化后，最后拼接成mbox_conf和mbox_loc。而mbox_conf后接reshape，再进行softmax（为何在softmax前进行reshape，Faster RCNN有提及）。</li>
<li>最后这些值输出detection_out_layer，获得检测结果</li>
</ul>
<p>可以看到，SSD一次判断priorbox到底是背景 or 是20种目标类别之一，相当于将Faster R-CNN的RPN与后续proposal再分类进行了整合。</p>
<center><img src="/images/SSD300.jpg"></center>

<center><em>图8 SSD300</em></center>

<h2 id="4-SSD网络结构优劣分析"><a href="#4-SSD网络结构优劣分析" class="headerlink" title="4 SSD网络结构优劣分析"></a>4 SSD网络结构优劣分析</h2><p>SSD算法的优点应该很明显：运行速度可以和YOLO媲美，检测精度可以和Faster RCNN媲美。除此之外，还有一些鸡毛蒜皮的优点，不解释了。这里谈谈缺点：</p>
<ol>
<li>需要人工设置prior box的min_size，max_size和aspect_ratio值。网络中prior box的基础大小和形状不能直接通过学习获得，而是需要手工设置。而网络中每一层feature使用的prior box大小和形状恰好都不一样，导致调试过程非常依赖经验。</li>
<li>虽然采用了pyramdial feature hierarchy的思路，但是对小目标的recall依然一般，并没有达到碾压Faster RCNN的级别。作者认为，这是由于SSD使用conv4_3低级feature去检测小目标，而低级特征卷积层数少，存在特征提取不充分的问题。</li>
</ol>
<h2 id="5-SSD训练过程"><a href="#5-SSD训练过程" class="headerlink" title="5 SSD训练过程"></a>5 SSD训练过程</h2><p><img src="https://pic2.zhimg.com/v2-79dccc5fbc3d31a24e4d0e42511cb653_b.jpg" alt="img"></p>
<p>对于SSD，虽然paper中指出采用了所谓的“multibox loss”，但是依然可以清晰看到SSD loss分为了confidence loss和location loss(bouding box regression loss)两部分，其中N是match到GT（Ground Truth）的prior box数量；而α参数用于调整confidence loss和location loss之间的比例，默认α=1。SSD中的confidence loss是典型的softmax loss：</p>
<p><img src="https://pic1.zhimg.com/v2-42c6a269bbfbae035b0f74c0602b14ba_b.jpg" alt="img"></p>
<p>其中</p>
<p><img src="https://pic2.zhimg.com/v2-46a8eb39bab8396443cc3a8bcedd777d_b.jpg" alt="img"></p>
<p>代表第i个prior box匹配到了第j个class为p类别的GT box；而location loss是典型的smooth L1 loss：</p>
<p><img src="https://pic1.zhimg.com/v2-e7b5c31560d34fdd309b05c1e23a9dab_b.jpg" alt="img"></p>
<p><strong>Matching strategy：</strong></p>
<p>在训练时，groundtruth boxes 与 default boxes（就是prior boxes） 按照如下方式进行配对：</p>
<ul>
<li>首先，寻找与每一个ground truth box有最大的jaccard overlap的default box，这样就能保证每一个groundtruth box与唯一的一个default box对应起来（所谓的jaccard overlap就是IoU，如图9）。</li>
<li>SSD之后又将剩余还没有配对的default box与任意一个groundtruth box尝试配对，只要两者之间的jaccard overlap大于阈值，就认为match（SSD 300 阈值为0.5）。</li>
<li>显然配对到GT的default box就是positive，没有配对到GT的default box就是negative。</li>
</ul>
<center><img src="/images/A交B.jpg"></center>

<center><img src="/images/A并B.jpg"></center>

<p><img src="https://pic4.zhimg.com/v2-8f2601b4c788246bd6138cf99c15f1bf_b.jpg" alt="img"></p>
<center><em>图9 jaccard overlap</em></center>

<p><strong>Hard negative mining：</strong></p>
<p>值得注意的是，一般情况下negative default boxes数量&gt;&gt;positive default boxes数量，直接训练会导致网络过于重视负样本，从而loss不稳定。所以需要采取：</p>
<ul>
<li>所以SSD在训练时会依据confidience score排序default box，挑选其中confidence高的box进行训练，控制 $positive:negative=1:3$</li>
</ul>
<p><strong>Data augmentation：</strong></p>
<p>数据增广。即对每一张image进行如下之一变换获取一个patch进行训练：</p>
<ul>
<li>直接使用原始的图像（即不进行变换）</li>
<li>采样一个patch，保证与GT之间最小的IoU为：0.1，0.3，0.5，0.7 或 0.9</li>
<li>完全随机的采样一个patch</li>
</ul>
<center><img src="/images/Random crop.jpg"></center>

<center><em>图10 Random crop</em></center>

<p>同时在原文中还提到：</p>
<ul>
<li>采样的patch占原始图像大小比例在 $[0.1,1]$ 之间</li>
<li>采样的patch的长宽比在 $[0.5,2]$之间</li>
<li>当 Ground truth box中心恰好在采样的patch中时，保留整个GT box</li>
<li>最后每个patch被resize到固定大小，并且以0.5的概率随机的水平翻转</li>
</ul>
<p>最终以这些处理好的patches进行训练。</p>
<p>其实Matching strategy，Hard negative mining，Data augmentation，都是为了加快网络收敛而设计的。尤其是Data augmentation，翻来覆去的randomly crop，保证每一个prior box都获得充分训练而已。后续有Focal loss解决这个问题。</p>
<p>SSD github : <a href="https://link.zhihu.com/?target=https%3A//github.com/weiliu89/caffe/tree/ssd" target="_blank" rel="noopener">https://github.com/weiliu89/caffe/tree/ssd</a></p>
<p>SSD paper : <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1512.02325" target="_blank" rel="noopener">https://arxiv.org/abs/1512.02325</a></p>
<p>SSD eccv2016 slide pdf : <a href="https://link.zhihu.com/?target=http%3A//www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf" target="_blank" rel="noopener">http://www.cs.unc.edu/~wliu/papers/ssd_eccv2016_slide.pdf</a></p>
<p>Focal Loss for Dense Object Detection ：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1708.02002" target="_blank" rel="noopener">https://arxiv.org/abs/1708.02002</a></p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/metric/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/12/deep_learning/object_detection/metric/" class="post-title-link" itemprop="url">目标检测网络之评价指标</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-11 10:43:24" itemprop="dateModified" datetime="2018-10-11T10:43:24+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="目标检测中的评价指标"><a href="#目标检测中的评价指标" class="headerlink" title="目标检测中的评价指标"></a>目标检测中的评价指标</h1><p>主要包括召回率( Recall )，精确率(Precision)，平均正确率(Average_precision(AP) )，交除并(Intersection-over-Union(IoU))</p>
<h2 id="大雁与飞机"><a href="#大雁与飞机" class="headerlink" title="大雁与飞机"></a><strong>大雁与飞机</strong></h2><p>假设现在有这样一个测试集，测试集中的图片只由大雁和飞机两种图片组成，如下图所示： </p>
 <center><img src="images/评价指标/1.png"></center>

<p>假设你的分类系统最终的目的是：能取出测试集中所有飞机的图片，而不是大雁的图片。</p>
<p>现在做如下的定义：<br> <strong>True positives :</strong>   飞机的图片被正确的识别成了飞机。<br> <strong>True negatives:</strong>  大雁的图片没有被识别出来，系统正确地认为它们是大雁。<br> <strong>False positives:</strong>  大雁的图片被错误地识别成了飞机。<br> <strong>False negatives:</strong> 飞机的图片没有被识别出来，系统错误地认为它们是大雁。</p>
<p>假设你的分类系统使用了上述假设识别出了四个结果，如下图所示： </p>
  <center><img src="images/评价指标/2.png"></center>

<p>那么在识别出的这四张照片中：<br> <strong>True positives :</strong> 有三个，画绿色框的飞机。<br> <strong>False positives:</strong>  有一个，画红色框的大雁。</p>
<p>没被识别出来的六张图片中：<br> <strong>True  negatives :</strong> 有四个，这四个大雁的图片，系统正确地没有把它们识别成飞机。<br> <strong>False negatives:</strong> 有两个，两个飞机没有被识别出来，系统错误地认为它们是大雁。</p>
<h2 id="Precision-与-Recall"><a href="#Precision-与-Recall" class="headerlink" title="Precision 与 Recall"></a><strong>Precision 与 Recall</strong></h2><p>Precision其实就是在识别出来的图片中，True positives所占的比率：<br>$$precision = \frac{tp}{tp+fp}=\frac{tp}{n}$$<br> 其中的n代表的是(True positives + False positives)，也就是系统一共识别出来多少照片 。<br> 在这一例子中，True positives为3，False positives为1，所以Precision值是 3/（3+1）=0.75。<br> 意味着在识别出的结果中，飞机的图片占75%。</p>
<p>Recall 是被正确识别出来的飞机个数与测试集中所有飞机的个数的比值：<br>$$recall= \frac{tp}{tp+fn}$$<br> Recall的分母是(True positives + False negatives)，这两个值的和，可以理解为一共有多少张飞机的照片。<br> 在这一例子中，True positives为3，False negatives为2，那么Recall值是 3/（3+2）=0.6。<br> 意味着在所有的飞机图片中，60%的飞机被正确的识别成飞机.。</p>
<h2 id="调整阈值"><a href="#调整阈值" class="headerlink" title="调整阈值"></a><strong>调整阈值</strong></h2><p>你也可以通过调整阈值，来选择让系统识别出多少图片，进而改变Precision 或 Recall 的值。<br> 在某种阈值的前提下（蓝色虚线），系统识别出了四张图片，如下图中所示： </p>
<center><img src="images/评价指标/3.png"></center>

<p> 分类系统认为大于阈值（蓝色虚线之上）的四个图片更像飞机。</p>
<p>我们可以通过改变阈值（也可以看作上下移动蓝色的虚线），来选择让系统识别能出多少个图片，当然阈值的变化会导致Precision与Recall值发生变化。比如，把蓝色虚线放到第一张图片下面，也就是说让系统只识别出最上面的那张飞机图片，那么Precision的值就是100%，而Recall的值则是20%。如果把蓝色虚线放到第二张图片下面，也就是说让系统只识别出最上面的前两张图片，那么Precision的值还是100%，而Recall的值则增长到是40%。</p>
<p>下图为不同阈值条件下，Precision与Recall的变化情况： </p>
<table>
<thead>
<tr>
<th>Retrieval cutoff</th>
<th>Precision</th>
<th>Recall</th>
</tr>
</thead>
<tbody>
<tr>
<td>Top 1 image</td>
<td>100%</td>
<td>20%</td>
</tr>
<tr>
<td>Top 2 images</td>
<td>100%</td>
<td>40%</td>
</tr>
<tr>
<td>Top 3 images</td>
<td>66%</td>
<td>40%</td>
</tr>
<tr>
<td>Top 4 images</td>
<td>75%</td>
<td>60%</td>
</tr>
<tr>
<td>Top 5 images</td>
<td>60%</td>
<td>60%</td>
</tr>
<tr>
<td>Top 6 images</td>
<td>66%</td>
<td>80%</td>
</tr>
<tr>
<td>Top 7 images</td>
<td>57%</td>
<td>80%</td>
</tr>
<tr>
<td>Top 8 images</td>
<td>50%</td>
<td>80%</td>
</tr>
<tr>
<td>Top 9 images</td>
<td>44%</td>
<td>80%</td>
</tr>
<tr>
<td>Top 10 images</td>
<td>50%</td>
<td>100%</td>
</tr>
</tbody>
</table>
<h2 id="Precision-recall-曲线"><a href="#Precision-recall-曲线" class="headerlink" title="Precision-recall 曲线"></a><strong>Precision-recall 曲线</strong></h2><p>如果你想评估一个分类器的性能，一个比较好的方法就是：观察当阈值变化时，Precision与Recall值的变化情况。如果一个分类器的性能比较好，那么它应该有如下的表现：被识别出的图片中飞机所占的比重比较大，并且在识别出大雁之前，尽可能多地正确识别出飞机，也就是让Recall值增长的同时保持Precision的值在一个很高的水平。而性能比较差的分类器可能会损失很多Precision值才能换来Recall值的提高。通常情况下，文章中都会使用Precision-recall曲线，来显示出分类器在Precision与Recall之间的权衡。<br> <center><img src="images/评价指标/4.png"></center></p>
<p> 上图就是分类器的Precision-recall 曲线，在不损失精度的条件下它能达到40%Recall。而当Recall达到100%时，Precision 降低到50%。</p>
<h2 id="Approximated-Average-precision"><a href="#Approximated-Average-precision" class="headerlink" title="Approximated Average precision"></a><strong>Approximated Average precision</strong></h2><p>相比较与曲线图，在某些时候还是一个具体的数值能更直观地表现出分类器的性能。通常情况下都是用 Average Precision来作为这一度量标准，它的公式为：<br> $$\int_{0}^{1} p(r)\, dr$$<br> 在这一积分中，其中p代表Precision ，r代表Recall，p是一个以r为参数的函数，That is equal to taking the area under the curve. </p>
<p>实际上这一积分极其接近于这一数值：对每一种阈值分别求（Precision值）乘以（Recall值的变化情况），再把所有阈值下求得的乘积值进行累加。公式如下：<br> $$\sum_{k=1}^N P(k)\Delta{r(k)}$$<br> 在这一公式中，N代表测试集中所有图片的个数，P(k)表示在能识别出k个图片的时候Precision的值，而 Delta r(k) 则表示识别图片个数从k-1变化到k时（通过调整阈值）Recall值的变化情况。</p>
<p>在这一例子中，Approximated Average Precision的值<br> (1 <em> 0.2) + (1 </em> 0.2) + (0.66 <em> 0) + (0.75 </em> 0.2) + (0.6 <em> 0) + (0.66 </em> 0.2) + (0.57 <em> 0) + (0.5 </em> 0) + (0.44 <em> 0) + (0.5 </em> 0.2) = 0.782.</p>
<p>通过计算可以看到，那些Recall值没有变化的地方（红色数值），对增加Average Precision值没有贡献。</p>
<h2 id="Interpolated-average-precision"><a href="#Interpolated-average-precision" class="headerlink" title="Interpolated average precision"></a><strong>Interpolated average precision</strong></h2><p>不同于Approximated Average Precision，一些作者选择另一种度量性能的标准：Interpolated Average Precision。这一新的算法不再使用P(k)，也就是说，不再使用当系统识别出k个图片的时候Precision的值与Recall变化值相乘。而是使用： </p>
<p>$$\text{max}_{\tilde{k}\geq{k}} P(k)$$</p>
<p> 也就是每次使用在所有阈值的Precision中，最大值的那个Precision值与Recall的变化值相乘。公式如下：<br> $$\sum_{k=1}^N \text{max}_{\tilde{k}\geq{k}}P(\tilde{k})\Delta{r(k)}​$$</p>
<p>下图的图片是Approximated Average Precision 与 Interpolated  Average Precision相比较。<br>  需要注意的是，为了让特征更明显，图片中使用的参数与上面所说的例子无关。 </p>
 <center><img src="images/评价指标/5.png"></center>

<p> 很明显 Approximated Average Precision与精度曲线挨的很近，而使用Interpolated Average Precision算出的Average Precision值明显要比Approximated Average Precision的方法算出的要高。</p>
<p>一些很重要的文章都是用Interpolated Average Precision 作为度量方法，并且直接称算出的值为Average Precision 。PASCAL Visual Objects Challenge从2007年开始就是用这一度量制度，他们认为这一方法能有效地减少Precision-recall 曲线中的抖动。所以在比较文章中Average Precision 值的时候，最好先弄清楚它们使用的是那种度量方式。</p>
<h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a><strong>IoU</strong></h2><p>IoU这一值，可以理解为系统预测出来的框与原来图片中标记的框的重合程度。<br> 计算方法即检测结果Detection Result与 Ground Truth 的交集比上它们的并集，即为检测的准确率：<br> $$IoU=\frac{DetectionResult⋂GroundTruth}{DetectionResult⋃GroundTruth}$$</p>
<p>如下图所示：<br> 蓝色的框是：GroundTruth<br> 黄色的框是：DetectionResult<br> 绿色的框是：DetectionResult ⋂ GroundTruth<br> 红色的框是：DetectionResult ⋃ GroundTruth </p>
<center><img src="images/评价指标/7.jpg"></center>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://sanchom.wordpress.com/tag/average-precision/" target="_blank" rel="noopener">https://sanchom.wordpress.com/tag/average-precision/</a> </li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/12/deep_learning/object_detection/R-CNN/" class="post-title-link" itemprop="url">目标检测网络之 R-CNN系列</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-11 10:41:28" itemprop="dateModified" datetime="2018-10-11T10:41:28+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><pre><code>目标检测(object detection)就是在给定的图片中精确找到物体所在位置，并标注出物体的类别。object detection要解决的问题就是物体在哪里，是什么这整个流程的问题。一般需要经过两个步骤：
</code></pre><ul>
<li><p>图像识别(classification)<br>输入：图片<br>输出：物体的类别<br>评估方法：准确率</p>
<center><img src="./images/rcnn_classfy.png" width="600"></center>
</li>
<li><p>定位(localization)</p>
<p>输入：图片<br>输出：方框在图片中的位置（x,y,w,h）<br>评估方法：检测评价函数 intersection-over-union ( IOU ) </p>
<center><img src="./images/rcnn_localization.png" width="600"></center>

</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><h3 id="思路一：看做回归问题"><a href="#思路一：看做回归问题" class="headerlink" title="思路一：看做回归问题"></a><strong>思路一：看做回归问题</strong></h3><pre><code>看做回归问题，我们需要预测出（x,y,w,h）四个参数的值，从而得出方框的位置。
</code></pre><p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112638429-1953242676.png" alt="img">步骤1:</p>
<ul>
<li><p>先解决简单问题， 搭一个识别图像的神经网络</p>
</li>
<li><p>在AlexNet VGG GoogleLenet上fine-tuning一下</p>
</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112659914-1900232742.jpg" alt="img"></p>
<p>步骤2:</p>
<ul>
<li>在上述神经网络的尾部展开（也就说CNN前面保持不变，我们对CNN的结尾处作出改进：加了两个头：“分类头”和“回归头”）</li>
<li>成为classification + regression模式</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112723757-880743532.png" alt="img"></p>
<p>步骤3:</p>
<ul>
<li>Regression那个部分用欧氏距离损失</li>
<li>使用SGD训练</li>
</ul>
<p>步骤4:</p>
<ul>
<li>预测阶段把2个头部拼上    </li>
<li>完成不同的功能</li>
</ul>
<p>这里需要进行两次fine-tuning<br>第一次在ALexNet上做，第二次将头部改成regression head，前面不变，做一次fine-tuning</p>
<p>Regression的部分加在哪？</p>
<p>有两种处理方法：</p>
<ul>
<li>加在最后一个卷积层后面（如VGG）</li>
<li>加在最后一个全连接层后面（如R-CNN）</li>
</ul>
<p>regression太难做了，应想方设法转换为classification问题。<br>regression的训练参数收敛的时间要长得多，所以上面的网络采取了用classification的网络来计算出网络共同部分的连接权值。</p>
<h3 id="思路二：取图像窗口"><a href="#思路二：取图像窗口" class="headerlink" title="思路二：取图像窗口"></a><strong>思路二：取图像窗口</strong></h3><ul>
<li>还是刚才的classification + regression思路</li>
<li>咱们取不同的大小的“框”　</li>
<li>让框出现在不同的位置，得出这个框的判定得分</li>
<li>取得分最高的那个框</li>
</ul>
<p>左上角的黑框：得分0.5<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112903273-1900432759.jpg" alt="img"><br>右上角的黑框：得分0.75</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112919320-1728574836.jpg" alt="img"></p>
<p>左下角的黑框：得分0.6<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112933164-1200242604.jpg" alt="img"><br>右下角的黑框：得分0.8</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112949320-428298146.jpg" alt="img"></p>
<p>根据得分的高低，我们选择了右下角的黑框作为目标位置的预测。<br>注：有的时候也会选择得分最高的两个框，然后取两框的交集作为最终的位置预测。</p>
<p>疑惑：框要取多大？<br>取不同的框，依次从左上角扫到右下角。非常粗暴啊。</p>
<p>总结一下思路：<br>对一张图片，用各种大小的框（遍历整张图片）将图片截取出来，输入到CNN，然后CNN会输出这个框的得分（classification）以及这个框图片对应的x,y,h,w（regression）。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113014179-105680354.jpg" alt="img"></p>
<p>这方法实在太耗时间了，做个优化。<br>原来网络是这样的：</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113030523-41422116.jpg" alt="img"></p>
<p>优化成这样：把全连接层改为卷积层，这样可以提提速。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113039304-1103823779.jpg" alt="img"></p>
<h2 id="候选框生成"><a href="#候选框生成" class="headerlink" title="候选框生成"></a>候选框生成</h2><p>当图像有很多物体怎么办的？难度可是一下暴增啊。</p>
<p>那任务就变成了：多物体识别+定位多个物体<br>那把这个任务看做分类问题？<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113057601-300431852.jpg" alt="img"></p>
<p>看成分类问题有何不妥？</p>
<ul>
<li>你需要找很多位置， 给很多个不同大小的框</li>
<li>你还需要对框内的图像分类　</li>
<li>当然， 如果你的GPU很强大， 恩， 那加油做吧…</li>
</ul>
<p>看做classification， 有没有办法优化下？我可不想试那么多框那么多位置啊！<br>有人想到一个好方法：<br>找出可能含有物体的框（也就是候选框，比如选1000个候选框），这些框之间是可以互相重叠互相包含的，这样我们就可以避免暴力枚举的所有框了。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113129211-135695982.jpg" alt="img"></p>
<p>大牛们发明好多选定候选框的方法，比如EdgeBoxes和Selective Search。<br>以下是各种选定候选框的方法的性能对比。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113209164-1717059035.jpg" alt="img"></p>
<p>有一个很大的疑惑，提取候选框用到的算法“选择性搜索”到底怎么选出这些候选框的呢？那个就得好好看看它的论文了，这里就不介绍了。</p>
<h2 id="R-CNN-1"><a href="#R-CNN-1" class="headerlink" title="R-CNN"></a>R-CNN</h2><p>基于以上的思路，RCNN的出现了。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113229570-69371857.png" alt="img"></p>
<p>步骤一：训练（或者下载）一个分类模型（比如AlexNet）<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113247742-406451407.jpg" alt="img"><br>步骤二：对该模型做fine-tuning</p>
<ul>
<li>将分类数从1000改为20</li>
<li>掉最后一个全连接层</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113302195-1032285194.png" alt="img"><br>步骤三：特征提取<br>　　-    提取图像的所有候选框（选择性搜索）<br>　　-    对于每一个区域：修正区域大小以适合CNN的输入，做一次前向运算，将第五个池化层的输出（就是对候选框提取到的特征）存到硬盘</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113326195-1862868537.png" alt="img"></p>
<p>步骤四：训练一个SVM分类器（二分类）来判断这个候选框里物体的类别<br>每个类别对应一个SVM，判断是不是属于这个类别，是就是positive，反之nagative<br>比如下图，就是狗分类的SVM</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113349351-169304797.png" alt="img"></p>
<p>步骤五：使用回归器精细修正候选框位置：对于每一个类，训练一个线性回归模型去判定这个框是否框得完美。</p>
<p> <img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113412351-143526289.png" alt="img"></p>
<h3 id="回归器"><a href="#回归器" class="headerlink" title="回归器"></a>回归器</h3><p>回归器：对每一类目标，使用一个线性脊回归器进行精修。正则项λ=1000。 输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。 训练样本：判定为本类的候选框中和真值重叠面积大于0.6的候选框。</p>
<pre><code>首先要明确目标检测不仅是要对目标进行识别，还要完成定位任务，所以最终获得的bounding-box也决定了目标检测的精度。 
</code></pre><p>这里先解释一下什么叫定位精度：定位精度可以用算法得出的物体检测框与实际标注的物体边界框的IoU值来近似表示。</p>
<p>如下图所示，绿色框为实际标准的卡宴车辆框，即Ground Truth；黄色框为selective search算法得出的建议框，即Region Proposal。即使黄色框中物体被分类器识别为卡宴车辆，但是由于绿色框和黄色框IoU值并不大，所以最后的目标检测精度并不高。采用回归器是为了对建议框进行校正，使得校正后的Region Proposal与selective search更接近， 以提高最终的检测精度。论文中采用bounding-box回归使mAP提高了3~4%。 </p>
<center><img src="images/rcnn_box_regression_1.jpg"></center>

<p>那么问题来了，回归器如何设计呢？ </p>
<center><img src="images/rcnn_box_regression_2.jpg"></center>

<p>如上图，黄色框口$P$表示建议框Region Proposal，绿色窗口$G$表示实际框Ground Truth，红色窗口$\widehat{G}$表示Region Proposal进行回归后的预测窗口，现在的目标是找到$P$到$\widehat{G}$的线性变换【当Region Proposal与Ground Truth的IoU&gt;0.6时可以认为是线性变换】，使得$\widehat{G}$与$G$越相近，这就相当于一个简单的可以用最小二乘法解决的线性回归问题，具体往下看。<br>让我们先来定义P窗口的数学表达式：$Pi=(P^i_x，P^i_y，P^i_w，P^i_h)$，其中$(P^i_x，P^i_y)$表示第一个i窗口的中心点坐标，$P_iw$,$P_ih$分别为第i个窗口的宽和高；$G$窗口的数学表达式为：$G^i=(G^i_x，G^i_y，G^i_w，G^i_h)$；$\widehat{G}$窗口的数学表达式为：$\widehat{G}_i=(\widehat{G}^i_x，\widehat{G}^i_y，\widehat{G}^i_w，\widehat{G}^i_h)$。以下省去$i$上标。<br>这里定义了四种变换函数，$d_x(P)$，$d_y(P)$，$d_w(P)$，$d_h(P)$。$d_x(P)$和$d_y(P)$通过平移对x和y进行变化，$d_w(P)$和$d_h(P)$通过缩放对w和h进行变化，即下面四个式子所示： </p>
<center><br><br>$$\widehat{G}_x=P_wd_x(P)+P_x$$<br><br>$$\widehat{G}_y=P_hd_y(P)+P_y$$<br><br>$$\widehat{G}_w=P_w\text{exp}(d_w(P))$$<br><br>$$\widehat{G}_h=P_h\text{exp}(d_h(P))​$$<br></center>

<p>每一个$d_∗(P)$【*表示x，y，w，h】都是一个AlexNet CNN网络Pool5层特征$\phi_5(P)$的线性函数，即$d_∗(P)=w^T_∗\phi_5(P)$ ，这里$w^T_∗$就是所需要学习的回归参数。损失函数即为：</p>
<p>$$Loss=argmin\Sigma_{i=0}^N(t^i_∗−w^T_∗ϕ<em>5(P^i))^2+λ||\widehat{w}</em>∗||^2$$</p>
<p>损失函数中加入正则项$λ||\widehat{w}<em>∗||^2$$ 是为了避免归回参数\widehat{w}</em>∗过大。其中，回归目标$$t_*$由训练输入对$(P，G)$按下式计算得来：</p>
<center><br><br>$$ t_x=(G_x−P_x)/P_w$$<br><br>$$t_y=(G_y−P_y)/P_h$$<br><br>$$t_w=log(G_w/P_w)$$<br><br>$$t_h=log(G_h/P_h)$$<br><br></center>

<p>①构造样本对。为了提高每类样本框回归的有效性，对每类样本都仅仅采集与Ground Truth相交IoU最大的Region Proposal，并且IoU&gt;0.6的Region Proposal作为样本对$(P^i，G^i)$，一共产生20对样本对【20个类别】；<br>②每种类型的回归器单独训练，输入该类型样本对N个：${(P^i,G^i)}<em>{i=1⋯N}$以及$P^i</em>{i=1⋯N}$所对应的AlexNet CNN网络Pool5层特征$\phi_5(P^i)<em>{i=1⋯N}$；<br>③利用输入样本对${(P^i,G^i)}</em>(i=1⋯N)$计算$t^i_{∗i=1⋯N}$；<br>④利用$\phi_5(P^i)<em>{i=1⋯N}$和$t^i</em>{∗i=1⋯N}$，根据损失函数进行回归，得到使损失函数最小的参数$w^T_∗$。</p>
<p>RCNN的进化中SPP Net的思想对其贡献很大，这里也简单介绍一下SPP Net。</p>
<h2 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP Net"></a><strong>SPP Net</strong></h2><p>SPP：Spatial Pyramid Pooling（空间金字塔池化）<br>它的特点有两个:</p>
<p>1.结合空间金字塔方法实现CNNs的对尺度输入。<br>一般CNN后接全连接层或者分类器，他们都需要固定的输入尺寸，因此不得不对输入数据进行crop或者warp，这些预处理会造成数据的丢失或几何的失真。SPP Net的第一个贡献就是将金字塔思想加入到CNN，实现了数据的多尺度输入。</p>
<p>如下图所示，在卷积层和全连接层之间加入了SPP layer。此时网络的输入可以是任意尺度的，在SPP layer中每一个pooling的filter会根据输入调整大小，而SPP的输出尺度始终是固定的。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113433539-94801265.jpg" alt="img"></p>
<p>　</p>
<p>2.只对原图提取一次卷积特征<br>在R-CNN中，每个候选框先resize到统一大小，然后分别作为CNN的输入，这样是很低效的。<br>所以SPP Net根据这个缺点做了优化：只对原图进行一次卷积得到整张图的feature map，然后找到每个候选框zaifeature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层。节省了大量的计算时间，比R-CNN有一百倍左右的提速。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113450414-709458906.jpg" alt="img"></p>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a><strong>Fast R-CNN</strong></h2><p>SPP Net真是个好方法，R-CNN的进阶版Fast R-CNN就是在RCNN的基础上采纳了SPP Net方法，对RCNN作了改进，使得性能进一步提高。</p>
<p>R-CNN与Fast RCNN的区别有哪些呢？<br>先说RCNN的缺点：即使使用了selective search等预处理步骤来提取潜在的bounding box作为输入，但是RCNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113527898-1753606875.png" alt="img"></p>
<p>大牛提出了一个可以看做单层sppnet的网络层，叫做ROI Pooling，这个网络层可以把不同大小的输入映射到一个固定尺度的特征向量，而我们知道，conv、pooling、relu等操作都不需要固定size的输入，因此，在原始图片上执行这些操作后，虽然输入图片size不同导致得到的feature map尺寸也不同，不能直接接到一个全连接层进行分类，但是可以加入这个神奇的ROI Pooling层，对每个region都提取一个固定维度的特征表示，再通过正常的softmax进行类型识别。另外，之前RCNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast-RCNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。Fast-RCNN很重要的一个贡献是成功的让人们看到了Region Proposal+CNN这一框架实时检测的希望，原来多类检测真的可以在保证准确率的同时提升处理速度，也为后来的Faster-RCNN做下了铺垫。</p>
<p>画一画重点：<br>R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。<br>大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。<br>解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征</p>
<p>原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归<br>现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归</p>
<p>所以容易看见，Fast RCNN相对于RCNN的提速原因就在于：不过不像RCNN把每个候选区域给深度网络提特征，而是整张图提一次特征，再把候选框映射到conv5上，而SPP只需要计算一次特征，剩下的只需要在conv5层上操作就可以了。</p>
<p>在性能上提升也是相当明显的：</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113546570-1486555910.png" alt="img"></p>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a><strong>Faster R-CNN</strong></h2><p>Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？<br>解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。<br>做这样的任务的神经网络叫做Region Proposal Network(RPN)。</p>
<p>具体做法：<br>　　-    将RPN放在最后一个卷积层的后面<br>　　-    RPN直接训练得到候选区域</p>
<p> <img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113604070-1781708405.png" alt="img"></p>
<p>RPN简介：<br>　　-    在feature map上滑动窗口<br>　　-    建一个神经网络用于物体分类+框位置的回归<br>　　-    滑动窗口的位置提供了物体的大体位置信息<br>　　-    框的回归提供了框更精确的位置</p>
 <center><img src="images/rpn.jpg"></center>

<p>一种网络，四个损失函数;<br>　　-    RPN calssification(anchor good.bad)<br>　　-    RPN regression(anchor-&gt;propoasal)<br>　　-    Fast R-CNN classification(over classes)<br>　　-    Fast R-CNN regression(proposal -&gt;box)</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113908179-1745309228.png" alt="img"></p>
<p>速度对比</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113649195-2098206818.png" alt="img"></p>
<p>Faster R-CNN的主要贡献是设计了提取候选区域的网络RPN，代替了费时的选择性搜索，使得检测速度大幅提高。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后总结一下各大算法的步骤：<br>RCNN</p>
<p>　　1.    在图像中确定约1000-2000个候选框 (使用选择性搜索)<br>　　2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取<br>　　3.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　4.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>Fast RCNN<br>　　1.    在图像中确定约1000-2000个候选框 (使用选择性搜索)<br>　　2.    对整张图片输进CNN，得到feature map<br>　　3.    找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层<br>　　4.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　5.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>Faster RCNN<br>　　1.    对整张图片输进CNN，得到feature map<br>　　2.    卷积特征输入到RPN，得到候选框的特征信息<br>　　3.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　4.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>总的来说，从R-CNN, SPP-NET, Fast R-CNN, Faster R-CNN一路走来，基于深度学习目标检测的流程变得越来越精简，精度越来越高，速度也越来越快。可以说基于region proposal的R-CNN系列目标检测方法是当前目标检测技术领域最主要的一个分支。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/math/merge_mean_vart/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/12/math/merge_mean_vart/" class="post-title-link" itemprop="url">均值方差合并</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2019-02-27 16:22:52" itemprop="dateModified" datetime="2019-02-27T16:22:52+08:00">2019-02-27</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Math/" itemprop="url" rel="index"><span itemprop="name">Math</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>#均值方差合并</p>
<h2 id="均值"><a href="#均值" class="headerlink" title="均值"></a>均值</h2><p>$$<br>\mathrm{mean}=\sum_i^n{\frac{x_i}{n}}=\frac{x_1+x_2+…+x_n}{n}=\frac{\mathrm{sum_1}}{n}<br>$$</p>
<p>其中$\mathrm{sum_1}=(x_1+x_2+…+x_n)$</p>
<h2 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h2><p>$$<br>\begin{alignat}{2} \mathrm{Var} &amp; = \frac{\sum_i^n{(x_i-\mathrm{mean})^2}}{n} \&amp; = \frac{\sum_i^n{(x_i^2-2<em>\mathrm{mean}</em>x_i+\mathrm{mean}^2)}}{n} \&amp; = \frac{\mathrm{sum_2}}{n}-2<em>\mathrm{mean}</em>\sum_i^n{\frac{x_i}{n}}+ \mathrm{mean}^2  \&amp; = \frac{\mathrm{sum_2}}{n}-\mathrm{mean}^2\\end{alignat}<br>$$</p>
<p>其中$\mathrm{sum_2}=(x_1^2+x_2^2+…+x_n^2)$</p>
<h2 id="合并均值方差"><a href="#合并均值方差" class="headerlink" title="合并均值方差"></a>合并均值方差</h2><p>计两个数组$A=(x_1,x_2,…x_m)$, $B=(y_1,y_2,…y_n)$。A数组包含m个元素，均值为mean1，方差为Var1，B数组包含n个元素，均值为mean2，方差为Var2</p>
<p>则合并A，B数组后的均值为<br>$$<br>\begin{alignat}{2} \mathrm{mean_{merge}} &amp; = \frac{\sum_i^m{x_i} +\sum_j^n{y_j}}{m+n} \&amp; = \frac{m<em>\mathrm{mean1} +n</em>\mathrm{mean2}}{m+n}\\end{alignat}<br>$$<br>方差为<br>$$<br>\begin{alignat}{2} \mathrm{Var_{merge}} &amp; = \frac{\sum_i^m{(x_i-\mathrm{mean_{merge}})^2+\sum_j^n{(y_j-\mathrm{mean_{merge}})^2}}}{m + n} \&amp; = \frac{\sum_i^m{(x_i^2-2<em>\mathrm{mean_{merge}}</em>x_i+\mathrm{mean_{merge}}^2)+\sum_j^n{(y_j^2-2<em>\mathrm{mean_{merge}}</em>y_j+\mathrm{mean_{merge}}^2)}}}{m+n} \&amp; = \frac{\mathrm{sum_2}}{m+n}-\mathrm{mean_{merge}}^2 \&amp; = \frac{\mathrm{(Var_A+\mathrm{mean_A}^2})<em>m +\mathrm{(Var_B+\mathrm{mean_B}^2})</em>n}{m+n}-\mathrm{mean_{merge}}^2\\end{alignat}<br>$$<br>其中$\mathrm{sum_2}=(x_1^2+x_2^2+…+x_m^2 + y_1^2+y_2^2+…+y_n^2)$,   记$\mathrm{sum_A}=(x_1^2+x_2^2+…+x_m^2)=\mathrm{(Var_A+\mathrm{mean_A}^2})<em>m$，$\mathrm{sum_B}=( y_1^2+y_2^2+…+y_n^2) = \mathrm{(Var_B+\mathrm{mean_B}^2})</em>n$</p>
<h2 id="Python代码"><a href="#Python代码" class="headerlink" title="Python代码"></a>Python代码</h2><h3 id="code"><a href="#code" class="headerlink" title="code"></a>code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">merge_mean_var</span><span class="params">(n, mean1, var1, m, mean2, var2)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    已知两组数据的个数，均值和方差，求总数据的均值和方差</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        n: 第一组数据的个数</span></span><br><span class="line"><span class="string">        mean1: 第一组数据的均值</span></span><br><span class="line"><span class="string">        var1: 第一组数据的方差</span></span><br><span class="line"><span class="string">        m: 第二组数据的个数</span></span><br><span class="line"><span class="string">        mean2: 第二组数据的均值</span></span><br><span class="line"><span class="string">        var2: 第二组数据的方差</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        所有数据的个数，均值，方差</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    mean = (n * mean1 + m * mean2) / (m + n)</span><br><span class="line">    var = (n * (var1 + mean1**<span class="number">2</span>) + m * (var2 + mean2**<span class="number">2</span>))/(m + n) - mean**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> m+n, mean, var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_mean_var</span><span class="params">(array)</span>:</span></span><br><span class="line">    mean = np.mean(array)</span><br><span class="line">    var = np.var(array)</span><br><span class="line">    <span class="keyword">return</span> mean, var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    array = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br><span class="line">    array1 = np.array([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line">    array2 = np.array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>])</span><br><span class="line">    mean, var = get_mean_var(array)</span><br><span class="line">    mean1, var1 = get_mean_var(array1)</span><br><span class="line">    mean2, var2 = get_mean_var(array2)</span><br><span class="line">    print(mean, var)</span><br><span class="line">    print(mean1, var1)</span><br><span class="line">    print(mean2, var2)</span><br><span class="line">    print(merge_mean_var(array1.size, mean1, var1, array2.size, mean2, var2))</span><br></pre></td></tr></table></figure>
<h3 id="output"><a href="#output" class="headerlink" title="output"></a>output</h3><blockquote>
<p>5.0 6.666666666666667<br>5.0 8.0<br>5.0 5.0<br>(9, 5.0, 6.666666666666668)</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/yolo/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/avatar.gif"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2018/04/12/deep_learning/object_detection/yolo/" class="post-title-link" itemprop="url">目标检测网络之 YOLOv3</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Publicado el</span>
              

              
                
              

              <time title="Creado por: 2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Editado el</span>
                
                <time title="Modificado por: 2018-10-11 10:52:44" itemprop="dateModified" datetime="2018-10-11T10:52:44+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">En</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="目标检测网络之-YOLOv3"><a href="#目标检测网络之-YOLOv3" class="headerlink" title="目标检测网络之 YOLOv3"></a><a href="http://www.cnblogs.com/makefile/p/YOLOv3.html" target="_blank" rel="noopener">目标检测网络之 YOLOv3</a></h1><p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181215936-1251293440.png" alt="yolo-idea"></p>
<p>本文逐步介绍YOLO v1~v3的设计历程。</p>
<h2 id="YOLOv1基本思想"><a href="#YOLOv1基本思想" class="headerlink" title="YOLOv1基本思想"></a>YOLOv1基本思想</h2><p>YOLO将输入图像分成SxS个格子，若某个物体 Ground truth 的中心位置的坐标落入到某个格子，那么这个格子就负责检测出这个物体。</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181242586-322645739.png" alt="yolo-grid-predict"></p>
<h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a><strong>网络结构</strong></h3><p>YOLOv1网络借鉴了GoogLeNet分类网络结构。不同的是，YOLO未使用inception module，而是使用1x1卷积层（此处1x1卷积层的存在是为了跨通道信息整合）+3x3卷积层简单替代。<br>YOLOv1网络在最后使用全连接层进行类别输出，因此全连接层的输出维度是 $S×S×(B×5+C)$。<br>YOLOv1网络比VGG16快(浮点数少于VGG的1/3),准确率稍差。</p>
<p>每个格子输出B个bounding box（包含物体的矩形区域）信息，以及C个物体属于某种类别的概率信息。</p>
<p>Bounding box信息包含5个数据值，分别是x,y,w,h,和confidence。其中x,y是指当前格子预测得到的物体的bounding box的中心位置的坐标。w,h是bounding box的宽度和高度。注意：实际训练过程中，w和h的值使用图像的宽度和高度进行归一化到[0,1]区间内；x，y是bounding box中心位置相对于当前格子位置的偏移值，并且被归一化到[0,1]。</p>
<p>confidence反映当前bounding box是否包含物体以及物体位置的准确性，计算方式如下：</p>
<p>$confidence = P_{(object)}<em> IOU$, 其中，若bounding box包含物体，则$P_{(object)} = 1$；否则$P_{(object)} = 0$. IOU(</em>intersection over union*)为预测bounding box与物体真实区域的交集面积（以像素为单位，用真实区域的像素面积归一化到[0,1]区间）。</p>
<p>因此，YOLO网络最终的全连接层的输出维度是 $S<em>S</em>(B<em>5 + C)$。YOLO论文中，作者训练采用的输入图像分辨率是448x448，S=7，B=2；采用VOC 20类标注物体作为训练数据，C=20。因此输出向量为$7</em>7<em>(20 + 2</em>5)=1470$维。作者开源出的YOLO代码中，全连接层输出特征向量各维度对应内容如下：</p>
<p><img src="https://pic3.zhimg.com/80/v2-1098c1152f55d73a859f20bae3d9bb1e_hd.jpg" alt="img"></p>
<p>缺馅:</p>
<ul>
<li>输入尺寸固定：由于输出层为全连接层，因此在检测时，YOLO训练模型只支持与训练图像相同的输入分辨率。其它分辨率需要缩放成改分辨率.</li>
<li>占比较小的目标检测效果不好.虽然每个格子可以预测B个bounding box，但是最终只选择只选择IOU最高的bounding box作为物体检测输出，即每个格子最多只预测出一个物体。当物体占画面比例较小，如图像中包含畜群或鸟群时，每个格子包含多个物体，但却只能检测出其中一个。</li>
</ul>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a><strong>损失函数</strong></h3><p>YOLO全部使用了均方和误差作为loss函数.由三部分组成:坐标误差、IOU误差和分类误差。</p>
<p>$$\text{loss}=\sum_{i=0}^{s^2}coordErr+iouErr+clsErr$$</p>
<p>简单相加时还要考虑每种loss的贡献率,YOLO给coordErr设置权重$λ_{\text{coord}}=5$.在计算IOU误差时，包含物体的格子与不包含物体的格子，二者的IOU误差对网络loss的贡献值是不同的。若采用相同的权值，那么不包含物体的格子的confidence值近似为0，变相放大了包含物体的格子的confidence误差在计算网络参数梯度时的影响。为解决这个问题，YOLO 使用</p>
<p>λnoobj=0.5</p>
<p>修正iouErr。（此处的‘包含’是指存在一个物体，它的中心坐标落入到格子内）。对于相等的误差值，大物体误差对检测的影响应小于小物体误差对检测的影响。这是因为，相同的位置偏差占大物体的比例远小于同等偏差占小物体的比例。YOLO将物体大小的信息项（w和h）进行求平方根来改进这个问题，但并不能完全解决这个问题。</p>
<p>综上，YOLO在训练过程中Loss计算如下式所示：</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181317188-1434000633.png" alt="yolo-loss"></p>
<p>yolo-loss</p>
<p>其中有宝盖帽子符号(x^,y^,w^,h^,C^,p^x^,y^,w^,h^,C^,p^)为预测值,无帽子的为训练标记值。1objij1ijobj表示物体落入格子i的第j个bbox内.如果某个单元格中没有目标,则不对分类误差进行反向传播;B个bbox中与GT具有最高IoU的一个进行坐标误差的反向传播,其余不进行.</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>1）预训练。使用 ImageNet 1000 类数据训练YOLO网络的前20个卷积层+1个average池化层+1个全连接层。训练图像分辨率resize到224x224。</p>
<p>2）用步骤1）得到的前20个卷积层网络参数来初始化YOLO模型前20个卷积层的网络参数，然后用 VOC 20 类标注数据进行YOLO模型训练。检测通常需要有细密纹理的视觉信息,所以为提高图像精度，在训练检测模型时，将输入图像分辨率从224 × 224 resize到448x448。</p>
<p>训练时B个bbox的ground truth设置成一样的.</p>
<h2 id="升级版-YOLO-v2"><a href="#升级版-YOLO-v2" class="headerlink" title="升级版 YOLO v2"></a>升级版 YOLO v2</h2><p>为提高物体定位精准性和召回率，YOLO作者提出了 《<a href="https://www.cnblogs.com/makefile/p/https//arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO9000: Better, Faster, Stronger</a>》 (<a href="https://pjreddie.com/publications/" target="_blank" rel="noopener">Joseph Redmon</a>, Ali Farhadi, CVPR 2017, Best Paper Honorable Mention)，相比v1提高了训练图像的分辨率；引入了faster rcnn中anchor box的思想，对网络结构的设计进行了改进，输出层使用卷积层替代YOLO的全连接层，联合使用coco物体检测标注数据和imagenet物体分类标注数据训练物体检测模型。相比YOLO，YOLO9000在识别种类、精度、速度、和定位准确性等方面都有大大提升。</p>
<h3 id="YOLOv2-改进之处"><a href="#YOLOv2-改进之处" class="headerlink" title="YOLOv2 改进之处"></a>YOLOv2 改进之处</h3><p>YOLO与Fast R-CNN相比有较大的定位误差，与基于region proposal的方法相比具有较低的召回率。因此YOLO v2主要改进是提高召回率和定位能力。下面是改进之处：</p>
<p><strong>Batch Normalization</strong>： v1中也大量用了Batch Normalization，同时在定位层后边用了dropout，v2中取消了dropout，在卷积层全部使用Batch Normalization。</p>
<p><strong>高分辨率分类器</strong>：v1中使用224 × 224训练分类器网络，扩大到448用于检测网络。v2将ImageNet以448×448 的分辨率微调最初的分类网络，迭代10 epochs。</p>
<p><strong>Anchor Boxes</strong>：v1中直接在卷积层之后使用全连接层预测bbox的坐标。v2借鉴Faster R-CNN的思想预测bbox的偏移.移除了全连接层,并且删掉了一个pooling层使特征的分辨率更大一些.另外调整了网络的输入(448-&gt;416)以使得位置坐标是奇数只有一个中心点(yolo使用pooling来下采样,有5个size=2,stride=2的max pooling,而卷积层没有降低大小,因此最后的特征是416/(2^5)=13).v1中每张图片预测7x7x2=98个box,而v2加上Anchor Boxes能预测超过1000个.检测结果从69.5mAP,81% recall变为69.2 mAP,88% recall.</p>
<p>YOLO v2对Faster R-CNN的手选先验框方法做了改进,采样k-means在训练集bbox上进行聚类产生合适的先验框.由于使用欧氏距离会使较大的bbox比小的bbox产生更大的误差，而IOU与bbox尺寸无关,因此使用IOU参与距离计算,使得通过这些anchor boxes获得好的IOU分值。距离公式：</p>
<p>D(box,centroid)=1−IOU(box,centroid)D(box,centroid)=1−IOU(box,centroid)</p>
<p>使用聚类进行选择的优势是达到相同的IOU结果时所需的anchor box数量更少,使得模型的表示能力更强,任务更容易学习.k-means算法代码实现参考:<a href="https://github.com/PaulChongPeng/darknet/blob/master/tools/k_means_yolo.py" target="_blank" rel="noopener">k_means_yolo.py</a>.算法过程是:将每个bbox的宽和高相对整张图片的比例(wr,hr)进行聚类,得到k个anchor box,由于darknet代码需要配置文件中region层的anchors参数是绝对值大小,因此需要将这个比例值乘上卷积层的输出特征的大小.如输入是416x416,那么最后卷积层的特征是13x13.</p>
<p><strong>细粒度特征</strong>(fine grain features):在Faster R-CNN 和 SSD 均使用了不同的feature map以适应不同尺度大小的目标.YOLOv2使用了一种不同的方法，简单添加一个 pass through layer，把浅层特征图（26x26）连接到深层特征图(连接到新加入的三个卷积核尺寸为3 * 3的卷积层最后一层的输入)。 通过叠加浅层特征图相邻特征到不同通道（而非空间位置），类似于Resnet中的identity mapping。这个方法把26x26x512的特征图叠加成13x13x2048的特征图，与原生的深层特征图相连接，使模型有了细粒度特征。此方法使得模型的性能获得了1%的提升。</p>
<p><strong>Multi-Scale Training</strong>: 和YOLOv1训练时网络输入的图像尺寸固定不变不同，YOLOv2（在cfg文件中random=1时）每隔几次迭代后就会微调网络的输入尺寸。训练时每迭代10次，就会随机选择新的输入图像尺寸。因为YOLOv2的网络使用的downsamples倍率为32，所以使用32的倍数调整输入图像尺寸{320,352，…，608}。训练使用的最小的图像尺寸为320 x 320，最大的图像尺寸为608 x 608。 这使得网络可以适应多种不同尺度的输入.</p>
<h3 id="YOLOv2网络结构"><a href="#YOLOv2网络结构" class="headerlink" title="YOLOv2网络结构"></a>YOLOv2网络结构</h3><p>YOLOv2对v1的基础网络做了更改.</p>
<p><strong>分类网络</strong></p>
<p>YOLOv2提出了一种新的分类模型Darknet-19.借鉴了很多其它网络的设计概念.主要使用3x3卷积并在pooling之后channel数加倍(VGG);global average pooling替代全连接做预测分类,并在3x3卷积之间使用1x1卷积压缩特征表示(Network in Network);使用 batch normalization 来提高稳定性,加速收敛,对模型正则化.<br>Darknet-19的结构如下表:</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181344634-594145493.png" alt="Darknet-19-arch"></p>
<p>Darknet-19-arch</p>
<p>包含 19 conv + 5 maxpooling.</p>
<p>训练:使用Darknet框架在ImageNet 1000类上训练160 epochs,学习率初始为0.1,以4级多项式衰减.weight decay=0.0005 , momentum=0.9.使用标准的数据增广方法:random crops, rotations, (hue, saturation), exposure shifts.</p>
<p>之后将输入从224放大至448,学习率调整为0.001,迭代10 epochs.结果达到top-1 accuracy 76.5% , top-5 accuracy 93.3%.</p>
<p><strong>检测网络</strong></p>
<p>在分类网络中移除最后一个1x1的层,在最后添加3个3x3x1024的卷积层,再接上输出是类别个数的1x1卷积.<br>对于输入图像尺寸为<code>Si x Si</code>,最终3x3卷积层输出的feature map是<code>Oi x Oi</code>(Oi=Si/(2^5)),对应输入图像的Oi x Oi个栅格，每个栅格预测<code>#anchors</code>种boxes大小，每个box包含4个坐标值,1个置信度和<code>#classes</code>个条件类别概率，所以输出维度是<code>Oi x Oi x #anchors x (5 + #classes)</code>。</p>
<p>添加<strong>跨层跳跃连接</strong>（借鉴ResNet等思想）,融合粗细粒度的特征:将前面最后一个3x3x512卷积的特征图,对于416x416的输入,该层输出26x26x512,直接连接到最后新加的三个3x3卷积层的最后一个的前边.将26x26x512变形为13x13x2048与后边的13x13x1024特征按channel堆起来得到13x13x3072.从yolo-voc.cfg文件可以看到，第25层为route层，逆向9层拿到第16层26 <em> 26 </em> 512的输出，并由第26层的reorg层把26 <em> 26 </em> 512 变形为13 <em> 13 </em> 2048，再有第27层的route层连接24层和26层的输出，堆叠为13 <em> 13 </em> 3072，由最后一个卷积核为3 * 3的卷积层进行跨通道的信息融合并把通道降维为1024。</p>
<p><strong>训练</strong>:作者在VOC07+12以及COCO2014数据集上迭代了160 epochs,初始学习率0.001,在60和90 epochs分别减小为0.1倍.<br>Darknet训练VOC的参数如下:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">learning_rate=0.0001</span><br><span class="line">batch=64</span><br><span class="line">max_batches = 45000 # 最大迭代batch数</span><br><span class="line">policy=steps # 学习率衰减策略</span><br><span class="line">steps=100,25000,35000 # 训练到这些batch次数时learning_rate按scale缩放</span><br><span class="line">scales=10,.1,.1 # 与steps对应</span><br></pre></td></tr></table></figure>
<p>网络结构如下(输入416,5个类别,5个anchor box; 此结构信息由Darknet框架启动时输出):</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181407843-936091130.png" alt="YOLO v2-network"></p>
<p>YOLO v2-network</p>
<h3 id="YOLO9000"><a href="#YOLO9000" class="headerlink" title="YOLO9000"></a>YOLO9000</h3><p>提出了一种联合训练方法，能够容许同时使用目标检测数据集和分类数据集。使用有标记的检测数据集精确定位，使用分类数据增加类别和鲁棒性。</p>
<h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2><p>YOLOv3在Pascal Titan X上处理608x608图像速度达到20FPS，在 COCO test-dev 上 <a href="mailto:mAP@0.5" target="_blank" rel="noopener">mAP@0.5</a> 达到 57.9%，与RetinaNet（FocalLoss论文所提出的单阶段网络）的结果相近，并且速度快4倍.</p>
<p>YOLO v3的模型比之前的模型复杂了不少，可以通过改变模型结构的大小来权衡速度与精度。</p>
<p>速度对比如下：</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180327003315889-714719589.png" alt="YOLOv3 compare"></p>
<p>YOLOv3 compare</p>
<p><strong>改进之处</strong>：</p>
<ul>
<li>多尺度预测 （类FPN）</li>
<li>更好的基础分类网络（类ResNet）和分类器</li>
</ul>
<p><strong>分类器-类别预测</strong>：<br>YOLOv3不使用Softmax对每个框进行分类，主要考虑因素有两个：</p>
<ol>
<li>Softmax使得每个框分配一个类别（score最大的一个），而对于<code>Open Images</code>这种数据集，目标可能有重叠的类别标签，因此Softmax不适用于多标签分类。</li>
<li>Softmax可被独立的多个logistic分类器替代，且准确率不会下降。<br>分类损失采用binary cross-entropy loss.</li>
</ol>
<p><strong>多尺度预测</strong><br>每种尺度预测3个box, anchor的设计方式仍然使用聚类,得到9个聚类中心,将其按照大小均分给3中尺度.</p>
<ul>
<li>尺度1: 在基础网络之后添加一些卷积层再输出box信息.</li>
<li>尺度2: 从尺度1中的倒数第二层的卷积层上采样(x2)再与最后一个16x16大小的特征图相加,再次通过多个卷积后输出box信息.相比尺度1变大两倍.</li>
<li>尺度3: 与尺度2类似,使用了32x32大小的特征图.</li>
</ul>
<p>参见网络结构定义文件<a href="https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg" target="_blank" rel="noopener">yolov3.cfg</a></p>
<p><strong>基础网络 Darknet-53</strong><br>仿ResNet, 与ResNet-101或ResNet-152准确率接近,但速度更快.对比如下:</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180327003709767-1829778920.png" alt="darknet-53 compare"></p>
<p>darknet-53 compare</p>
<p>网络结构如下：</p>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180327004340505-1572852891.png" alt="YOLOv3-arch"></p>
<p>YOLOv3-arch</p>
<p>YOLOv3在<a href="mailto:mAP@0.5mAP" target="_blank" rel="noopener">mAP@0.5mAP</a>@0.5及小目标APSAPS上具有不错的结果,但随着IOU的增大,性能下降,说明YOLOv3不能很好地与ground truth切合.</p>
<p>.</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点</p>
<ul>
<li>快速,pipline简单.</li>
<li>背景误检率低。</li>
<li>通用性强。YOLO对于艺术类作品中的物体检测同样适用。它对非自然图像物体的检测率远远高于DPM和RCNN系列检测方法。</li>
</ul>
<p>但相比RCNN系列物体检测方法，YOLO具有以下缺点：</p>
<ul>
<li>识别物体位置精准性差。</li>
<li>召回率低。在每个网格中预测两个bbox这种约束方式减少了对同一目标的多次检测(R-CNN使用的region proposal方式重叠较多),相比R-CNN使用Selective Search产生2000个proposal（RCNN测试时每张超过40秒）,yolo仅使用7x7x2个.</li>
</ul>
<h3 id="YOLO-v-s-Faster-R-CNN"><a href="#YOLO-v-s-Faster-R-CNN" class="headerlink" title="YOLO v.s. Faster R-CNN"></a>YOLO v.s. Faster R-CNN</h3><ol>
<li>统一网络:<br>YOLO没有显示求取region proposal的过程。Faster R-CNN中尽管RPN与fast rcnn共享卷积层，但是在模型训练过程中，需要反复训练RPN网络和fast rcnn网络.<br>相对于R-CNN系列的”看两眼”(候选框提取与分类，图示如下),YOLO只需要Look Once.</li>
<li>YOLO统一为一个回归问题<br>而R-CNN将检测结果分为两部分求解：物体类别（分类问题），物体位置即bounding box（回归问题）。</li>
</ol>
<p><img src="https://images2018.cnblogs.com/blog/606386/201803/606386-20180324181429804-1383715883.png" alt="R-CNN pipline"></p>
<p>R-CNN pipline</p>
<hr>
<h2 id="Darknet-框架"><a href="#Darknet-框架" class="headerlink" title="Darknet 框架"></a>Darknet 框架</h2><p>Darknet 由 C 语言和 CUDA 实现, 对GPU显存利用效率较高(CPU速度差一些, 通过与SSD的Caffe程序对比发现存在CPU较慢,GPU较快的情况). Darknet 对第三方库的依赖较少,且仅使用了少量GNU linux平台C接口,因此很容易移植到其它平台,如Windows或嵌入式设备.<br>参考<a href="http://www.cnblogs.com/makefile/p/darknet-win-port.html" target="_blank" rel="noopener">Windows 版 Darknet (YOLOv2) 移植</a>, <a href="https://github.com/makefile/darknet" target="_blank" rel="noopener">代码在此</a>.</p>
<p><strong>region层</strong>:参数anchors指定kmeans计算出来的anchor box的长宽的绝对值(与网络输入大小相关),num参数为anchor box的数量,<br>另外还有bias_match,classes,coords等参数.在parser.c代码中的parse_region函数中解析这些参数,并保存在region_layer.num参数保存在l.n变量中;anchors保存在l.biases数组中.region_layer的前向传播中使用for(n = 0; n &lt; l.n; ++n)这样的语句,因此,如果在配置文件中anchors的数量大于num时,仅使用前num个,小于时内存越界.</p>
<p>region层的输入和输出大小与前一层(1x1 conv)的输出大小和网络的输入大小相关.</p>
<p><strong>Detection层</strong>: 坐标及类别结果输出层.</p>
<hr>
<p><strong>参考</strong></p>
<ul>
<li>YOLO主页 <a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="noopener">https://pjreddie.com/darknet/yolo/</a></li>
<li><a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="noopener">YOLOv3: An Incremental Improvement</a></li>
<li><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">YOLO9000: Better, Faster, Stronger</a></li>
<li><a href="http://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">You Only Look Once: Unified, Real-Time Object Detection</a></li>
</ul>
<p>著作权归作者所有。商业转载请联系作者获得授权,非商业转载请注明出处。</p>
<p>原文: </p>
<p><a href="https://www.cnblogs.com/makefile/p/YOLOv3.html" target="_blank" rel="noopener">https://www.cnblogs.com/makefile/p/YOLOv3.html</a></p>
<p> © </p>
<p>康行天下</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Página siguiente"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Heroinlin</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">35</span>
                    <span class="site-state-item-name">entradas</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">categorías</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">59</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/heroinlin" title="GitHub &rarr; https://github.com/heroinlin" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="/heroinlj@gmail.com" title="E-Mail &rarr; heroinlj@gmail.com"><i class="fa fa-fw fa-gmail"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://twitter.com/Heroin" title="Twitter &rarr; https://twitter.com/Heroin" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Heroinlin</span>

  

  
</div>


  <div class="powered-by">Creado mediante <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.6.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Tema – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.1.2</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  



  




  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
