<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222"/>
























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0"/>

<link rel="stylesheet" href="/css/main.css?v=7.1.2"/>


  <link rel="apple-touch-icon" sizes="180x180" href="/images/leaf.jpg?v=7.1.2">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/leaf.ico?v=7.1.2">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/leaf1.ico?v=7.1.2">


  <link rel="mask-icon" href="/images/leaf.jpg?v=7.1.2" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="R-CNN前言目标检测(object detection)就是在给定的图片中精确找到物体所在位置，并标注出物体的类别。object detection要解决的问题就是物体在哪里，是什么这整个流程的问题。一般需要经过两个步骤：  图像识别(classification)输入：图片输出：物体的类别评估方法：准确率   定位(localization) 输入：图片输出：方框在图片中的位置（x,y,w,h">
<meta name="keywords" content="object detection,R-CNN,Fast R-CNN,Faster R-CNN">
<meta property="og:type" content="article">
<meta property="og:title" content="目标检测网络之 R-CNN系列">
<meta property="og:url" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/index.html">
<meta property="og:site_name" content="Heroinlin&#39;s Blog">
<meta property="og:description" content="R-CNN前言目标检测(object detection)就是在给定的图片中精确找到物体所在位置，并标注出物体的类别。object detection要解决的问题就是物体在哪里，是什么这整个流程的问题。一般需要经过两个步骤：  图像识别(classification)输入：图片输出：物体的类别评估方法：准确率   定位(localization) 输入：图片输出：方框在图片中的位置（x,y,w,h">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rcnn_classfy.png">
<meta property="og:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rcnn_localization.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112638429-1953242676.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112659914-1900232742.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112723757-880743532.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112903273-1900432759.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112919320-1728574836.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112933164-1200242604.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112949320-428298146.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113014179-105680354.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113030523-41422116.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113039304-1103823779.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113057601-300431852.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113129211-135695982.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113209164-1717059035.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113229570-69371857.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113247742-406451407.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113302195-1032285194.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113326195-1862868537.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113349351-169304797.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113412351-143526289.png">
<meta property="og:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rcnn_box_regression_1.jpg">
<meta property="og:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rcnn_box_regression_2.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113433539-94801265.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113450414-709458906.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113527898-1753606875.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113546570-1486555910.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113604070-1781708405.png">
<meta property="og:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rpn.jpg">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113908179-1745309228.png">
<meta property="og:image" content="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113649195-2098206818.png">
<meta property="og:updated_time" content="2018-10-11T02:41:28.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="目标检测网络之 R-CNN系列">
<meta name="twitter:description" content="R-CNN前言目标检测(object detection)就是在给定的图片中精确找到物体所在位置，并标注出物体的类别。object detection要解决的问题就是物体在哪里，是什么这整个流程的问题。一般需要经过两个步骤：  图像识别(classification)输入：图片输出：物体的类别评估方法：准确率   定位(localization) 输入：图片输出：方框在图片中的位置（x,y,w,h">
<meta name="twitter:image" content="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/images/rcnn_classfy.png">





  
  
  <link rel="canonical" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/"/>



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>目标检测网络之 R-CNN系列 | Heroinlin's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Heroinlin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br/>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br/>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br/>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br/>归档</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/04/12/deep_learning/object_detection/R-CNN/"/>

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Heroinlin"/>
      <meta itemprop="description" content=""/>
      <meta itemprop="image" content="/images/leaf.jpg"/>
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Heroinlin's Blog"/>
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">目标检测网络之 R-CNN系列

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-04-12 10:48:11" itemprop="dateCreated datePublished" datetime="2018-04-12T10:48:11+08:00">2018-04-12</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-10-11 10:41:28" itemprop="dateModified" datetime="2018-10-11T10:41:28+08:00">2018-10-11</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/object-detection/" itemprop="url" rel="index"><span itemprop="name">object detection</span></a></span>

                
                
              
            </span>
          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2018/04/12/deep_learning/object_detection/R-CNN/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/2018/04/12/deep_learning/object_detection/R-CNN/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><pre><code>目标检测(object detection)就是在给定的图片中精确找到物体所在位置，并标注出物体的类别。object detection要解决的问题就是物体在哪里，是什么这整个流程的问题。一般需要经过两个步骤：
</code></pre><ul>
<li><p>图像识别(classification)<br>输入：图片<br>输出：物体的类别<br>评估方法：准确率</p>
<center><img src="./images/rcnn_classfy.png" width="600"></center>
</li>
<li><p>定位(localization)</p>
<p>输入：图片<br>输出：方框在图片中的位置（x,y,w,h）<br>评估方法：检测评价函数 intersection-over-union ( IOU ) </p>
<center><img src="./images/rcnn_localization.png" width="600"></center>

</li>
</ul>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><h3 id="思路一：看做回归问题"><a href="#思路一：看做回归问题" class="headerlink" title="思路一：看做回归问题"></a><strong>思路一：看做回归问题</strong></h3><pre><code>看做回归问题，我们需要预测出（x,y,w,h）四个参数的值，从而得出方框的位置。
</code></pre><p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112638429-1953242676.png" alt="img">步骤1:</p>
<ul>
<li><p>先解决简单问题， 搭一个识别图像的神经网络</p>
</li>
<li><p>在AlexNet VGG GoogleLenet上fine-tuning一下</p>
</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112659914-1900232742.jpg" alt="img"></p>
<p>步骤2:</p>
<ul>
<li>在上述神经网络的尾部展开（也就说CNN前面保持不变，我们对CNN的结尾处作出改进：加了两个头：“分类头”和“回归头”）</li>
<li>成为classification + regression模式</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112723757-880743532.png" alt="img"></p>
<p>步骤3:</p>
<ul>
<li>Regression那个部分用欧氏距离损失</li>
<li>使用SGD训练</li>
</ul>
<p>步骤4:</p>
<ul>
<li>预测阶段把2个头部拼上    </li>
<li>完成不同的功能</li>
</ul>
<p>这里需要进行两次fine-tuning<br>第一次在ALexNet上做，第二次将头部改成regression head，前面不变，做一次fine-tuning</p>
<p>Regression的部分加在哪？</p>
<p>有两种处理方法：</p>
<ul>
<li>加在最后一个卷积层后面（如VGG）</li>
<li>加在最后一个全连接层后面（如R-CNN）</li>
</ul>
<p>regression太难做了，应想方设法转换为classification问题。<br>regression的训练参数收敛的时间要长得多，所以上面的网络采取了用classification的网络来计算出网络共同部分的连接权值。</p>
<h3 id="思路二：取图像窗口"><a href="#思路二：取图像窗口" class="headerlink" title="思路二：取图像窗口"></a><strong>思路二：取图像窗口</strong></h3><ul>
<li>还是刚才的classification + regression思路</li>
<li>咱们取不同的大小的“框”　</li>
<li>让框出现在不同的位置，得出这个框的判定得分</li>
<li>取得分最高的那个框</li>
</ul>
<p>左上角的黑框：得分0.5<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112903273-1900432759.jpg" alt="img"><br>右上角的黑框：得分0.75</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112919320-1728574836.jpg" alt="img"></p>
<p>左下角的黑框：得分0.6<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112933164-1200242604.jpg" alt="img"><br>右下角的黑框：得分0.8</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504112949320-428298146.jpg" alt="img"></p>
<p>根据得分的高低，我们选择了右下角的黑框作为目标位置的预测。<br>注：有的时候也会选择得分最高的两个框，然后取两框的交集作为最终的位置预测。</p>
<p>疑惑：框要取多大？<br>取不同的框，依次从左上角扫到右下角。非常粗暴啊。</p>
<p>总结一下思路：<br>对一张图片，用各种大小的框（遍历整张图片）将图片截取出来，输入到CNN，然后CNN会输出这个框的得分（classification）以及这个框图片对应的x,y,h,w（regression）。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113014179-105680354.jpg" alt="img"></p>
<p>这方法实在太耗时间了，做个优化。<br>原来网络是这样的：</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113030523-41422116.jpg" alt="img"></p>
<p>优化成这样：把全连接层改为卷积层，这样可以提提速。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113039304-1103823779.jpg" alt="img"></p>
<h2 id="候选框生成"><a href="#候选框生成" class="headerlink" title="候选框生成"></a>候选框生成</h2><p>当图像有很多物体怎么办的？难度可是一下暴增啊。</p>
<p>那任务就变成了：多物体识别+定位多个物体<br>那把这个任务看做分类问题？<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113057601-300431852.jpg" alt="img"></p>
<p>看成分类问题有何不妥？</p>
<ul>
<li>你需要找很多位置， 给很多个不同大小的框</li>
<li>你还需要对框内的图像分类　</li>
<li>当然， 如果你的GPU很强大， 恩， 那加油做吧…</li>
</ul>
<p>看做classification， 有没有办法优化下？我可不想试那么多框那么多位置啊！<br>有人想到一个好方法：<br>找出可能含有物体的框（也就是候选框，比如选1000个候选框），这些框之间是可以互相重叠互相包含的，这样我们就可以避免暴力枚举的所有框了。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113129211-135695982.jpg" alt="img"></p>
<p>大牛们发明好多选定候选框的方法，比如EdgeBoxes和Selective Search。<br>以下是各种选定候选框的方法的性能对比。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113209164-1717059035.jpg" alt="img"></p>
<p>有一个很大的疑惑，提取候选框用到的算法“选择性搜索”到底怎么选出这些候选框的呢？那个就得好好看看它的论文了，这里就不介绍了。</p>
<h2 id="R-CNN-1"><a href="#R-CNN-1" class="headerlink" title="R-CNN"></a>R-CNN</h2><p>基于以上的思路，RCNN的出现了。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113229570-69371857.png" alt="img"></p>
<p>步骤一：训练（或者下载）一个分类模型（比如AlexNet）<br><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113247742-406451407.jpg" alt="img"><br>步骤二：对该模型做fine-tuning</p>
<ul>
<li>将分类数从1000改为20</li>
<li>掉最后一个全连接层</li>
</ul>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113302195-1032285194.png" alt="img"><br>步骤三：特征提取<br>　　-    提取图像的所有候选框（选择性搜索）<br>　　-    对于每一个区域：修正区域大小以适合CNN的输入，做一次前向运算，将第五个池化层的输出（就是对候选框提取到的特征）存到硬盘</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113326195-1862868537.png" alt="img"></p>
<p>步骤四：训练一个SVM分类器（二分类）来判断这个候选框里物体的类别<br>每个类别对应一个SVM，判断是不是属于这个类别，是就是positive，反之nagative<br>比如下图，就是狗分类的SVM</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113349351-169304797.png" alt="img"></p>
<p>步骤五：使用回归器精细修正候选框位置：对于每一个类，训练一个线性回归模型去判定这个框是否框得完美。</p>
<p> <img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113412351-143526289.png" alt="img"></p>
<h3 id="回归器"><a href="#回归器" class="headerlink" title="回归器"></a>回归器</h3><p>回归器：对每一类目标，使用一个线性脊回归器进行精修。正则项λ=1000。 输入为深度网络pool5层的4096维特征，输出为xy方向的缩放和平移。 训练样本：判定为本类的候选框中和真值重叠面积大于0.6的候选框。</p>
<pre><code>首先要明确目标检测不仅是要对目标进行识别，还要完成定位任务，所以最终获得的bounding-box也决定了目标检测的精度。 
</code></pre><p>这里先解释一下什么叫定位精度：定位精度可以用算法得出的物体检测框与实际标注的物体边界框的IoU值来近似表示。</p>
<p>如下图所示，绿色框为实际标准的卡宴车辆框，即Ground Truth；黄色框为selective search算法得出的建议框，即Region Proposal。即使黄色框中物体被分类器识别为卡宴车辆，但是由于绿色框和黄色框IoU值并不大，所以最后的目标检测精度并不高。采用回归器是为了对建议框进行校正，使得校正后的Region Proposal与selective search更接近， 以提高最终的检测精度。论文中采用bounding-box回归使mAP提高了3~4%。 </p>
<center><img src="images/rcnn_box_regression_1.jpg"></center>

<p>那么问题来了，回归器如何设计呢？ </p>
<center><img src="images/rcnn_box_regression_2.jpg"></center>

<p>如上图，黄色框口$P$表示建议框Region Proposal，绿色窗口$G$表示实际框Ground Truth，红色窗口$\widehat{G}$表示Region Proposal进行回归后的预测窗口，现在的目标是找到$P$到$\widehat{G}$的线性变换【当Region Proposal与Ground Truth的IoU&gt;0.6时可以认为是线性变换】，使得$\widehat{G}$与$G$越相近，这就相当于一个简单的可以用最小二乘法解决的线性回归问题，具体往下看。<br>让我们先来定义P窗口的数学表达式：$Pi=(P^i_x，P^i_y，P^i_w，P^i_h)$，其中$(P^i_x，P^i_y)$表示第一个i窗口的中心点坐标，$P_iw$,$P_ih$分别为第i个窗口的宽和高；$G$窗口的数学表达式为：$G^i=(G^i_x，G^i_y，G^i_w，G^i_h)$；$\widehat{G}$窗口的数学表达式为：$\widehat{G}_i=(\widehat{G}^i_x，\widehat{G}^i_y，\widehat{G}^i_w，\widehat{G}^i_h)$。以下省去$i$上标。<br>这里定义了四种变换函数，$d_x(P)$，$d_y(P)$，$d_w(P)$，$d_h(P)$。$d_x(P)$和$d_y(P)$通过平移对x和y进行变化，$d_w(P)$和$d_h(P)$通过缩放对w和h进行变化，即下面四个式子所示： </p>
<center><br><br>$$\widehat{G}_x=P_wd_x(P)+P_x$$<br><br>$$\widehat{G}_y=P_hd_y(P)+P_y$$<br><br>$$\widehat{G}_w=P_w\text{exp}(d_w(P))$$<br><br>$$\widehat{G}_h=P_h\text{exp}(d_h(P))​$$<br></center>

<p>每一个$d_∗(P)$【*表示x，y，w，h】都是一个AlexNet CNN网络Pool5层特征$\phi_5(P)$的线性函数，即$d_∗(P)=w^T_∗\phi_5(P)$ ，这里$w^T_∗$就是所需要学习的回归参数。损失函数即为：</p>
<p>$$Loss=argmin\Sigma_{i=0}^N(t^i_∗−w^T_∗ϕ<em>5(P^i))^2+λ||\widehat{w}</em>∗||^2$$</p>
<p>损失函数中加入正则项$λ||\widehat{w}<em>∗||^2$$ 是为了避免归回参数\widehat{w}</em>∗过大。其中，回归目标$$t_*$由训练输入对$(P，G)$按下式计算得来：</p>
<center><br><br>$$ t_x=(G_x−P_x)/P_w$$<br><br>$$t_y=(G_y−P_y)/P_h$$<br><br>$$t_w=log(G_w/P_w)$$<br><br>$$t_h=log(G_h/P_h)$$<br><br></center>

<p>①构造样本对。为了提高每类样本框回归的有效性，对每类样本都仅仅采集与Ground Truth相交IoU最大的Region Proposal，并且IoU&gt;0.6的Region Proposal作为样本对$(P^i，G^i)$，一共产生20对样本对【20个类别】；<br>②每种类型的回归器单独训练，输入该类型样本对N个：${(P^i,G^i)}<em>{i=1⋯N}$以及$P^i</em>{i=1⋯N}$所对应的AlexNet CNN网络Pool5层特征$\phi_5(P^i)<em>{i=1⋯N}$；<br>③利用输入样本对${(P^i,G^i)}</em>(i=1⋯N)$计算$t^i_{∗i=1⋯N}$；<br>④利用$\phi_5(P^i)<em>{i=1⋯N}$和$t^i</em>{∗i=1⋯N}$，根据损失函数进行回归，得到使损失函数最小的参数$w^T_∗$。</p>
<p>RCNN的进化中SPP Net的思想对其贡献很大，这里也简单介绍一下SPP Net。</p>
<h2 id="SPP-Net"><a href="#SPP-Net" class="headerlink" title="SPP Net"></a><strong>SPP Net</strong></h2><p>SPP：Spatial Pyramid Pooling（空间金字塔池化）<br>它的特点有两个:</p>
<p>1.结合空间金字塔方法实现CNNs的对尺度输入。<br>一般CNN后接全连接层或者分类器，他们都需要固定的输入尺寸，因此不得不对输入数据进行crop或者warp，这些预处理会造成数据的丢失或几何的失真。SPP Net的第一个贡献就是将金字塔思想加入到CNN，实现了数据的多尺度输入。</p>
<p>如下图所示，在卷积层和全连接层之间加入了SPP layer。此时网络的输入可以是任意尺度的，在SPP layer中每一个pooling的filter会根据输入调整大小，而SPP的输出尺度始终是固定的。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113433539-94801265.jpg" alt="img"></p>
<p>　</p>
<p>2.只对原图提取一次卷积特征<br>在R-CNN中，每个候选框先resize到统一大小，然后分别作为CNN的输入，这样是很低效的。<br>所以SPP Net根据这个缺点做了优化：只对原图进行一次卷积得到整张图的feature map，然后找到每个候选框zaifeature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层。节省了大量的计算时间，比R-CNN有一百倍左右的提速。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113450414-709458906.jpg" alt="img"></p>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a><strong>Fast R-CNN</strong></h2><p>SPP Net真是个好方法，R-CNN的进阶版Fast R-CNN就是在RCNN的基础上采纳了SPP Net方法，对RCNN作了改进，使得性能进一步提高。</p>
<p>R-CNN与Fast RCNN的区别有哪些呢？<br>先说RCNN的缺点：即使使用了selective search等预处理步骤来提取潜在的bounding box作为输入，但是RCNN仍会有严重的速度瓶颈，原因也很明显，就是计算机对所有region进行特征提取时会有重复计算，Fast-RCNN正是为了解决这个问题诞生的。</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113527898-1753606875.png" alt="img"></p>
<p>大牛提出了一个可以看做单层sppnet的网络层，叫做ROI Pooling，这个网络层可以把不同大小的输入映射到一个固定尺度的特征向量，而我们知道，conv、pooling、relu等操作都不需要固定size的输入，因此，在原始图片上执行这些操作后，虽然输入图片size不同导致得到的feature map尺寸也不同，不能直接接到一个全连接层进行分类，但是可以加入这个神奇的ROI Pooling层，对每个region都提取一个固定维度的特征表示，再通过正常的softmax进行类型识别。另外，之前RCNN的处理流程是先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做bbox regression，而在Fast-RCNN中，作者巧妙的把bbox regression放进了神经网络内部，与region分类和并成为了一个multi-task模型，实际实验也证明，这两个任务能够共享卷积特征，并相互促进。Fast-RCNN很重要的一个贡献是成功的让人们看到了Region Proposal+CNN这一框架实时检测的希望，原来多类检测真的可以在保证准确率的同时提升处理速度，也为后来的Faster-RCNN做下了铺垫。</p>
<p>画一画重点：<br>R-CNN有一些相当大的缺点（把这些缺点都改掉了，就成了Fast R-CNN）。<br>大缺点：由于每一个候选框都要独自经过CNN，这使得花费的时间非常多。<br>解决：共享卷积层，现在不是每一个候选框都当做输入进入CNN了，而是输入一张完整的图片，在第五个卷积层再得到每个候选框的特征</p>
<p>原来的方法：许多候选框（比如两千个）–&gt;CNN–&gt;得到每个候选框的特征–&gt;分类+回归<br>现在的方法：一张完整图片–&gt;CNN–&gt;得到每张候选框的特征–&gt;分类+回归</p>
<p>所以容易看见，Fast RCNN相对于RCNN的提速原因就在于：不过不像RCNN把每个候选区域给深度网络提特征，而是整张图提一次特征，再把候选框映射到conv5上，而SPP只需要计算一次特征，剩下的只需要在conv5层上操作就可以了。</p>
<p>在性能上提升也是相当明显的：</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113546570-1486555910.png" alt="img"></p>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a><strong>Faster R-CNN</strong></h2><p>Fast R-CNN存在的问题：存在瓶颈：选择性搜索，找出所有的候选框，这个也非常耗时。那我们能不能找出一个更加高效的方法来求出这些候选框呢？<br>解决：加入一个提取边缘的神经网络，也就说找到候选框的工作也交给神经网络来做了。<br>做这样的任务的神经网络叫做Region Proposal Network(RPN)。</p>
<p>具体做法：<br>　　-    将RPN放在最后一个卷积层的后面<br>　　-    RPN直接训练得到候选区域</p>
<p> <img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113604070-1781708405.png" alt="img"></p>
<p>RPN简介：<br>　　-    在feature map上滑动窗口<br>　　-    建一个神经网络用于物体分类+框位置的回归<br>　　-    滑动窗口的位置提供了物体的大体位置信息<br>　　-    框的回归提供了框更精确的位置</p>
 <center><img src="images/rpn.jpg"></center>

<p>一种网络，四个损失函数;<br>　　-    RPN calssification(anchor good.bad)<br>　　-    RPN regression(anchor-&gt;propoasal)<br>　　-    Fast R-CNN classification(over classes)<br>　　-    Fast R-CNN regression(proposal -&gt;box)</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113908179-1745309228.png" alt="img"></p>
<p>速度对比</p>
<p><img src="https://images2015.cnblogs.com/blog/1093303/201705/1093303-20170504113649195-2098206818.png" alt="img"></p>
<p>Faster R-CNN的主要贡献是设计了提取候选区域的网络RPN，代替了费时的选择性搜索，使得检测速度大幅提高。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后总结一下各大算法的步骤：<br>RCNN</p>
<p>　　1.    在图像中确定约1000-2000个候选框 (使用选择性搜索)<br>　　2. 每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取<br>　　3.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　4.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>Fast RCNN<br>　　1.    在图像中确定约1000-2000个候选框 (使用选择性搜索)<br>　　2.    对整张图片输进CNN，得到feature map<br>　　3.    找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层<br>　　4.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　5.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>Faster RCNN<br>　　1.    对整张图片输进CNN，得到feature map<br>　　2.    卷积特征输入到RPN，得到候选框的特征信息<br>　　3.    对候选框中提取出的特征，使用分类器判别是否属于一个特定类<br>　　4.    对于属于某一特征的候选框，用回归器进一步调整其位置</p>
<p>总的来说，从R-CNN, SPP-NET, Fast R-CNN, Faster R-CNN一路走来，基于深度学习目标检测的流程变得越来越精简，精度越来越高，速度也越来越快。可以说基于region proposal的R-CNN系列目标检测方法是当前目标检测技术领域最主要的一个分支。</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        
          
        
        <div class="post-tags">
          
            <a href="/tags/object-detection/" rel="tag"># object detection</a>
          
            <a href="/tags/R-CNN/" rel="tag"># R-CNN</a>
          
            <a href="/tags/Fast-R-CNN/" rel="tag"># Fast R-CNN</a>
          
            <a href="/tags/Faster-R-CNN/" rel="tag"># Faster R-CNN</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/12/deep_learning/object_detection/metric/" rel="next" title="目标检测网络之评价指标">
                <i class="fa fa-chevron-left"></i> 目标检测网络之评价指标
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/04/12/deep_learning/object_detection/yolo/" rel="prev" title="目标检测网络之 YOLOv3">
                目标检测网络之 YOLOv3 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="comments">
      
        <div id="gitment-container"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/leaf.jpg"
                alt="Heroinlin"/>
            
              <p class="site-author-name" itemprop="name">Heroinlin</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">35</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">11</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">59</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/heroinlin" title="GitHub &rarr; https://github.com/heroinlin" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="/heroinlj@gmail.com" title="E-Mail &rarr; heroinlj@gmail.com"><i class="fa fa-fw fa-gmail"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://twitter.com/Heroin" title="Twitter &rarr; https://twitter.com/Heroin" rel="noopener" target="_blank"><i class="fa fa-fw fa-twitter"></i>Twitter</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#R-CNN"><span class="nav-number">1.</span> <span class="nav-text">R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#前言"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#思路"><span class="nav-number">1.2.</span> <span class="nav-text">思路</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#思路一：看做回归问题"><span class="nav-number">1.2.1.</span> <span class="nav-text">思路一：看做回归问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#思路二：取图像窗口"><span class="nav-number">1.2.2.</span> <span class="nav-text">思路二：取图像窗口</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#候选框生成"><span class="nav-number">1.3.</span> <span class="nav-text">候选框生成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#R-CNN-1"><span class="nav-number">1.4.</span> <span class="nav-text">R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#回归器"><span class="nav-number">1.4.1.</span> <span class="nav-text">回归器</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SPP-Net"><span class="nav-number">1.5.</span> <span class="nav-text">SPP Net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fast-R-CNN"><span class="nav-number">1.6.</span> <span class="nav-text">Fast R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Faster-R-CNN"><span class="nav-number">1.7.</span> <span class="nav-text">Faster R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">1.8.</span> <span class="nav-text">总结</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Heroinlin</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.6.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.1.2</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.2"></script>

  <script src="/js/motion.js?v=7.1.2"></script>



  
  


  <script src="/js/affix.js?v=7.1.2"></script>

  <script src="/js/schemes/pisces.js?v=7.1.2"></script>



  
  <script src="/js/scrollspy.js?v=7.1.2"></script>
<script src="/js/post-details.js?v=7.1.2"></script>



  


  <script src="/js/next-boot.js?v=7.1.2"></script>


  

  

  

  


  
    <!-- LOCAL: You can save these files to your site and update links -->

  
  <script src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/gitmint.browser.js"></script>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/theme-next/theme-next-gitment@1/default.css"/>
<!-- END LOCAL -->

<script>
  function renderGitment() {
    var gitment = new Gitmint({
      id: window.location.pathname,
      owner: 'heroinlin',
      repo: 'heroinlin.github.io',
      
        lang: '' || navigator.language || navigator.systemLanguage || navigator.userLanguage,
      
      oauth: {
      
      
        client_secret: '264679785d383afbc726145178abea84ff750743',
      
        client_id: '33b4a51ea87942e922ca'
      }
    });
    gitment.render('gitment-container');
  }

  
    renderGitment();
  
</script>

  


  




  

  

  
  

  
  

  


  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
